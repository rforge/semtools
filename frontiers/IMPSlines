1. Good morning everyone. My name is Ting Wang. Today I'm going to talk about score-based tests' application in measurement invariance. 

2. Measurement invariance is an important assumption to develop unbiased scales. It means items can assign consistent scores across diverse groups. For example, we want SAT score represents the same amount of ability for each ethnic group. We also want the intelligence test score indicates the same amount of intelligence for each cohorts. 

3. If we translate these wishes in factor analysis framework, the question is wheather the loading for scale 1 for kids in lower grade is equvialent for kids in higher grade. If it is, we say the M.I. assumption holds, which means this null hypothesis holds(pass to slide 4). If not, we say the M.I. assumption is violated. which means kids in lower grade have one set of parameters, and kids in higher grade have another set of parameters. 

4. This M.I. hypothesis can be extended to multiple groups g. The only changing place is the alternative hypothesis, which means each group has its own parameters. vg is the auxiliary variable, it can be categorical, like gender; or ordinal, like grade; or continuous, like age. 

5. For this kind of hypothesis testing problem, researchers ususlly use LRT, wald test or Lagrange Multiplier test. Note LM test only requires estimates under null hypothesis. In this study we are going to focus on a more general LM test, which is called score-based tests.

6. In this presentation, we are going to first introduce these tests' theoretical background. Then we will demonstrate these tests' performance under practical scenarios by using simulation studies. In the end, we will illustrate how to use these tests. 

7. The score-based tests rely on the first derivatives of the model's log-likelihood function taken at the maximum estimation. Or equivalently, we can say the maximum estimation is got when the sum of scores is zero. These scores tell how well a particular parameter describles a particular individual. 

8. After we get those scores for each indiviudal, we need a way to aggregate scores across people. Specifically, we need to order these scores according to an auxiliarly variable. We also need to decorrelate the potential correlations between scores for each parameter. This empirical cumulative sum score can do these two things. Where I hat which is the information matrix decorrelate the scores. 

9. Those equations are very abstract and hard to interpret. So we will illustrate by this matrix demonstration. The left is the score matrix. Each row is every individual, each column represent each parameter. The right is the cumulative score, it just means we sum the score matrix rows. For example, the second row is the sum of these two rows, and third row is the sum of these three rows, so on and so forth. The last row is always zero, because that's how we get the maximum estimation.  After decorrelation, if we see there is a very big number, it is very likely that this parameter, theta k violates M.I. assumption. 

10. So we need some critical value to summarize the behavior of the empirical sum scores. Luckily, under the hypothesis of measurement invariance, a central limit theorem can be used to show that the empirical sum of score converges to a k dimensional Brownian bridge. k is the length of parameter vector. Thus we can get p value and critical value under the hypothesis M.I. 

11. Depending on what kind of auxiliary variable we use, multiple statistics were proposed. When it is categorical, we can use LM-uo, this statistic is asymptotic equvialent to LRT. If it is ordinal, we can use WDMo or maxLMo. We will demonstrate these statistics equation in the end. 

12. In this particular study, we focus on the practical issues of using these tests. We know, in practice, model misspecification is inevitable and in most studies, the auxiliary variable are ordinal, like income level, grade level, age level. So we want to examine the ordinal tests' performance under model misspecification by using simulations.  Besides, we will illustrate how to use these tests in application work.  So these tests can be available to all researchers. 

13. Particularly, the question for simulation is what is the ordinal tests' power under model misspecification.  It can be divided into two senarios, one is the estimated model missed out one parameter, but that parameter is not important, which means that parameter doesn't violate M.I. The second senario is worse. The estimated model missed out one parameter, and that parameter violates the M.I. assumption. 

14. The simulation's set up is like this. We explored three sample sizes. Because the pattern didn't change much for different sample sizes. Here we only show result for sample size 480. Then 3 numbers of levels were explored. Violation magnitude is d times parameters' asymptotic standard error. The larger the d is, the larger violation magnitude. The violation happens in the middle of the levels. These statistics were examined. 

15. In simulation 1, we explored this loading is excluded, but the violation paramater lambda 11 is included in the model. 

16. The result is like this. The y axis represents power, the x axis represents d. panel title represents the testing parameter and level. 
The first row is when testing parameter is lambda 11. We can see with increasing d, the power increases. Also the ordinal statistics have higher power than this categorical statistic, which is asymptotic equivalent to LRT. When we test all loadings in the second row, the same pattern here. 

17. And the other parameters like the correlations between factors, error variances and intercepts have power near 0. So we know the test can specifically detect the violation parameter lambda 11. 

18. In simulation 2, when we exclude this loading associated with scale 1 and also this loading is the violation one. 

19. The result is like this. The loading and error variances associated scale 1 demonstrated increasing power with increading violation magnitude. 

20. The correlation between factors and intercept associated with scale 1 have power near 0. 

21. The conlusion we can draw from simulation is that ordinal statistics have better power for detecting M.I. parameter specifically. And this feature is robust as long as the violation parameter is included in the model. Also the use of these tests are convenient because we don't need to compare full model and reduced model. I will show the procedure of how to implement in software. 

22. Software preparation, basically we need R. Model estimation can be carried out in lavaan package. The test statistic and plot is got from strucchange package. 
 
23. In this example, we use gratitude scale. It is completed by six age groups. sample size is over one thousand. LRT is always significant when sample size is large. 

24. After we input data, we only need to fit the constrained model. 

25. Then we use the sctest function to call these tests. In this example, the p value is larger than 0.05. If we use plot=TRUE here, 
we can generate the plot. 

26. The x-axis is the age group. The y-axis is the statistics for each group. If the statistic is larger than critical value--the red line, then we know M.I. assumption is violated. 

27. That's all. Thanks. Do you have any questions?



