%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Editing Rules:                                                            %
%1. Ed's comment and questions:\readme{}                                   %     
%2. Ting's comment and questions:\seeme{}                                  % 
%3. When comments and questions are resovled, the corresponding \readme or %  
%   \seeme will be removed by Ting.                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[doc]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm}
\usepackage[english]{babel}



\SweaveOpts{engine = R, eps = FALSE, echo = FALSE, pdf=TRUE}

\title{Score-based tests of measurement invariance: Use in practice}
\twoauthors{Ting Wang and Edgar C.\ Merkle}{Achim Zeileis}
\twoaffiliations{University of Missouri}{Universit\"{a}t Innsbruck}

\abstract{
We study a family of 
recently-proposed measurement invariance tests that are derived from
stochastic processes.  As applied to factor analysis and other
psychometric models, the tests are advantageous in that (i) they do
not require advance definition of subgroups of cases that violate
measurement invariance; (ii) they can potentially identify specific
model parameters that violate measurement invariance; and (iii) they
do not require a model of additional complexity to be estimated.  
Because the tests have been applied to only a small number of
psychometric examples, we conduct a series of simulation studies that provide
a detailed examination of test properties.  These studies allow us
to study (details here).  The studies indicate that.}




\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. 
  Correspondence to. 
  Email: }
\shorttitle{Measurement invariance test properties}
\rightheader{Measurement invariance test properties}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}
\newcommand{\seeme}[1]{\emph{\marginpar{SEEME} (#1)}}


\spacing{1}

\begin{document}
\maketitle

<<preliminaries1>>=
## packages
library("lavaan")
library("strucchange")
library("mvtnorm")
library("lattice")

## auxiliary code
source("simall.R")
source("mz.R")
source("../www/efpFunctional-cat.R")
source("../pkg/sctest.lavaan.R")

## turn off stars
options(show.signif.stars = FALSE)

## convenience function for plotting boundaries without color
get_boundary <- function(obj, fun, trim = 0) {
  bound <- fun$boundary(0:obj$nobs/obj$nobs)
  bound <- fun$computeCritval(0.05, ncol(obj$process)) * bound
  bound <- zoo(bound, time(obj$process))
  if(trim > 0) bound <- head(tail(bound, - floor(trim * obj$nobs)), - floor(trim * obj$nobs))
  return(bound)
}

## convenience function for applying tests to real data
info_full <- function(x, ...) solve(vcov(x) * nobs(x))
@

Parameter invariance is a fundamental assumption for measurement model in 
developing psychometric scales. Violation of it could happen in any estimated parameter.  
In order to fix the psychometric scale, we need to specify the violating parameter.  
Moreover, in practice model misspecification is an inevitable issue to a certain extent 
and may interfere with parameter invariance specificity. A family of tests derived from 
stochastic process has been recently proposed to identify specific parameters impacted 
by measurement invariance violation. However, these tests have only been used to a limited 
type of parameter violation. It is this paper's intent to provide a detailed examination 
of the tests' performance under practical research scenarios. 

In the following section, we first briefly review the 
theoretical framework of proposed statistical tests and
provide a short tutorial illustrating the use of the tests in R.
Next, we study the tests'
ability through simulations that mimic practical research. 
Finally, some suggestion on the tests' use in practice is provided.  

\section{Background}
This section contains background and discussion of the 
proposed statistics as applied to SEM; for a more detailed account, see
\citeA{MerZei13} and \citeA{MerFanZei}.  For details on the
statistics' application to general statistical models, see
\citeA{zeihor07}.

As currently implemented for SEM, the statistical tests described in
this paper can be applied to models that are estimated via a
multivariate normal or Wishart likelihood (or discrepancy) function,
with extension to other discrepancy functions being conceptually straightforward. 
The tests are carried out following model estimation, making use of output
associated with the fitted model.  In general, we fit a model that
restricts parameters to be equal across observations, then carry out a
posthoc test to examine whether specific parameters vary
across observations.  This procedure is similar in spirit to the
calculation of modification indices CITE and to Lagrange multiplier
tests CITE, and, in fact, those statistics can be viewed as  
special cases of the family described here.

Following model estimation, the tests primarily work on the {\em
  scores} of the fitted model; these are defined as
%% TODO indicate that this is evaluated at theta hat
\begin{equation}
\label{eq:score}
s(\hat{\theta};x_{i}) = \left ( \frac{\partial
      \ell(\theta;x_{i})}{\partial(\theta_{1})},...,\frac{\partial
      \ell(\theta;x_{i})}{\partial(\theta_{k})} \right )^{T},
\end{equation} 
where $\ell(\theta; x_i)$ is the likelihood associated with individual
$i$, $\theta$ is a $k$-dimensional parameter vector, and
$\hat{\theta}$ is the maximum likelihood estimate.  The cross-product
of these scores forms the ``meat'' for the calculation of robust
(Huber-White) standard errors. %TODO cite

To verbally describe the above equation, each
individual has $k$ scores describing the extent to which the fitted
model describes that particular individual.  Scores close to zero
indicate a ``good'' description, and scores far from zero indicate a
``bad'' description.  Each of an individual's $k$ scores represent one
model parameter, so that the scores provide specific information about
each parameter's fit to each individual.

To use these scores for testing, we order individuals according to
an auxiliary variable (the variable against which we are testing 
measurement invariance) and look for ``trends'' in the
scores.  For example, imagine that we are testing
for measurement 
invariance w.r.t.\ age.  If the manifest variables violate measurement
invariance here, then some parameter estimates may be too large for
young individuals and too small for old individuals (say).  This
result would be reflected in the scores, where young individuals'
scores may be greater than zero and old individuals' scores 
less than zero (though the sign of the scores will depend on whether a
function is being minimized or maximized).  Conversely, if measurement
invariance holds, then all 
individuals' scores will fluctuate around zero.

To formalize the ideas in the previous paragraph, we define a cumulative
sum of the ordered scores.  This cumulative sum may be written as
\begin{equation} 
    \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ %\hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n \cdot t \rfloor} {\bm s}(\hat {\bm \theta}; x_{(i)})
  \qquad (0 \le t \le 1)
\end{equation}
where $\lfloor nt \rfloor$ is the integer part of $nt$ (i.e., a floor
operator) and $x_{(i)}$ reflects the individual with the
$i^{\text{th}}$-smallest value of the auxiliary variable.
We specifically focus on how the
cumulative sum fluctuates as more individuals' scores are added to it,
starting with the youngest and ending with the oldest individual
(assuming that age is the auxiliary variable of interest).  
The summation is also typically premultiplied by the inverse square
root of the information matrix, which serves to decorrelate the
fluctuation processes associated with individual model parameters (i.e., the process associated with one parameter is not correlated with the processes associated with other parameters).

Under the
hypothesis of measurement invariance, a central limit theorem can be
used to show that the fluctuation of the above cumulative sum follows a
Brownian bridge.  This result allows us to calculate $p$-values and
critical values for test statistics under the hypothesis of
measurement invariance.  We can obtain test statistics associated with
all model parameters and with subsets of model parameters.

%% TODO focus on ordinal
Multiple test statistics are available, depending on how one
summarizes the behavior of the cumulative sum of scores.  For example, one could
take the absolute maximum that the cumulative sum attains for any
parameter of interest, resulting in a {\em double max} statistic (the maximum is taken across parameters and individuals).
Alternatively, one could sum the (squared) cumulative sum across parameters
of interest and take the maximum or the average across individuals, resulting in a {\em maximum Lagrange multiplier} statistic and Cram\'{e}r-von Mises statistic, respectively \cite<see>[for further discussion]{MerZei13}.  These statistics are given by
\begin{eqnarray}
    \label{eq:dmax}
    \mathit{DM} & = & \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} \\
        \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2.
\end{eqnarray}

Critical values associated with $\mathit{DM}$ can be obtained analytically, while critical values associated with the other statistics can be obtained from direct simulation \cite{Zei06} or from
more refined techniques \cite{han97}.  This issue should not be important to the user, as critical values are obtained directly from the R implementation described later.


Importantly, the above statistics were derived for situations where
individuals are uniquely ordered according to the auxiliary variable.
This is not always the case for measurement invariance applications,
where the auxiliary variable is often ordinal.  To remedy this
situation, \citeA{MerFanZei} extended the framework to situations
where one has an ordinal auxiliary variable of interest.  Essentially,
one allows all individuals with the same value of the auxiliary
variable to enter into the cumulative sum at the same time.  Analogous test 
statistics are then computed, with
modified critical values being adopted to reflect the change in the
statistics' computation.  

For an ordinal auxiliary variable with $m$ levels, these modifications are based on $t_{\ell}$ $(\ell=1,\ldots,m-1)$, which are the empirical, cumulative proportions of individuals observed at the first $m-1$ levels.
The modified statistics are then given by
\begin{eqnarray}
    \label{eq:wdm}
      \mathit{WDM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~ \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1/2}      
                             \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,\\
    \label{eq:maxlmo}
      \max \mathit{LM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~
                             \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
                             \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
where $i_{\ell}=\lfloor n \cdot t_{\ell} \rfloor$ $(\ell=1,\ldots,m-1)$.
Critical values associated with the $\mathit{WDM}_o$ statistic can be obtained directly from a multivariate normal distribution \cite<see>{hotzei08}, while critical values associated with $\max \mathit{LM}_o$ can be obtained via simulation.  This simulation is somewhat computationally intensive and, in practice, takes about 10 minutes on the authors' computers.  However, the wait appears to be worth it, as \citeA{MerFanZei} found the performance of the $\max \mathit{LM}_o$ statistic to be considerably better than the $\mathit{WDM}_o$ statistic.



\SweaveOpts{engine = R, eps = FALSE, echo = TRUE, pdf=TRUE}
\section{Tutorial}

In this section, we demonstrate how the above tests can be carried out in~R, using the package lavaan \cite{lavaan11} for model estimation and strucchange \cite{ZeiLei02,Zei06} for testing.  We use data from \citeA{FroFan11} concerning the applicability of adult gratitude scales to youth, available in the~R package psychotools CITE.  The data consist of responses to three adult gratitude scales from $n=1401$ youth aged 10--19 years. The original authors were specifically interested in whether the scales were measurement invariant across age.  Because the sample size at each age was unbalanced, the authors created age groups of approximately equal sample size.  In the examples below, we test for measurement invariance across these age groups.

We focus on measurement invariance of the factor loadings associated with the GQ-6 scale, using a one-factor model.
While the ``age group'' variable against which we are testing measurement invariance is best considered ordinal, for demonstration we consider its treatment as categorical, continuous, and ordinal.  Each of these treatments is described below in a separate section.

%% THE FOLLOWING DETAILS ARE REMOVED FOR NOW
%% In general, a set of scales is defined to be measurement invariant with respect
%% to an auxiliary variable $V$ if: 

%% \begin{equation}
%% \label{equ:invariance}
%% f(x_{i}|t_{i},v_{i},...)=f(x_{i}|t_{i},...),
%% \end{equation}

%% where $x_{i}$ is the data vector for individual $i$, $t_{i}$ is the latent variable 
%% for variable $i$ that the scales purport to measure, and $f$ is the model's 
%% distributional form \cite{mel89}. If the cut point of $v$ is known in advance, i.e. 
%% gender, nested multiple group models \cite{bollen98} coupled with likelihood ratio test 
%% are most commonly applied. Suppose there are two groups A and B. The null hypothesis 
%% of measurement invariance is 


%% \begin{equation}
%% \label{equ:null}
%% H_{0}: \theta_{A}=\theta_{B},
%% \end{equation}

%% The alternative hypothesis is 

%% \begin{equation}
%% \label{equ:alternative}
%% H_{1}:\theta_{i}=
%% \begin{cases}
%% \theta^{(A)} & v_{i}\leq v\\
%% \theta^{(B)} & v_{i}\geq v
%% \end{cases}
%% \end{equation}

%% The parameter estimate $\hat{\theta}^{(A)}$ , $\hat{\theta}^{(B)}$ ,$\hat{\theta}$ 
%% (group A and group B) can be obtained by Maximum Likelihood(ML) 
%% from observations $i=1,...m(v_{i}\leq v),i=m+1,...n(v_{i}\geq v), i=1,...,n$,
%% respectively. The LR test statistic for the given threshold $v$ is then 

%% \begin{equation}
%% \label{equ:LRT}
%% LR(v)=-2[\ell(\hat{\theta};x_{1},,,,x_{n})-{\ell(\hat{\theta}^
%% {(A)};x_{1},...,x_{m})+\ell(\hat{\theta}^{(B)};x_{m+1},...,x_{n})
%% }],
%% \end{equation}

%% ,which has an asymptotic $\chi^{2}$ distribution with degrees of freedom equal 
%% to the number difference of parameters in $\theta$. 


\subsection{Categorical Treatment}

\fixme{Need to update the citation below so that the last name is ``van de Schoot''.}
Measurement invariance is most often tested using multiple groups models \cite<see, e.g., >{vande12}.  This amounts to assuming that our auxiliary variable is categorical (i.e., unordered), which is not true for the age groups in the data.  However, we demonstrate the procedure for completeness.

To conduct the analysis, we first load the data and keep only complete cases for simplicity (though the tests can be applied to incomplete data).
<<data>>=
## Reading in the data
data("YouthGratitude",package="psychotools")

## remove cases with 'imputed' values(not in 1,...,9)
compcases <- apply(YouthGratitude[,4:28], 1, function(x) all(x %in% 1:9))
yg <- YouthGratitude[compcases,]
@
Next, we fit two models in lavaan: a one-factor model where loadings are restricted to be equal across age groups, and a one-factor model where loadings are free across age groups.
<<modest>>=
## Restricted model
reduced <- cfa('f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
             data=yg, group="agegroup", meanstructure=TRUE,
             group.equal="loadings")

## Unrestricted model
full <- cfa('f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
             data=yg, group="agegroup", meanstructure=TRUE)
@
Finally, we can get the results of a likelihood ratio test via the \verb+anova()+ function, which implies that the GQ-6 violates measurement invariance.
<<LRT>>=
## LRT
anova(full, reduced)
@
Because our sample size is large, this likelihood ratio test is sensitive to small measurement invariance violations \cite{Ben80}.  Thus, the above test may be significant solely due to the large sample size.  Additionally, the above test is sensitive to small measurement invariance violations that are not likely to be of interest to researchers.  For example, imagine that the 15-year-olds' parameters are slightly different than the other age groups.  The 15-year-olds are in the middle of the age groups, and there is not likely to be any theoretical justification for 15-year-olds differing from every other age group.  We need test statistics that are sensitive to measurement invariance violations that are monotonic with age.  The score-based statistics described previously possess this property.

%% TODO Illustrate catL2BB statistic?

\subsection{Continuous Treatment}
If we are interested in measurement invariance violations that are monotonic with the age groups, it is perhaps simplest to treat the age groups as continuous.  In doing so, we can use the statistics from Equations~\eqref{eq:dmax},~\eqref{eq:cvm}, and~\eqref{eq:maxlm}.  That is, we can fit a model whose parameters 
are restricted to be equal across across all individuals and then examine 
how individuals' scores $s(\hat{theta};x_{i})$ fluctuate with their
age (where age ties are broken arbitrarily).
This is demonstrated below, with similar code being useful when one is testing measurement invariance w.r.t.\ other continuous variables.


%% The multiple group test performs typically well when the $V$ 
%% is a relatively-small number of categories and the sample size 
%% is not too large. However, when $V$ (in this case, age) continuous variable, however, 
%% multiple-group analysis usually cannot be performed because there are 
%% no existing groups. Instead, we can follow the procedure described in
%% the Background section.

To proceed, we focus only on the restricted model that was fit in the previous section (the object \verb+reduced+).  We obtain scores associated with the factor loadings from this model, then test the fluctuation of these scores across \verb+agegroup+.  As demonstrated below, the score computation and testing can be efficiently carried out using \verb+sctest.lavaan()+.
%% Ting: I removed this because the model was already fit in the
%%       previous section
%%<<theta estimate>>=
%%theta<-cfa(
%%  'f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
%%  data=yg,group="agegroup",meanstructure=TRUE,
%%  group.equal="loadings")
%%@


<<Get Estimate>>=
dm <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="DM")
cvm <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="CvM")
maxlm <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLM")

c(dm$p.value, cvm$p.value, maxlm$p.value)
@
In the code above, the \verb+parm=1:4+ argument contains parameter numbers reflecting the factor loadings that we wish to test.  The ordering of parameters can be obtained via the command \verb+coef(reduced)+.  Two of the three $p$-values output at the end of the code are larger than that associated with the LRT (with the CvM statistic being non-significant).  

%% Aug 21: Ed stopped here.  TODO: graphs


\begin{figure}
\caption{Get Continuous Estimate DM Alternative Way}
\label{fig:conti1res}
\setkeys{Gin}{width=\textwidth}
<<conti1res, fig=TRUE, height=7, width=7>>=
DM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="DM", fplot=TRUE) 
DM
@
\end{figure}

\begin{figure}
\caption{Get Continuous Estimate CvM Alternative Way}
\label{fig:conti2res}
\setkeys{Gin}{width=\textwidth}
<<conti2res, fig=TRUE, height=7, width=7>>=
CvM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="CvM", fplot=TRUE) 
CvM
@
\end{figure}


<<conti3resmaxLM>>=
maxLM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLM", fplot=FALSE) 
maxLM
@
Since there are more than one observations located in each age level. 
So the observation order within each age level is not unique, thus, 
maxLM can't produce the plot. Actually, all three continuous statistics 
were calculated on the arbitrary order that particular dataset entered 
in each age level. In order to accurately account for the multiple observations 
at the same age level, it is more appropriate to use the proposed ordinal test.

\subsection{Ordinal Test}
As a matter of fact, there is only a partial ordering of individuals 
with respect to $V$,i.e. observations with the same level 
of $V$ have no unique ordering. The ordinal statistics 
proposed here are similar to those described in Equation 
and above, except that we focus on "bins" of individuals 
at each level of the ordinal variable.  

The difference between the continuous test and ordinal 
test is that we don't force arbitrary order on the observations 
within the same age groups. Therefore, this ordinal test should 
reflect more real status of the data. In terms of code, we still need the gefp 
function to get the B estimate. After that, we can use different 
functions to aggregate and scale B estimation. 
The function are called ordwmax and ol2bb1.fun, respectively. 
<<Ordinal Test>>=
gefp1<-gefp(reduced,fit=NULL,order.by=as.numeric(yg$agegroup),
       vcov=info_full,sandwich=FALSE,parm=1:4)
pval.ord=rep(NA,2)
pval.ord[1]<-sctest(gefp1,functional=ordwmax(gefp1))$p.value

if(file.exists("opval1.rda")){
  load("opval1.rda")
} else {
  opval1 <- ordL2BB(gefp1)
  save(opval1, file="opval1.rda")
}
pval.ord[2]<-sctest(gefp1, functional=opval1)$p.value
pval.ord
@

Or alternatively, we could use the sctest.lavaan function, but assign ordinal statistics.
\begin{figure}
\caption{Get Ordinal Estimate WDMo Alternative Way}
\label{fig:ord1res}
\setkeys{Gin}{width=\textwidth}
<<ord1res, fig=TRUE, height=7, width=7>>=
WDMo<-sctest(reduced, as.numeric(yg$agegroup),parm=1:4, stat="WDMo", fplot=TRUE)
WDMo 
@
\end{figure}

\begin{figure}
\caption{Get Ordinal Estimate maxLMo Alternative Way}
\label{fig:ord2res}
\setkeys{Gin}{width=\textwidth}
<<ord2res, fig=TRUE, height=7, width=7>>=
maxLMo<-sctest(reduced, as.numeric(yg$agegroup),parm=1:4, stat="maxLMo", 
               fnl=opval1, fplot=TRUE)
maxLMo 
@
\end{figure}



In employing the ordinal tests, we obtain $p=0.060$ and $p=0.096$. 
Both $p-$values are clearly larger than that of the 
likelihood ratio test and neither is significant at $\alpha=0.05$. 
This result is consistent with alternative fit indices used in Froh et al paper\citeA{FroFan11}.

\section{Simulation}
\section{Simulation 1}

In Simulation 1, we examined the extent



 to which the proposed tests
are sensitive to the specific model parameter that violates measurement
invariance.  If, say, a factor loading violates measurement
invariance, it is plausible that this violation impacts other
parameters such as factor covariances or other loadings 
associated with the factor in question.  Thus, the goal of the
simulation was to examine the extent to which the proposed tests
attribute the measurement invariance violation to the parameters that
are truly in violation.  

\subsection{Methods}
To examine these specificity issues, we generated data from a
two-factor model with three indicators each (the same model used in
Merkle and Zeileis, \citeyearNP{MerZei13}). The measurement invariance
violation occurred in one of three places: the factor loadings
 $\lambda_{11}--\lambda_{62}$, the unique variance associated
 $\epsilon_{11}--\epsilon_{66}$, or the factor covariance $\sigma_{12}$.  
We then tested for measurement invariance in seven subsets of parameters: the three
individual parameters noted above, all six factor loadings $\lambda_{11}--\lambda_{62}$, 
all six unique variances $\epsilon_{11}--\epsilon_{66}$. The path diagram is shown in  
Figure~\ref{fig:path}.

\begin{figure}
\caption{Path diagram representing the factor analysis model 
         used for simulations.}
\label{fig:path}
\includegraphics{PathDiagram}
\end{figure}

Power and Type I error were examined across three sample sizes
($n=120,480,960$) , three numbers of categories ($m=4,8,12$)and
7 magnitudes of invariance violations. 
The meaurement invariance violations began at level $1+m/2$ of $V$
and were consistant thereafter. These
violations were based on the auxiliary variable $V$: individuals below
the $1+m/2$ percentile of $V$ deviated from individuals above the $1+m/2$ 
percentile  by $d$ times the parameters' asymptotic standard errors
(scaled by $\sqrt n$), with $d=0,0,25,0.5,...,1.5$. 
For each combination of sample size ($n$) $\times$ violation
magnitude ($d$) $\times$ violating parameter $\times$ categories $m$, 5000 datasets were
generated and tested.Four statistics were examined above. In all conditions, we
maintained equal sample sizes at each level of the ordinal variable. 

\subsection{Results}

\section{General Discussion}

What do the results mean, future studies, etc.






\section*{Computational Details}

All results were obtained using the {R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on package
{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} for fitting 
of the factor analysis models and
{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. {R}~and the packages {lavaan} and 
{strucchange} are
freely available under the General Public License~2 from the
Comprehensive {R} Archive Network at \url{http://CRAN.R-project.org/}.
{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.


\bibliography{refs}

\end{document}
