%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Editing Rules:                                                            %
%1. Ed's comment and questions:\readme{}                                   %     
%2. Ting's comment and questions:\seeme{}                                  % 
%3. When comments and questions are resovled, the corresponding \readme or %  
%   \seeme will be removed by Ting.                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[doc]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm,float}
\usepackage[english]{babel}
\usepackage{tikz}

% Seems necessary for texlive 2012?
\usetikzlibrary{arrows}

\title{Score-based tests of measurement invariance: Use in practice}
\twoauthors{Ting Wang and Edgar C.\ Merkle}{Achim Zeileis}
\twoaffiliations{University of Missouri}{Universit\"{a}t Innsbruck}

\abstract{
In this paper, we consider a family of  recently-proposed measurement invariance
tests that are based on the {\em scores} of a fitted model.  This family can be used
to test for measurement invariance w.r.t.\ a continuous auxiliary variable,
without pre-specification of subgroups. Moreover, the family can be used when
one wishes to test for  measurement invariance w.r.t.\ an ordinal auxiliary
variable, yielding test statistics that are sensitive to violations that are
monotonically related to the ordinal variable (and less sensitive to
non-monotonic violations).  The paper is specifically aimed at potential users
of the tests who may wish to know (i) how the tests can be employed for their
data, and (ii) whether the tests can accurately identify specific models parameters that violate measurement invariance (possibly in the presence of model misspecification).  After providing an
overview of the tests, we illustrate their general use via the \proglang{R} packages \pkg{lavaan}
and \pkg{strucchange}.  We then describe two novel simulations that provide evidence
of the tests' practical abilities.  As a whole, the paper provides researchers
with the tools and knowledge needed to apply these tests to general measurement
invariance scenarios.
}

\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. 
  Correspondence to Edgar Merkle. 
  Email: merklee@missouri.edu.}
\shorttitle{Score-based tests in practice}
\rightheader{Score-based tests in practice}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
\let\proglang=\textsf
\let\pkg=\emph
\let\code=\texttt

%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{Ed} (#1)}}
\newcommand{\seeme}[1]{\emph{\marginpar{Ting} (#1)}}


\spacing{1}

\begin{document}
\maketitle

\include{Sweave}
\setkeys{Gin}{width=\textwidth}
<<preliminaries, echo=FALSE>>=
## packages
library("lavaan")
library("strucchange") ## at least 1.5-0
library("mvtnorm")
library("lattice")

## auxiliary code
source("../www/sim-frontiers.R")
source("../www/mz-frontiers.R")

## some options
options(prompt = "R> ", continue = "+  ", digits = 3,
  useFancyQuotes = FALSE, show.signif.stars = FALSE)
@

Many of the papers in this special issue focus on the topic of approximate
measurement invariance: we know that strict hypotheses of measurement invariance
do not hold exactly across different groups, and this should be reflected in
corresponding tests of measurement invariance.  Under a Bayesian
approach, we may utilize the idea of approximate invariance
\cite<e.g.,>{muthen13}, whereby across-group equality constraints on
parameters are replaced with informative prior distributions.  In this paper, we
describe an alternative approach: the development of test statistics that are
sensitive to invariance violations of interest and insensitive to ``anomalous''
invariance violations.  The test statistics are specifically applicable to
situations where one wishes to test for measurement invariance with respect to
an ordinal variable, and they are special cases of a family of tests that may
be used to study measurement invariance w.r.t.\ continuous,
categorical, and ordinal variables.

The family of tests described in this paper have recently been applied
to the study of measurement invariance \cite{MerZei13,MerFanZei}, though their
practical application has been limited to a small set of simulations and
datasets.  In this paper, we provide a detailed illustration of the tests' use
and performance under
scenarios likely to be encountered in practice. 
%In order to fix the psychometric scale, we need to specify the violating parameter.  
%Moreover, in practice model misspecification is an inevitable issue to a certain extent 
%and may interfere with parameter invariance specificity. A family of tests derived from 
%stochastic process has been recently proposed to identify specific parameters impacted 
%by measurement invariance violation. However, these tests have only been used to a limited 
%type of parameter violation. It is this paper's intent to provide a detailed examination 
%of the tests' performance under practical research scenarios. 
In the following sections, we first briefly review the  theoretical framework of
the proposed tests and provide a short tutorial illustrating the use of the
tests in \proglang{R} \cite{R11}. Next, we study the tests' performance in simulations that mimic
practical research scenarios.  Finally, we provide some further discussion on
the tests' use in practice.  


\section{Background}

This section contains background and discussion of the  proposed statistics as
applied to structural equation models (SEMs); for a more detailed account, see \citeA{MerZei13} and
\citeA{MerFanZei}.  For details on the statistics' application to general
statistical models, see \citeA{zeihor07}.

As currently implemented for SEM, the statistical tests described in
this paper can be applied to models that are estimated via a
multivariate normal or Wishart likelihood (or discrepancy) function,
with extension to other discrepancy functions being conceptually straightforward. 
The tests are carried out following model estimation, making use of output
associated with the fitted model.  In general, we fit a model that
restricts parameters to be equal across observations, then carry out a
posthoc test to examine whether specific parameters vary
across observations.  This procedure is similar in spirit to the
calculation of modification indices \cite{bentler90} and to Lagrange multiplier
tests \cite{sat89}, and, in fact, those statistics can be viewed as  
special cases of the family described here.

Following model estimation, the tests primarily work on the \emph{scores}
of the fitted model; these are defined as
%% TODO indicate that this is evaluated at theta hat
\begin{equation}
\label{eq:score}
s(\theta;x_{i}) = \left (
  \frac{\partial \ell(\theta;x_{i})}{\partial \theta_{1}}, \dots,
  \frac{\partial \ell(\theta;x_{i})}{\partial \theta_{k}} \right
  )^\top,\ i=1,\ldots,n,
\end{equation} 
where $\ell(\theta; x_i)$ is the likelihood associated with individual
$i$ and $\theta$ is a $k$-dimensional parameter vector. The corresponding
maximum likelihood estimate $\hat{\theta}$ solves the first order condition:
$\sum_{i = 1}^n s(\hat \theta;x_{i}) = 0$. The cross-product
of these scores forms the ``meat'' for the calculation of robust
(Huber-White) standard errors \cite<e.g.,>{zei06b}.

To verbally describe the above equation, each
individual has $k$ scores describing the extent to which the fitted
model describes that particular individual.  Scores close to zero
indicate a ``good'' description, and scores far from zero indicate a
``bad'' description.  Each of an individual's $k$ scores represent one
model parameter, so that the scores provide specific information about
each parameter's fit to each individual.

To use these scores for testing, we order individuals according to
an auxiliary variable $V$ (the variable against which we are testing 
measurement invariance) and look for ``trends'' in the
scores.  For example, imagine that we are testing
for measurement 
invariance w.r.t.\ age.  If the manifest variables violate measurement
invariance here, then some parameter estimates may be too large for
young individuals and too small for old individuals (say).  This
result would be reflected in the scores, where young individuals'
scores may be greater than zero and old individuals' scores 
less than zero (though the sign of the scores will depend on whether a
function is being minimized or maximized).  Conversely, if measurement
invariance holds, then all 
individuals' scores will fluctuate randomly around zero.

To formalize these ideas, we define a
suitably scaled cumulative sum of the ordered scores.  This may be written as
\begin{equation} 
    \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ \hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n \cdot t \rfloor} {\bm s}(\hat {\bm \theta}; x_{(i)})
  \qquad (0 \le t \le 1)
\end{equation}
where $\hat{\bm I}$ is an estimate of the information matrix, $\lfloor
nt \rfloor$ is 
the integer part of $nt$ (i.e., a floor 
operator), and $x_{(i)}$ reflects the individual with the
$i$-th smallest value of the auxiliary variable $V$.
We specifically focus on how the
cumulative sum fluctuates as more individuals' scores are added to it, e.g.,
starting with the youngest and ending with the oldest individual
if age is the auxiliary variable of interest.
The summation is premultiplied by an estimate of the inverse square
root of the information matrix, which serves to decorrelate the
fluctuation processes associated with individual model parameters.
Thus, the process associated with one parameter is not correlated 
with the processes associated with other parameters.

Under the
hypothesis of measurement invariance, a central limit theorem can be
used to show that the fluctuation of the above cumulative sum follows a
Brownian bridge.  This result allows us to calculate $p$-values and
critical values for test statistics under the hypothesis of
measurement invariance.  We can obtain test statistics associated with
all model parameters and with subsets of model parameters.

%% TODO focus on ordinal
Multiple test statistics are available, depending on how one
summarizes the behavior of the cumulative sum of scores.  For example, 
one could take the absolute maximum that the cumulative sum attains for any
parameter of interest, resulting in a {\em double max} statistic 
(the maximum is taken across parameters and individuals).
Alternatively, one could sum the (squared) cumulative sum across parameters
of interest and take the maximum or the average across individuals, resulting in a 
{\em maximum Lagrange multiplier} statistic and \emph{Cram\'{e}r-von Mises} statistic, respectively 
\cite<see>[for further discussion]{MerZei13}.  These statistics are given by
\begin{eqnarray}
    \label{eq:dmax}
    \mathit{DM} & = & \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} | \\
        \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2.
\end{eqnarray}
Critical values associated with $\mathit{DM}$ can be obtained analytically, 
while critical values associated with the other statistics can be obtained 
from direct simulation \cite{Zei06} or from more refined techniques \cite{han97}.  
This issue should not be important to the user, as critical values are obtained 
directly from the \proglang{R} implementation described later.


Importantly, the above statistics were derived for situations where
individuals are uniquely ordered according to the auxiliary variable.
This is not always the case for measurement invariance applications,
where the auxiliary variable is often ordinal.  To remedy this
situation, \citeA{MerFanZei} extended the framework to situations
where one has an ordinal auxiliary variable of interest.  Essentially,
one allows all individuals with the same value of the auxiliary
variable to enter into the cumulative sum at the same time.  Analogous test 
statistics are then computed, with
modified critical values being adopted to reflect the change in the
statistics' computation.  

For an ordinal auxiliary variable with $m$ levels, these modifications are 
based on $t_{\ell}$ $(\ell=1,\ldots,m-1)$, which are the empirical, cumulative 
proportions of individuals observed at the first $m-1$ levels.
The modified statistics are then given by
\begin{eqnarray}
    \label{eq:wdm}
      \mathit{WDM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~ \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1/2}      
                             \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,\\
    \label{eq:maxlmo}
      \max \mathit{LM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~
                             \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
                             \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
where $i_{\ell}=\lfloor n \cdot t_{\ell} \rfloor$ $(\ell=1,\ldots,m-1)$.
Critical values associated with the $\mathit{WDM}_o$ statistic can be obtained 
directly from a multivariate normal distribution \cite<see>{hotzei08}, while 
critical values associated with $\max \mathit{LM}_o$ can be obtained via simulation.  
This simulation is somewhat computationally intensive and, in practice, takes about 
10 minutes on the authors' computers when 50,000 replications are sampled from the 
approximate asymptotic distribution.  However, the wait is often worth it, 
as \citeA{MerFanZei} found the performance of the $\max \mathit{LM}_o$ statistic 
to have more power than the $\mathit{WDM}_o$ statistic and the traditional
likelihood ratio test statistic when the measurement invariance
violation is monotonic with the ordinal variable.

Finally, if the auxiliary variable $V$ is only nominal/categorical, the cumulative
sums of scores can be used to obtain a Lagrange multiplier statistic.
This test statistic can be formally written as
\begin{equation}
    \label{eq:lmuo}
     \mathit{LM}_{uo} = \sum_{\ell = 1, \dots, m} \sum_{j = 1, \dots, k}
       \left( {\bm B}(\hat {\bm \theta})_{i_\ell j} - {\bm B}(\hat {\bm \theta})_{i_{\ell - 1}j} \right)^2,
\end{equation}
where ${\bm B}(\hat {\bm \theta})_{i_{0}j} = 0$ for all $j$.
This statistic is asymptotically equivalent to the usual, likelihood
ratio test statistic, and it is advantageous over the likelihood ratio
test because it requires estimation of 
only one model (the restricted model).  We make use of this advantage in the
simulations, described later.



\section{Tutorial}

In this section, we demonstrate how the above tests can be carried out in \proglang{R}, 
using the package \pkg{lavaan} \cite{lavaan11} for model estimation and \pkg{strucchange} 
\cite{ZeiLei02,Zei06} for testing.  We use data from \citeA{FroFan11} concerning 
the applicability of adult gratitude scales to youth, available in the~\proglang{R} 
package \pkg{psychotools} \cite{zeilei12}.  The data consist of responses to three adult 
gratitude scales from $n=1401$ youth aged 10--19 years. The original authors 
were specifically interested in whether the scales were measurement invariant 
across age.  Because the sample size at each age was unbalanced, the authors 
created age groups of approximately equal sample size.  In the examples below, 
we test for measurement invariance across these age groups.

We focus on measurement invariance of the factor loadings associated with 
the GQ-6 scale, using a one-factor model. While the ``age group'' variable against 
which we are testing measurement invariance is best considered ordinal, 
for demonstration we consider its treatment as categorical, continuous, and ordinal.  
Each of these treatments is described below in a separate section.

%% THE FOLLOWING DETAILS ARE REMOVED FOR NOW
%% In general, a set of scales is defined to be measurement invariant with respect
%% to an auxiliary variable $V$ if: 

%% \begin{equation}
%% \label{equ:invariance}
%% f(x_{i}|t_{i},v_{i},...)=f(x_{i}|t_{i},...),
%% \end{equation}

%% where $x_{i}$ is the data vector for individual $i$, $t_{i}$ is the latent variable 
%% for variable $i$ that the scales purport to measure, and $f$ is the model's 
%% distributional form \cite{mel89}. If the cut point of $v$ is known in advance, i.e. 
%% gender, nested multiple group models \cite{bollen98} coupled with likelihood ratio test 
%% are most commonly applied. Suppose there are two groups A and B. The null hypothesis 
%% of measurement invariance is 


%% \begin{equation}
%% \label{equ:null}
%% H_{0}: \theta_{A}=\theta_{B},
%% \end{equation}

%% The alternative hypothesis is 

%% \begin{equation}
%% \label{equ:alternative}
%% H_{1}:\theta_{i}=
%% \begin{cases}
%% \theta^{(A)} & v_{i}\leq v\\
%% \theta^{(B)} & v_{i}\geq v
%% \end{cases}
%% \end{equation}

%% The parameter estimate $\hat{\theta}^{(A)}$ , $\hat{\theta}^{(B)}$ ,$\hat{\theta}$ 
%% (group A and group B) can be obtained by Maximum Likelihood(ML) 
%% from observations $i=1,...m(v_{i}\leq v),i=m+1,...n(v_{i}\geq v), i=1,...,n$,
%% respectively. The LR test statistic for the given threshold $v$ is then 

%% \begin{equation}
%% \label{equ:LRT}
%% LR(v)=-2[\ell(\hat{\theta};x_{1},,,,x_{n})-{\ell(\hat{\theta}^
%% {(A)};x_{1},...,x_{m})+\ell(\hat{\theta}^{(B)};x_{m+1},...,x_{n})
%% }],
%% \end{equation}

%% ,which has an asymptotic $\chi^{2}$ distribution with degrees of freedom equal 
%% to the number difference of parameters in $\theta$. 


\subsection{Categorical Treatment}

Measurement invariance is most often tested using multiple groups models \cite<see, e.g., >{vande12}.  
This amounts to assuming that our auxiliary variable is categorical (i.e., unordered), 
which is not true for the age groups in the data.  However, we demonstrate the procedure for completeness.

To conduct the analysis, we first load the data and keep only complete cases for simplicity 
(though the tests can be applied to incomplete data).
%
<<data>>=
data("YouthGratitude", package = "psychotools")
compcases <- apply(YouthGratitude[, 4:28], 1, function(x) all(x %in% 1:9))
yg <- YouthGratitude[compcases, ]
@
%
Next, we fit two models in \pkg{lavaan}: a one-factor model where loadings are restricted 
to be equal across age groups, and a one-factor model where loadings are free across age groups.
%
<<models>>=
restr <- cfa("f1 = ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5",
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = "loadings")
full <- cfa("f1= ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5",
  data = yg, group = "agegroup", meanstructure = TRUE)
@
%
Finally, we can get the results of a likelihood ratio test via the \code{anova()}
function, which implies that the GQ-6 violates measurement invariance.
<<LRT>>=
anova(full, restr)
@
To obtain the asymptotically equivalent $\mathit{LM}_\mathit{uo}$ (Equation~\eqref{eq:lmuo}), we
can use the \code{sctest()} function from \pkg{strucchange}:
<<LM_UO>>=
sctest(restr, order.by = yg$agegroup, parm = 1:4, vcov = "info",
  functional = "LMuo")
@
This command specifies that we assess the parameter 1--4 of
model \code{restr} after ordering the observations according to
\code{agegroup}.  Additionally, 
the observed information matrix is used as the variance-covariance matrix. Note
that the model parameters 1--4 are the factor loadings supplied by
\pkg{lavaan}, which can be seen by inspecting \code{coef(restr)}. This
also leads to somewhat 
smaller test statistics that are very close to being significant at the 5\% level.

Because our sample size is large, the likelihood ratio test is known to be sensitive to 
small measurement invariance violations \cite{Ben80}.  That is, the above tests 
are sensitive to small measurement invariance violations that are not likely to be 
of interest to researchers.  For example, imagine that the 15-year-olds' 
parameters are slightly different than the other age groups.  
The 15-year-olds are in the middle of the age groups, and there 
is not likely to be any theoretical justification for 15-year-olds 
differing from every other age group.  One solution to this problem would be the
Bayesian, approximate invariance methods described in the
introduction \cite{muthen13}.
Alternatively, we can use the proposed family of score-based statistics to obtain
tests that are sensitive to the ordering of age.



\subsection{Continuous Treatment}

If we are interested in measurement invariance violations that are 
monotonic with the age groups, it is perhaps simplest to treat the 
age groups as continuous.  In doing so, we can use the statistics 
from Equations~\eqref{eq:dmax}, \eqref{eq:cvm}, and~\eqref{eq:maxlm}.  
That is, we can fit a model whose parameters 
are restricted to be equal across all individuals and then examine 
how individuals' scores $s(\hat{\theta};x_{i})$ fluctuate with their
age (where age ties are broken arbitrarily, using the original order
of the observations within each age group).
This is demonstrated below, with similar code being useful when one is 
testing for measurement invariance w.r.t.\ truly continuous variables.


%% The multiple group test performs typically well when the $V$ 
%% is a relatively-small number of categories and the sample size 
%% is not too large. However, when $V$ (in this case, age) continuous variable, however, 
%% multiple-group analysis usually cannot be performed because there are 
%% no existing groups. Instead, we can follow the procedure described in
%% the Background section.

Again, we employ the \code{sctest()} function to assess parameters~1--4
from the restricted model \code{restr} after ordering w.r.t.\ \code{agegroup}:
%
<<sctest-cont>>=
dm <- sctest(restr, order.by = yg$agegroup, parm = 1:4, vcov = "info",
  functional = "DM")
cvm <- sctest(restr, order.by = yg$agegroup, parm = 1:4, vcov = "info",
  functional = "CvM")
maxlm <- sctest(restr, order.by = yg$agegroup, parm = 1:4,
  vcov = "info", functional = "maxLM")
c(dm$p.value, cvm$p.value, maxlm$p.value)
@
%
We see that two of the three $p$-values output at the end of the code are
larger than that associated with the LRT (with the CvM statistic being non-significant).  

The tests carried out here assume a unique ordering of individuals by age, but 
this is obviously not the case.  To compute the statistics and $p$-values, 
the \pkg{strucchange} package implicitly employed the (arbitrary) ordering of 
individuals who are tied on age.  If we were to change this ordering, 
the resulting statistics and $p$-values would also change, potentially
switching significant results to being non-significant and vice versa.
Clearly, this is problematic.  
To accurately account for the multiple observations  
at the same age level, we must use the ordinal tests from 
Equations~\eqref{eq:wdm} and~\eqref{eq:maxlmo}.  These are described next.

\subsection{Ordinal Treatment}

%% As a matter of fact, there is only a partial ordering of individuals 
%% with respect to $V$,i.e. observations with the same level 
%% of $V$ have no unique ordering. The ordinal statistics 
%% proposed here are similar to those described in Equation 
%% and above, except that we focus on "bins" of individuals 
%% at each level of the ordinal variable.  
The main difference between the ordinal test statistics and their
continuous counterparts is that the ordinal statistics are unchanged
when re-ordering individuals within the same age group.  To compute the test statistics, we allow
the scores of all tied individuals to enter the cumulative sum
(Equation~\eqref{eq:cumscore}) simultaneously.  This results in
modified critical values and test statistics that are sensitive to
measurement invariance violations that are monotonic w.r.t.\ age group.
%% Therefore, this ordinal test should 
%% reflect more real status of the data. In terms of code, we still need the gefp 
%% function to get the B estimate. After that, we can use different 
%% functions to aggregate and scale B estimation. 
%% The function are called ordwmax and ol2bb1.fun, respectively. 

To carry out the tests, we can rely on the same function that we used
for the continuous test statistics.  As mentioned previously,
calculation of the $\max\mathit{LM}_o$ statistic (Equation~\eqref{eq:maxlmo})
can be lengthy from the need to simulate critical values (though see
the end of this section, which provides a partial speed-up).
%% This is more complicated than necessary, but it is written like
%% this so that we can load the ordinal critical values behind the
%% scenes without confusing the reader.
<<sctest-ord1, echo=FALSE, results=hide>>=
set.seed(1090)
wdmo <- sctest(restr, order.by = yg$agegroup, parm = 1:4,
  vcov = "info", functional = "WDMo")

if(file.exists("maxLMo.rda")){
  load("maxLMo.rda")
} else {
  RNGkind(kind = "default", normal.kind = "default")
  set.seed(1090)
  maxLMo <- ordL2BB(yg$agegroup, nproc = 4)
  save(maxLMo, file = "maxLMo.rda")
}
maxlmo <- sctest(restr, order.by = yg$agegroup, parm = 1:4,
  vcov = "info", functional = maxLMo)
@ 
<<sctest-ord2, eval=FALSE,strip.white=all>>=
wdmo <- sctest(restr, order.by = yg$agegroup, parm = 1:4, vcov = "info",
  functional = "WDMo")
maxlmo <- sctest(restr, order.by = yg$agegroup, parm = 1:4,
  vcov = "info", functional = "maxLMo")
@ 
<<sctest-ord3,strip.white=all>>=
c(wdmo$p.value, maxlmo$p.value)
@ 
In computing the ordinal test statistics, we
obtain~$p=\Sexpr{round(wdmo$p.value, 3)}$
and~$p=\Sexpr{round(maxlmo$p.value, 3)}$, respectively.\footnote{To replicate
both $p$-values exactly, \proglang{R}'s random seed needs to be
set by \code{set.seed(1090)} prior to each \code{sctest()} call.}
Both $p$-values are clearly larger than that of the 
likelihood ratio test and neither is significant at $\alpha=0.05$. 
This provides evidence that there is no measurement
invariance violation that is monotonic with age group.  Instead, given
the large sample size, the likelihood ratio test may be overly
sensitive to anomalous, non-monotonic violations at one (or a few) age groups.

In addition to test statistics, ``instability plots'' can be generated
by setting 
\code{plot = TRUE} in the \code{sctest()} calls above. The resulting plots representing
the ordinal statistics' fluctuations across levels of age group are displayed in
Figure~\ref{fig:ordres}.
These plots display the loadings' fluctuation across age groups, with the x-axis
reflecting age group and the y-axis reflecting test statistic values (larger
values reflect more instability).  The dashed horizontal lines reflect critical values, so
that the hypothesis of measurement invariance is rejected if the sequence of
test statistics crosses the critical value.  While the measurement invariance tests are
non-significant, the plots imply some instability in the older age groups (15 and~16).

\begin{figure}
\caption{Fluctuation processes for the $\mathit{WDM}_o$ statistic (left panel) and the $\max\mathit{LM}_o$ statistic (right panel).}
\label{fig:ordres}
<<sctest-ord-graphics, fig=TRUE, height=4.5, width=9, echo=FALSE, results=hide>>=
par(mfrow = c(1, 2))
set.seed(1090)
sctest(restr, order.by = yg$agegroup, parm = 1:4, vcov = "info",
  functional = "WDMo", plot = TRUE, ylim = c(0, 3.2),
  xlab = "Age group", ylab = "Weighted test statistics",
  main = expression(WDM[o]), boundary = list(col = 1, lty = 2))
sctest(restr, order.by = yg$agegroup, parm = 1:4, vcov = "info",
  functional = maxLMo, plot = TRUE, ylim = c(0, 14),
  xlab = "Age group", ylab = "LM statistics",
  main = expression(maxLM[o]), boundary = list(col = 1, lty = 2))
@
\end{figure}

Finally, if the user anticipates multiple calculations of the
$\max\mathit{LM}_o$ statistic for a specific dataset, it is possible
to save time by simulating critical values once and re-using them for
multiple tests.  We can use the \code{ordL2BB()} function to generate
critical values and store them in an object \code{mLMo}, say.
Then, this object can be employed to obtain the test statistic in the usual manner.
<<ordsave, eval=FALSE>>=
mLMo <- ordL2BB(yg$agegroup)
maxlmo <- sctest(restr, order.by = yg$agegroup, parm = 1:4,
  vcov = "info", functional = mLMo)
@ 
The \code{ordL2BB()} command automatically generates critical values
for testing 1 to 20 parameters at a time. If only a smaller number
of parameters (e.g., only up to 6) is to be tested, some computation time can be
saved by setting the \code{nproc} argument accordingly (e.g., \code{nproc = 1:6}).
In the same way, \code{nproc} can be employed to simulate higher-dimensional
fluctuation processes suitable for testing more parameters. One can re-use
\code{mLMo} in this manner for further tests of the youth gratitude data.
Critical values must be resimulated for new data, however, because they depend on the
proportion of individuals observed at each level of the ordinal
variable (denoted $t_\ell$ for Equation~\eqref{eq:maxlmo}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the above sections, we have illustrated the score-based tests'
computation in \proglang{R}.  We suspect that the ordinal tests will be most
popular with users, because measurement invariance tests are typically
carried out across categories (ordered or not), as opposed to
continuous variables.  Thus, in the sections below, we conduct
novel simulations to study the ordinal statistics' expected behavior
in practice. 
In particular, we wish to study (i) the extent to which the
ordinal statistics attribute measurement invariance violations to the
correct parameter(s), and (ii) the extent to which the tests are
robust to model misspecification.  These issues are especially
important to examine because SEMs are typically complex, with many
inter-related parameters that may exhibit measurement invariance.
Previous applications of score-based tests have typically focused on
regression-like models with only a small number of parameters that
may exhibit instability \cite<e.g.,>{zeihor07}.  Thus, the simulations
here provide general evidence about the extent to which the tests accurately
capture instabilities in complex models.



\section{Simulation 1}
In Simulation 1, we examined the extent to which the proposed tests
are sensitive to the specific model parameter that violates measurement
invariance.  If, say, a factor loading violates measurement
invariance, it is plausible that this violation impacts other
parameter estimates, including factor covariances or the unique variance
associated with the manifest variable in question.  Thus, the goal of the
Simulation 1 is to examine the extent to which the proposed tests
attribute the measurement invariance violation to the parameters that
are truly in violation.  

\subsection{Methods}

To examine these issues, we generated data from a
two-factor model with three indicators each (see Figure~\ref{fig:path}).
The measurement invariance
violation occurred in one of three places: the factor loading associated with Scale 1 
 ($\lambda_{11}$), the unique variance associated with Scale 1
 ($\psi_{11}$), or the factor covariance $\phi_{12}$.  
 We then tested for measurement invariance in five subsets of parameters: each of the three
individual parameters noted above, all six factor loadings, % $\lambda_{11}--\lambda_{62}$, and 
and all six unique variances. % $\epsilon_{11}--\epsilon_{66}$.


%\begin{figure}
%\caption{Path diagram representing the factor analysis model 
%         used for simulations.}
%\label{fig:path}
%\includegraphics{PathDiagram}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Plot Code

\begin{figure}
    \caption{General model used for the simulations.}
    \label{fig:path}
\begin{tikzpicture}
[latent/.style={circle,draw=black!50,fill=white!20,thick,
                inner sep=0pt, minimum width=20mm, minimum height=10mm},
 manifest/.style={rectangle,draw=black!50,fill=white!20,thick,
                inner sep=0pt,minimum width=20mm, minimum height=10mm},
 error/.style={circle,draw=black!50,fill=white!20,thick,
                inner sep=0pt, minimum width=10mm},
 post/.style={->,shorten >=1pt,>=stealth',semithick},
 sling/.style={<->,shorten >=1pt,>=stealth',shorten <=1pt,>=stealth',auto,distance=20mm,semithick},
 errorsling/.style={<->,shorten >=1pt,>=stealth',shorten <=1pt,>=stealth',auto,distance=10mm,semithick}]



%position objects.

\node[latent] (VERBAL) at (0,4) {VERBAL};
\node[latent] (MATH)   at (0,0) {MATH};

\node[manifest] (SCALE1) at(5,6) {SCALE1};
\node[manifest] (SCALE2) at (5,4.5) {SCALE2};
\node[manifest] (SCALE3) at (5,3) {SCALE3};
\node[manifest] (SCALE4) at(5,1) {SCALE4};
\node[manifest] (SCALE5) at (5,-0.5) {SCALE5};
\node[manifest] (SCALE6) at (5,-2) {SCALE6};

\node[error] (E1) at (7,6) {E1};
\node[error] (E2) at (7,4.5) {E2};
\node[error] (E3) at (7,3) {E3};
\node[error] (E4) at (7,1) {E4};
\node[error] (E5) at (7,-0.5) {E5};
\node[error] (E6) at (7,-2) {E6};

%arrows, slings and texts
\node[latent] (VERBAL) at (0,4) {VERBAL}
   edge [post] node[above=0.01cm,text width=2cm]{\scriptsize{$\lambda_{11}=4.92$}} (SCALE1)
   edge [post] node[above=0.001mm,text width=2cm]{\scriptsize{$\lambda_{21}=2.96$}} (SCALE2)
   edge [post] node[above=0.1cm,text width=2cm]{\scriptsize{$\lambda_{31}=5.96$}} (SCALE3)
   edge [sling,bend right=100] node[auto,swap]{1}(VERBAL.-180)
   edge [sling,bend right=70] node[auto,swap]{$\phi_{12}=-0.48$}(MATH)  ;

\node[latent] (MATH) at (0,0) {MATH}
   edge [post] node[above=0.01cm,text width=2cm]{\scriptsize{$\lambda_{42}=3.24$}}(SCALE4)
   edge [post] node[above=0.01cm,text width=2cm]{\scriptsize{$\lambda_{52}=4.32$}}(SCALE5)
   edge [post] node[above=0.25cm,text width=2cm]{\scriptsize{$\lambda_{62}=7.21$}}(SCALE6)
   edge [sling,bend right=100] node[auto,swap]{1}(MATH.270);

\node[error] (E1) at (7,6) {E1}
   edge [post] node[auto,swap]{\small{1}}(SCALE1)
   edge [errorsling, bend right=100]node[right=0.1,text width=2cm]{\scriptsize{$\psi_{11}=26.77$}} (E1.45);
\node[error] (E2) at (7,4.5) {E2}
   edge [post] node[auto,swap]{\small{1}} (SCALE2)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{22}=13.01$}}(E2.45);
\node[error] (E3) at (7,3) {E3}
   edge [post] node[auto,swap]{\small{1}}(SCALE3)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{33}=30.93$}}(E3.45);
\node[error] (E4) at (7,1) {E4}
   edge [post] node[auto,swap]{\small{1}}(SCALE4)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{44}=3.17$}}(E4.45);
\node[error] (E5) at (7,-0.5) {E5}
   edge [post] node[auto,swap]{\small{1}}(SCALE5)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{55}=8.82$}} (E5.45);
\node[error] (E6) at (7,-2) {E6}
   edge [post] node[auto,swap]{\small{1}}(SCALE6)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{66}=22.5$}}(E6.45);

\end{tikzpicture}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Power and Type I error were examined across three sample sizes
($n=120,480,960$), three numbers of categories ($m=4,8,12$), and
17 magnitudes of invariance violations (described in the following sentences). 
The measurement invariance violations began at level $1+m/2$ of the
auxiliary variable $V$ and were consistent thereafter: individuals below
level $1+m/2$ of $V$ deviated from individuals at or above level $1+m/2$ 
by $d$ times the parameters' asymptotic standard errors
(scaled by $\sqrt n$), with $d=0,0.25,0.5,...,4$. 
For each combination of sample size ($n$) $\times$ violation
magnitude ($d$) $\times$ violating parameter $\times$ categories ($m$), 5000 datasets were
generated and tested.  Statistics from Equations~\eqref{eq:wdm}, \eqref{eq:maxlmo}
and~\eqref{eq:lmuo} were examined. As mentioned previously,
\eqref{eq:lmuo} is asymptotically equivalent to the usual likelihood
ratio test.  Thus, this statistic provides information about the
relative performance of the ordinal statistics vs.\ the LRT.  

In all conditions, we maintained equal sample 
sizes in each subgroup of the ordinal variable. 

\subsection{Results}

Full simulation results are presented in Figures~\ref{fig:sim11res}
to~\ref{fig:sim13res}.
Figure~\ref{fig:sim11res} displays power curves as a function of 
violation magnitude in the factor loading $\lambda_{11}$,
with the parameters being tested changing across rows,
the number of levels $m$ of the ordinal variable $V$ across columns,
and lines reflecting different test statistics.
Figures~\ref{fig:sim12res} and Figure~\ref{fig:sim13res} display 
similar power curves when the factor covariance 
$\phi_{12}$ and error variance $\epsilon_{11}$ violate measurement
invariance, respectively. In these figures, we generally show tests
associated with parameters that exhibited nonzero power curves.  For
example, in Figure~\ref{fig:sim11res}, the middle row shows that power
for tests of $\psi_{11}$ stays near zero for all values of $m$ and $d$.
Similar rows have been omitted from this figure and other figures.


Within each panel of Figure~\ref{fig:sim11res} to 
Figure~\ref{fig:sim13res}, the three lines reflect the three test
statistics.  It is seen that the two ordinal statistics exhibit 
similar results, with $\max\mathit{LM}_{uo}$ demonstrating lower power
across all situations.  This demonstrates the sensitivity of the
ordinal statistics to invariance violations that are monotonic with
$V$.  In situations where only one parameter is tested,
$\mathit{WDM}_o$  and $\max \mathit{LM}_o$ exhibit equivalent power
curves.  This is because, when only one parameter is tested, the
statistics are equivalent. 


From these figures, one generally observes that the tests isolate 
the parameter violating measurement invariance.  Additionally, the tests 
have somewhat higher power to detect measurement invariance violations 
in the factor loading and factor covariance parameters, as opposed to the error variance
parameter.  Finally, simultaneous tests of all factor loadings or all error
parameters result in decreased power, as compared to the situation
where one tests only the violating parameter.  This occurs because, in
testing a subset of parameters (only one of which violates measurement
invariance), we are effectively dampening the signal of a measurement
invariance violation. This ``dampening'' effect is more apparent for
the $\max \mathit{LM}_o$ statistic, because it involves a sum across
all tested parameters (see Equation~\eqref{eq:maxlmo}).
Conversely, $\mathit{WDM}_o$ takes the maximum over parameters
(Equation~\eqref{eq:wdm}), so that invariant parameters have no
impact on this statistic.

In summary, we found that the proposed tests can attribute
measurement invariance violations to the correct parameter.  This
provides evidence that, in practice, one can have confidence in the
tests' abilities to locate the measurement invariance violation.  Of
course, this statement is qualified by the fact that, in this
simulation, the model was correctly specified.  In the following
simulation, we examine the tests' performance in the likely situation
of model misspecification.

<<sim1,echo=FALSE>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim1.rda")) {
  load("sim1.rda")
} else {
  sim1 <- simulation(sim = "sim1", nobs = 480, parms = c("loading", "error", "var"))
  sim1$nlevels <- factor(sim1$nlevels)
  levels(sim1$nlevels) <- paste("m=", levels(sim1$nlevels), sep="")
 
  sim1$nobs <- factor(sim1$nobs)
  levels(sim1$nobs) <- paste("n=", levels(sim1$nobs), sep="")
  levels(sim1$test) <- c("maxLM_O", "WDM_O", "LM_uO")
  save(sim1, file="sim1.rda")
}
sim1$test <- factor(as.character(sim1$test),
  levels = c("ordmax", "ordwmax", "catdiff"),
  labels = c("maxLM_o", "WDM_o", "LM_uo"))
  parlabs <- c(expression(lambda[11]), expression(phi[12]), 
               expression(psi[11]),
	       expression(list(lambda[11], ldots, lambda[62])), 
               expression(list(psi[11], ldots, psi[66])))
  levels(sim1$pars) <- c("Loading1", "Covariance", "Error1", "All Loadings", "All Errors")  
@

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and
$\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 1. The parameter violating measurement 
invariance is $\lambda_{11}$.  Panel labels denote the parameter(s)
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim11res}
<<sim11res, fig=TRUE, height=7, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim1,
       subset = (parms == "loading" & 
		 pars %in% c("Loading1", "Error1", "All Loadings") & diff %% 0.5 == 0),
       type = "b", xlab = expression(paste("Violation Magnitude (", lambda[11], ")")),
       ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
           if(which.given == 2){
             strip.default(which.given, factor.levels = parlabs[c(1, 3, 4)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and
$\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$,
  and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 1. The
parameter violating measurement invariance is $\phi_{12}$. Panel
labels denote the parameter(s)  
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim12res}
<<sim12res, fig=TRUE, height=4.5, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim1,
       subset = (parms == "var" & 
		 pars %in% c("Covariance") & diff %% 0.5 == 0),
       type = "b", xlab = expression(paste("Violation Magnitude (", phi[12], ")")),
       ylab="Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(2)],...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 1. The
parameter violating measurement invariance is $\psi_{11}$. Panel labels
denote the parameter(s) 
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim13res}
<<sim13res, fig=TRUE, height=7, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim1,
       subset = (parms == "error" & 
		 pars %in% c("Error1", "All Errors") & diff %% 0.5 == 0),
       type = "b", xlab = expression(paste("Violation Magnitude (", psi[11], ")")),
       ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(3,5)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}




\section{Simulation 2}
In Simulation 2, we examine the extent to which the results of
Simulation 1 are robust to model misspecification.  Specifically, we
generate data from the factor analysis model used in the previous
section, except that the model contains an extra loading from the
second factor to Scale 1.
The estimated model matches that displayed in Figure~\ref{fig:path},
however, resulting in model misspecification.  The goal of this
simulation is to examine the proposed statistics' 
power to detect measurement invariance violations (and to attribute
the violation to the correct parameter) under this misspecification.

\subsection{Method}
A measurement invariance violation could occur in
each of the three parameters from Simulation 1 (factor loading, factor
covariance, and unique variance), and a violation could also occur in
the extra, unmodeled loading. In each condition, a single parameter
exhibited the violation. 
Sample size and magnitude of measurement invariance violation were manipulated 
in the same way as they were in Simulation 1.  The tested parameters
were also the same as Simulation 1.

\subsection{Results}
Results of
primary interest are conditions where the unmodeled loading violates
measurement invariance.  A subset of results is displayed in Figure~\ref{fig:sim21res}.  One can generally observe
that tests of the first loading and unique variance exhibited high
``power,'' which is actually a high Type I error rate here.  This Type
I error also demonstrated when testing all loadings and all unique
variances, as shown in the appendix.  Tests
associated with the factor 
covariance did not demonstrate this error, however.  In
terms of specific 
statistic performance, $\max \mathit{LM}_o$ and $\mathit{WDM}_o$ 
demonstrated higher Type I error than $\mathit{LM}_{uo}$ in each panel,
especially with increasing levels.  This is likely because the unmodeled
loading's non-invariance was monotonic with $V$; if it were not monotonic, we
would expect $\mathit{LM}_{uo}$ to have higher Type I error. 


When the parameter violating measurement invariance was modeled,
results were generally the same as Simulation 1.  
When the modeled factor loading, $\lambda_{11}$, violated measurement
invariance, the statistics were generally able to pick up the violation despite
the misspecification. Similar results were observed
when the unique variance and factor covariance parameters violated measurement
invariance; these results are all shown in the Appendix.
In particular, the power of ordered statistics $\max \mathit{LM}_o$ test and
$\mathit{WDM}_o$ test showed higher power than unordered $\mathit{LM}_{uo}$ in
each of these panels. 

In summary, the proposed test statistics appear robust to unmodeled
loading parameters, so long 
as the unmodeled loading does not violate measurement invariance.  If
the unmodeled loading  
does violate measurement invariance, the tests can still detect
measurement invariance violations.  The violations are assigned to 
modeled parameters that do not violate measurement invariance, however.
The impacted parameters include the error 
variance and other loadings associated with the manifest variable that
has an unmodeled loading.
Thus, as for other tests of measurement invariance, it is important to
study the extent to 
which the hypothesized model includes all parameters of importance.
None of these tests (score-based or otherwise) inform the researcher of
model misspecification.

<<sim2,echo=FALSE>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim2.rda")) {
  load("sim2.rda")
} else {
  sim2 <- simulation(sim = "sim2", nobs = 480, 
  parms = c("extra", "extra+loading", "extra+var", "extra+error"))

  save(sim2, file="sim2.rda")
}
sim2$test <- factor(as.character(sim2$test),
  levels = c("ordmax", "ordwmax", "catdiff"),
  labels = c("maxLM_o", "WDM_o", "LM_uo"))
  sim2$nlevels <- factor(sim2$nlevels)
  levels(sim2$nlevels) <- paste("m=", levels(sim2$nlevels), sep="")
  sim2$nobs <- factor(sim2$nobs)
  levels(sim2$nobs) <- paste("n=", levels(sim2$nobs), sep="")
  parlabs <- c(expression(lambda[11]), expression(phi[12]), 
               expression(psi[11]),
	       expression(list(lambda[11], ldots, lambda[62])), 
               expression(list(psi[11], ldots, psi[66])))
  levels(sim2$pars) <- c("Loading1", "Covariance", "Error1", "All Loadings", "All Errors") 

@ 



\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 2. The
parameter violating measurement invariance is the unmodeled
loading. Panel labels denote the parameter(s) 
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim21res}
<<sim21res, fig=TRUE, height=9, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
       subset = (parms == "extra" & 
		 pars %in% c("Loading1", "Covariance", "Error1") & diff %% 0.5 == 0),
       type = "b", xlab = "Violation Magnitude (Unmodeled Loading)",
       ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(1, 2, 3)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}


\section{General Discussion}


In this paper, we first described a novel family of test statistics
for measurement invariance and illustrated their use via the
\proglang{R} packages \pkg{lavaan} and \pkg{strucchange}.  Next, we examined these
statistics' abilities to identify the parameter violating measurement
invariance under well-specified and misspecified models.  We found
that the
proposed statistics could generally isolate the model parameter
violating measurement invariance, so long as the violating parameter
is included in the model. 

In the remainder of the paper, we first compare
these tests to traditional tests of measurement invariance.  We then 
discuss test extension to other fit functions and to other specialized
models. 


\subsection{Applications}

Many of the applications in this volume, along with many measurement
invariance applications in
general, focus on testing across unordered categories
such as nations or gender.  As discussed earlier in this paper, the score-based
tests for unordered categories are essentially equivalent to the usual
likelihood ratio test.  Given a measurement invariance violation across these
unordered categories, however, researchers typically wish to know why the
violation occurred.  At this point, researchers may examine education level,
socioeconomic status, income levels, and so on across the unordered categories. 
These variables are often ordinal or continuous in nature, so that the family of
tests described in this paper are applicable.  This is a first step towards
describing why measurement invariance violations occur, as opposed to simply
detecting measurement invariance violations. 
%% TODO!!
%\readme{In the abstracts for the
%special issue (which the special editors sent us), one paper was proposed along
%these lines.  I will get a draft of that paper and then we can cite it here.}
The tests described here are convenient for this purpose, as they do
not require a new model to 
be estimated for each ordinal variable.  Instead, each ordinal variable defines
an ordering of observations, which in turn yields a test statistic that is
specific to that ordinal variable.

%% I'm not sure we want to make a big deal of this.  If there are only a small number of ties, we are probably better off with the continuous tests:
%These ordinal tests are useful in behavioral and social science in general, since the truly continuous auxiliary variable is hard to find in real research context. It is very common to observe several individuals with the same age, IQ, income rank, etc. Therefore, the ordinal tests which dealing with multiple ties in auxiliary variable is more suitable than the continuous test. 

%Moreover, even though researchers might be originally interested in comparing categorical differences. For example, researchers might want to test whether there is gender difference or cultural difference for the scale. Using traditional likelihood test or wald test, there might existing some differences regarding to the categorical variable. Then the next natural question would be why there is gender or culture differences? . Thus these test statistics offer an convenient assessing tool to further exploring research hypothesis without making complicated assumptions or fitting multiple different models.

\subsection{Extension}

In this paper, we focused on testing for measurement invariance in factor
analysis models that assume multivariate normality and that are estimated via
maximum likelihood (ML).  The family of tests described here generally apply to estimation methods
that maximize/minimize a fit function, however \cite<see>{zeihor07}, so they are
potentially applicable to alternative SEM discrepancy functions such
as generalized 
least squares \cite<e.g.,>{broarm95}.  Score calculation for these alternative
discrepancy functions has not been implemented (to our knowledge), though the
calculation could be implemented.  Test statistic calculation and
inference would then proceed in exactly the same manner as the calculation and
inference illustrated in this paper.

In addition to alternative fit functions, the tests can be extended to other
models estimated via ML.  Of primary interest to the topic of measurement
invariance, the tests can be extended to item response models to examine
differential item functioning.  In particular, \citeA{strkop13} studied
application of these tests to the Rasch model, using them as the basis of a
recursive partioning procedure that segments subgroups of individuals who
exhibit DIF.  Further study and extension of these tests for IRT seem warranted.

% Removed for now:
%% \subsection{Conclusion}
%% \readme{Not sure whether we need this paragraph, but I still need to think about it.}
%% In summary, the ordinal test statistic proposed have relatively-high power for detecting measurement invariance violation parameter specifically that are monotonic with the auxiliary ordinal variable. This
%% feature is robust as long as the violation parameter is included in the testing model. Furthermore, as illustrated in tutorial part, the use of these tests is convenient without changing the focal psychometric model. In all, the tests have advantageous properties that should be implemented in practice.


\section*{Computational Details}

All results were obtained using the \proglang{R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on package
\pkg{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} for fitting 
of the factor analysis models and
\pkg{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. \proglang{R}~and both
packages are freely available under the General Public License~2 from the
Comprehensive \proglang{R} Archive Network at \url{http://CRAN.R-project.org/}.
\proglang{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.


\bibliography{refs}

\section{Appendix}

This Appendix contains additional results from Simulation 2, where there existed
model misspecification (lacking one loading from Scale 1 to
Math). Figure~\ref{fig:sim22res} to Figure~\ref{fig:sim25res} display
results when the unmodeled loading, the loading $\lambda_{11}$, the
covariance $\phi_{12}$, and the error term $\psi_{11}$ violate
invariance, respectively.  Results are only shown for simulation
conditions exhibiting power curves that increased from zero.  These
results were generally the same as the Simulation 1 results.

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 2. The
parameter violating measurement invariance is the unmodeled
loading. Panel labels denote the parameter(s) 
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim22res}
<<sim22res, fig=TRUE, height=7, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
       subset = (parms == "extra" & 
		 pars %in% c("All Loadings", "All Errors") & diff %% 0.5 == 0),
       type = "b", xlab = "Violation Magnitude (Unmodeled Loading)", ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(4, 5)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 2. The
parameter violating measurement invariance is $\lambda_{11}$.  Panel
labels denote the parameter(s)  
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim23res}
<<sim23res, fig=TRUE, height=7, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
       subset = (parms=="extra+loading" & 
		 pars %in% c("Loading1", "All Loadings") & diff %% 0.5 == 0),
       type = "b", xlab = expression(paste("Violation Magnitude (", lambda[11], ")")), ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(1, 4)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 2. The
parameter violating measurement invariance is $\phi_{12}$.  Panel
labels denote the parameter  
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim24res}
<<sim24res, fig=TRUE, height=4.5, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
       subset = (parms=="extra+var" & 
		 pars %in% c("Covariance") & diff %% 0.5 == 0),
       type = "b", xlab = expression(paste("Violation Magnitude (", phi[12], ")")),
       ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(2, 4:5)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$, $\mathit{WDM}_o$, and $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$), Simulation 2. The
parameter violating measurement invariance is $\psi_{11}$.  Panel
labels denote the parameter(s)  
being tested and the number of levels of the ordinal variable $m$.}
\label{fig:sim25res}
<<sim25res, fig=TRUE, height=7, width=9, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
       subset = (parms == "extra+error" & 
		 pars %in% c("Error1", "All Errors") & diff %% 0.5 == 0),
       type = "b", xlab = expression(paste("Violation Magnitude (", psi[11], ")")),
       ylab = "Power", key = mykey, as.table = TRUE,
       strip = function(..., which.given, factor.levels){
	   if(which.given == 2){
	       strip.default(which.given, factor.levels = parlabs[c(3,5)], ...)
	   } else {
	       strip.default(which.given, factor.levels = factor.levels, ...)
	   }
       })
@

\end{figure}

\end{document}
