%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Editing Rules:                                                            %
%1. Ed's comment and questions:\readme{}                                   %     
%2. Ting's comment and questions:\seeme{}                                  % 
%3. When comments and questions are resovled, the corresponding \readme or %  
%   \seeme will be removed by Ting.                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[doc]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm,float}
\usepackage[english]{babel}






\title{Score-based tests of measurement invariance: Use in practice}
\twoauthors{Ting Wang and Edgar C.\ Merkle}{Achim Zeileis}
\twoaffiliations{University of Missouri}{Universit\"{a}t Innsbruck}

\abstract{
We study a family of 
recently-proposed measurement invariance tests that are derived from
stochastic processes.  As applied to factor analysis and other
psychometric models, the tests are advantageous in that (i) they do
not require advance definition of subgroups of cases that violate
measurement invariance; (ii) they can potentially identify specific
model parameters that violate measurement invariance; and (iii) they
do not require a model of additional complexity to be estimated.  
Because the tests have been applied to only a small number of
psychometric examples, we conduct a series of simulation studies that provide
a detailed examination of test properties.  These studies allow us
to study (details here).  The studies indicate that.}


\SweaveOpts{engine = R, eps = FALSE, echo = FALSE, pdf=TRUE}

\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. 
  Correspondence to. 
  Email: }
\shorttitle{Measurement invariance test properties}
\rightheader{Measurement invariance test properties}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}
\newcommand{\seeme}[1]{\emph{\marginpar{SEEME} (#1)}}


\spacing{1}

\begin{document}
\maketitle

<<preliminaries1>>=
## packages
library("lavaan")
library("strucchange")
library("mvtnorm")
library("lattice")

## auxiliary code
source("simall-ordinal.R")
source("mz.R")
source("../www/efpFunctional-cat.R")
source("../pkg/sctest.lavaan.R")
source("../www/mz-ordinal.R")
source("../www/estfun-lavaan.R")


## turn off stars
options(show.signif.stars = FALSE)

## convenience function for plotting boundaries without color
get_boundary <- function(obj, fun, trim = 0) {
  bound <- fun$boundary(0:obj$nobs/obj$nobs)
  bound <- fun$computeCritval(0.05, ncol(obj$process)) * bound
  bound <- zoo(bound, time(obj$process))
  if(trim > 0) bound <- head(tail(bound, - floor(trim * obj$nobs)), - floor(trim * obj$nobs))
  return(bound)
}

## convenience function for applying tests to real data
info_full <- function(x, ...) solve(vcov(x) * nobs(x))
@

Parameter invariance is a fundamental assumption for measurement model in 
developing psychometric scales. Violation of it could happen in any estimated parameter.  
In order to fix the psychometric scale, we need to specify the violating parameter.  
Moreover, in practice model misspecification is an inevitable issue to a certain extent 
and may interfere with parameter invariance specificity. A family of tests derived from 
stochastic process has been recently proposed to identify specific parameters impacted 
by measurement invariance violation. However, these tests have only been used to a limited 
type of parameter violation. It is this paper's intent to provide a detailed examination 
of the tests' performance under practical research scenarios. 

In the following section, we first briefly review the 
theoretical framework of proposed statistical tests and
provide a short tutorial illustrating the use of the tests in R.
Next, we study the tests'
ability through simulations that mimic practical research. 
Finally, some suggestion on the tests' use in practice is provided.  

\section{Background}
This section contains background and discussion of the 
proposed statistics as applied to SEM; for a more detailed account, see
\citeA{MerZei13} and \citeA{MerFanZei}.  For details on the
statistics' application to general statistical models, see
\citeA{zeihor07}.

As currently implemented for SEM, the statistical tests described in
this paper can be applied to models that are estimated via a
multivariate normal or Wishart likelihood (or discrepancy) function,
with extension to other discrepancy functions being conceptually straightforward. 
The tests are carried out following model estimation, making use of output
associated with the fitted model.  In general, we fit a model that
restricts parameters to be equal across observations, then carry out a
posthoc test to examine whether specific parameters vary
across observations.  This procedure is similar in spirit to the
calculation of modification indices \cite{bentler90} and to Lagrange multiplier
tests \cite{sat89}, and, in fact, those statistics can be viewed as  
special cases of the family described here.

Following model estimation, the tests primarily work on the {\em
  scores} of the fitted model; these are defined as
%% TODO indicate that this is evaluated at theta hat
\begin{equation}
\label{eq:score}
s(\hat{\theta};x_{i}) = \left ( \frac{\partial
      \ell(\theta;x_{i})}{\partial(\theta_{1})},...,\frac{\partial
      \ell(\theta;x_{i})}{\partial(\theta_{k})} \right )^{T},
\end{equation} 
where $\ell(\theta; x_i)$ is the likelihood associated with individual
$i$, $\theta$ is a $k$-dimensional parameter vector, and
$\hat{\theta}$ is the maximum likelihood estimate.  The cross-product
of these scores forms the ``meat'' for the calculation of robust
(Huber-White) standard errors \cite{freed06}. \seeme{not sure about this citation}

To verbally describe the above equation, each
individual has $k$ scores describing the extent to which the fitted
model describes that particular individual.  Scores close to zero
indicate a ``good'' description, and scores far from zero indicate a
``bad'' description.  Each of an individual's $k$ scores represent one
model parameter, so that the scores provide specific information about
each parameter's fit to each individual.

To use these scores for testing, we order individuals according to
an auxiliary variable (the variable against which we are testing 
measurement invariance) and look for ``trends'' in the
scores.  For example, imagine that we are testing
for measurement 
invariance w.r.t.\ age.  If the manifest variables violate measurement
invariance here, then some parameter estimates may be too large for
young individuals and too small for old individuals (say).  This
result would be reflected in the scores, where young individuals'
scores may be greater than zero and old individuals' scores 
less than zero (though the sign of the scores will depend on whether a
function is being minimized or maximized).  Conversely, if measurement
invariance holds, then all 
individuals' scores will fluctuate around zero.

To formalize the ideas in the previous paragraph, we define a cumulative
sum of the ordered scores.  This cumulative sum may be written as
\begin{equation} 
    \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ %\hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n \cdot t \rfloor} {\bm s}(\hat {\bm \theta}; x_{(i)})
  \qquad (0 \le t \le 1)
\end{equation}
where $\lfloor nt \rfloor$ is the integer part of $nt$ (i.e., a floor
operator) and $x_{(i)}$ reflects the individual with the
$i^{\text{th}}$-smallest value of the auxiliary variable.
We specifically focus on how the
cumulative sum fluctuates as more individuals' scores are added to it,
starting with the youngest and ending with the oldest individual
(assuming that age is the auxiliary variable of interest).  
The summation is also typically premultiplied by the inverse square
root of the information matrix, which serves to decorrelate the
fluctuation processes associated with individual model parameters 
(i.e., the process associated with one parameter is not correlated 
with the processes associated with other parameters).

Under the
hypothesis of measurement invariance, a central limit theorem can be
used to show that the fluctuation of the above cumulative sum follows a
Brownian bridge.  This result allows us to calculate $p$-values and
critical values for test statistics under the hypothesis of
measurement invariance.  We can obtain test statistics associated with
all model parameters and with subsets of model parameters.

%% TODO focus on ordinal
Multiple test statistics are available, depending on how one
summarizes the behavior of the cumulative sum of scores.  For example, 
one could take the absolute maximum that the cumulative sum attains for any
parameter of interest, resulting in a {\em double max} statistic 
(the maximum is taken across parameters and individuals).
Alternatively, one could sum the (squared) cumulative sum across parameters
of interest and take the maximum or the average across individuals, resulting in a 
{\em maximum Lagrange multiplier} statistic and Cram\'{e}r-von Mises statistic, respectively 
\cite<see>[for further discussion]{MerZei13}.  These statistics are given by

\begin{eqnarray}
    \label{eq:dmax}
    \mathit{DM} & = & \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} \\
        \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2.
\end{eqnarray}

Critical values associated with $\mathit{DM}$ can be obtained analytically, 
while critical values associated with the other statistics can be obtained 
from direct simulation \cite{Zei06} or from more refined techniques \cite{han97}.  
This issue should not be important to the user, as critical values are obtained 
directly from the R implementation described later.


Importantly, the above statistics were derived for situations where
individuals are uniquely ordered according to the auxiliary variable.
This is not always the case for measurement invariance applications,
where the auxiliary variable is often ordinal.  To remedy this
situation, \citeA{MerFanZei} extended the framework to situations
where one has an ordinal auxiliary variable of interest.  Essentially,
one allows all individuals with the same value of the auxiliary
variable to enter into the cumulative sum at the same time.  Analogous test 
statistics are then computed, with
modified critical values being adopted to reflect the change in the
statistics' computation.  

For an ordinal auxiliary variable with $m$ levels, these modifications are 
based on $t_{\ell}$ $(\ell=1,\ldots,m-1)$, which are the empirical, cumulative 
proportions of individuals observed at the first $m-1$ levels.
The modified statistics are then given by
\begin{eqnarray}
    \label{eq:wdm}
      \mathit{WDM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~ \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1/2}      
                             \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,\\
    \label{eq:maxlmo}
      \max \mathit{LM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~
                             \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
                             \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
where $i_{\ell}=\lfloor n \cdot t_{\ell} \rfloor$ $(\ell=1,\ldots,m-1)$.
Critical values associated with the $\mathit{WDM}_o$ statistic can be obtained 
directly from a multivariate normal distribution \cite<see>{hotzei08}, while 
critical values associated with $\max \mathit{LM}_o$ can be obtained via simulation.  
This simulation is somewhat computationally intensive and, in practice, takes about 
10 minutes on the authors' computers.  However, the wait appears to be worth it, 
as \citeA{MerFanZei} found the performance of the $\max \mathit{LM}_o$ statistic 
to be considerably better than the $\mathit{WDM}_o$ statistic.

%% TODO Illustrate catL2BB statistic

If $V$ is only nominal/categorical,
there is not even a partial ordering, i.e., measurement invariance tests should neither
exploit the ordering of $V$'s levels nor of the observations within the level.
In this situation, unordered $\mathit{LM}$ is proposed.  This test statistic can be formally written as
\begin{equation}
    \label{eq:lmuo}
     \mathit{LM}_\mathit{uo} = \sum_{\ell = 1, \dots, m} \sum_{j = 1, \dots, k}
       \left( {\bm B}(\hat {\bm \theta})_{i_\ell j} - {\bm B}(\hat {\bm \theta})_{i_{\ell - 1}j} \right)^2,
\end{equation}
This test statistic discards the ordinal nature of the auxiliary
variable, essentially similar to the nature of likelihood ratio tests (or,
equivalently, via Wald tests or Lagrange multiplier tests): the ordinality of the auxiliary variable is
ignored. By contrast, this statistics is easier to get compared to likelihood ratio test statistics since it doesn't involve specifying different sets of competitive models. 

\SweaveOpts{engine = R, eps = FALSE, echo = TRUE, pdf=TRUE}
\section{Tutorial}

In this section, we demonstrate how the above tests can be carried out in~R, 
using the package lavaan \cite{lavaan11} for model estimation and strucchange 
\cite{ZeiLei02,Zei06} for testing.  We use data from \citeA{FroFan11} concerning 
the applicability of adult gratitude scales to youth, available in the~R 
package psychotools \cite{zeilei11}.  The data consist of responses to three adult 
gratitude scales from $n=1401$ youth aged 10--19 years. The original authors 
were specifically interested in whether the scales were measurement invariant 
across age.  Because the sample size at each age was unbalanced, the authors 
created age groups of approximately equal sample size.  In the examples below, 
we test for measurement invariance across these age groups.

We focus on measurement invariance of the factor loadings associated with 
the GQ-6 scale, using a one-factor model. While the ``age group'' variable against 
which we are testing measurement invariance is best considered ordinal, 
for demonstration we consider its treatment as categorical, continuous, and ordinal.  
Each of these treatments is described below in a separate section.

%% THE FOLLOWING DETAILS ARE REMOVED FOR NOW
%% In general, a set of scales is defined to be measurement invariant with respect
%% to an auxiliary variable $V$ if: 

%% \begin{equation}
%% \label{equ:invariance}
%% f(x_{i}|t_{i},v_{i},...)=f(x_{i}|t_{i},...),
%% \end{equation}

%% where $x_{i}$ is the data vector for individual $i$, $t_{i}$ is the latent variable 
%% for variable $i$ that the scales purport to measure, and $f$ is the model's 
%% distributional form \cite{mel89}. If the cut point of $v$ is known in advance, i.e. 
%% gender, nested multiple group models \cite{bollen98} coupled with likelihood ratio test 
%% are most commonly applied. Suppose there are two groups A and B. The null hypothesis 
%% of measurement invariance is 


%% \begin{equation}
%% \label{equ:null}
%% H_{0}: \theta_{A}=\theta_{B},
%% \end{equation}

%% The alternative hypothesis is 

%% \begin{equation}
%% \label{equ:alternative}
%% H_{1}:\theta_{i}=
%% \begin{cases}
%% \theta^{(A)} & v_{i}\leq v\\
%% \theta^{(B)} & v_{i}\geq v
%% \end{cases}
%% \end{equation}

%% The parameter estimate $\hat{\theta}^{(A)}$ , $\hat{\theta}^{(B)}$ ,$\hat{\theta}$ 
%% (group A and group B) can be obtained by Maximum Likelihood(ML) 
%% from observations $i=1,...m(v_{i}\leq v),i=m+1,...n(v_{i}\geq v), i=1,...,n$,
%% respectively. The LR test statistic for the given threshold $v$ is then 

%% \begin{equation}
%% \label{equ:LRT}
%% LR(v)=-2[\ell(\hat{\theta};x_{1},,,,x_{n})-{\ell(\hat{\theta}^
%% {(A)};x_{1},...,x_{m})+\ell(\hat{\theta}^{(B)};x_{m+1},...,x_{n})
%% }],
%% \end{equation}

%% ,which has an asymptotic $\chi^{2}$ distribution with degrees of freedom equal 
%% to the number difference of parameters in $\theta$. 


\subsection{Categorical Treatment}

Measurement invariance is most often tested using multiple groups models \cite<see, e.g., >{vande12}.  
This amounts to assuming that our auxiliary variable is categorical (i.e., unordered), 
which is not true for the age groups in the data.  However, we demonstrate the procedure for completeness.

To conduct the analysis, we first load the data and keep only complete cases for simplicity 
(though the tests can be applied to incomplete data).
<<data>>=
## Reading in the data
data("YouthGratitude",package="psychotools")

## remove cases with 'imputed' values(not in 1,...,9)
compcases <- apply(YouthGratitude[,4:28], 1, function(x) all(x %in% 1:9))
yg <- YouthGratitude[compcases,]
@
Next, we fit two models in lavaan: a one-factor model where loadings are restricted 
to be equal across age groups, and a one-factor model where loadings are free across age groups.
<<modest>>=
## Restricted model
reduced <- cfa('f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
             data=yg, group="agegroup", meanstructure=TRUE,
             group.equal="loadings")

## Unrestricted model
full <- cfa('f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
             data=yg, group="agegroup", meanstructure=TRUE)
@
Finally, we can get the results of a likelihood ratio test via the \verb+anova()+ 
function, which implies that the GQ-6 violates measurement invariance.
<<LRT>>=
## LRT
anova(full, reduced)
@

Another similar statistics is $\mathit{LM}_\mathit{uo}$ as shown in Equation~ \eqref{eq:lmuo}. We can obtain this statistic by using the following function. 
<<LM_UO>>=
## unordered LM
lm_u0 <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="range")
round(c(lm_u0$p.value), 2)
@
we wish to test model parameter numbers 1 through 4 (which are the factor loadings), 
which are supplied by lavaan.  The ordering of parameters can be obtained via the 
command \verb+coef(reduced)+. 

Because our sample size is large, this likelihood ratio test is sensitive to 
small measurement invariance violations \cite{Ben80}.  Thus, the above test may 
be significant solely due to the large sample size.  Additionally, the above test 
is sensitive to small measurement invariance violations that are not likely to be 
of interest to researchers.  For example, imagine that the 15-year-olds' 
parameters are slightly different than the other age groups.  
The 15-year-olds are in the middle of the age groups, and there 
is not likely to be any theoretical justification for 15-year-olds 
differing from every other age group.  We need test statistics that 
are sensitive to measurement invariance violations that are monotonic 
with age.  The score-based statistics described previously possess this property.


\subsection{Continuous Treatment}
If we are interested in measurement invariance violations that are 
monotonic with the age groups, it is perhaps simplest to treat the 
age groups as continuous.  In doing so, we can use the statistics 
from Equations~\eqref{eq:dmax},~\eqref{eq:cvm}, and~\eqref{eq:maxlm}.  
That is, we can fit a model whose parameters 
are restricted to be equal across all individuals and then examine 
how individuals' scores $s(\hat{theta};x_{i})$ fluctuate with their
age (where age ties are broken arbitrarily).
This is demonstrated below, with similar code being useful when one is 
testing measurement invariance w.r.t.\ other continuous variables.


%% The multiple group test performs typically well when the $V$ 
%% is a relatively-small number of categories and the sample size 
%% is not too large. However, when $V$ (in this case, age) continuous variable, however, 
%% multiple-group analysis usually cannot be performed because there are 
%% no existing groups. Instead, we can follow the procedure described in
%% the Background section.

To proceed, we focus only on the restricted model that was fit in 
the previous section (the object \verb+reduced+).  We obtain scores 
associated with the factor loadings from this model, then test the 
fluctuation of these scores across \verb+agegroup+.  
As demonstrated below, the score computation and testing can be efficiently carried out using \verb+sctest.lavaan()+.
%% Ting: I removed this because the model was already fit in the
%%       previous section
%%<<theta estimate>>=
%%theta<-cfa(
%%  'f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
%%  data=yg,group="agegroup",meanstructure=TRUE,
%%  group.equal="loadings")
%%@


<<Get Estimate>>=
dm <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="DM")
cvm <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="CvM")
maxlm <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLM")
round(c(dm$p.value, cvm$p.value, maxlm$p.value), 2)
@
%% move this code description to the cat2BB part. 
%In the code above, the \verb+parm=1:4+ argument means that 
%we wish to test model parameter numbers 1 through 4 (which are the factor loadings), 
%which are supplied by lavaan.  The ordering of parameters can be obtained via the 
%command \verb+coef(reduced)+.  

We see that two of the three $p$-values output at 
the end of the code are larger than that associated with the LRT (with the CvM statistic being non-significant).  

%% TODO Illustrate with graphs?


%% THE FOLLOWING HAS BEEN MOVED
%% \begin{figure}
%% \caption{Get Continuous Estimate DM Alternative Way}
%% \label{fig:conti1res}
%% \setkeys{Gin}{width=\textwidth}
%% <<conti1res, fig=TRUE, height=7, width=7>>=
%% DM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="DM", fplot=TRUE) 
%% DM
%% @
%% \end{figure}

%% \begin{figure}
%% \caption{Get Continuous Estimate CvM Alternative Way}
%% \label{fig:conti2res}
%% \setkeys{Gin}{width=\textwidth}
%% <<conti2res, fig=TRUE, height=7, width=7>>=
%% CvM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="CvM", fplot=TRUE) 
%% CvM
%% @
%% \end{figure}


%% <<conti3resmaxLM>>=
%% maxLM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLM", fplot=FALSE) 
%% maxLM
%% @
The tests carried out here assume a unique ordering of individuals by age, but 
this is obviously not the case.  To compute the statistics and $p$-values, 
the strucchange package implicitly assumed an arbitrary ordering of 
individuals who are tied on age.  If we were to change this ordering, 
the resulting statistics and $p$-values would also change, which is obviously problematic.  
To accurately account for the multiple observations  
at the same age level, we must used the ordinal tests from 
Equations~\eqref{eq:wdm} and~\eqref{eq:maxlmo}.  These are described next.

\subsection{Ordinal Treatment}

%% As a matter of fact, there is only a partial ordering of individuals 
%% with respect to $V$,i.e. observations with the same level 
%% of $V$ have no unique ordering. The ordinal statistics 
%% proposed here are similar to those described in Equation 
%% and above, except that we focus on "bins" of individuals 
%% at each level of the ordinal variable.  

The difference between the ordinal test statistics and their
continuous counterparts is that the ordinal statistics do not require
an ordering of individuals  
within the same age group.  To compute the test statistics, we allow
the scores of all tied individuals to enter the cumulative sum
(Equation~\eqref{eq:cumscore}) simultaneously.  This results in
modified critical values and test statistics that are sensitive to
measurement invariance violations that are monotonic with age group.
%% Therefore, this ordinal test should 
%% reflect more real status of the data. In terms of code, we still need the gefp 
%% function to get the B estimate. After that, we can use different 
%% functions to aggregate and scale B estimation. 
%% The function are called ordwmax and ol2bb1.fun, respectively. 

To carry out the tests, we can rely on the same function that we used
for the continuous test statistics.  As mentioned previously,
calculation of the ``maxLMo'' statistic (Equation~\eqref{eq:maxlmo})
can be lengthy from the need to simulate critical values.

<<critvals,echo=FALSE>>=
if(file.exists("opval1.rda")){
  load("opval1.rda")
} else {
  opval1 <- ordL2BB(gefp1)
  save(opval1, file="opval1.rda")
}
## Get test statistics using fnl=opval1 without showing it in the paper
wdmo <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="WDMo")
maxlmo <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLMo",
                 fnl=opval1)
@ 

<<ordtest,eval=FALSE>>=
wdmo <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="WDMo")
maxlmo <- sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLMo")

@ 
<<pvals>>=
round(c(wdmo$p.value, maxlmo$p.value), 2)
@ 

In computing the ordinal test statistics, we
obtain~$p=\Sexpr{round(wdmo$p.value,2)}$
and~$p=\Sexpr{round(maxlmo$p.value,2)}$, respectively.
Both $p-$values are clearly larger than that of the 
likelihood ratio test and neither is significant at $\alpha=0.05$. 
This provides evidence that there is no measurement
invariance violation that is monotonic with age group.  Instead, given
the large sample size, the likelihood ratio test may be overly
sensitive to anomalous, non-monotonic violations at one (or a few) age groups.

Besides, plots can be generated by using \verb+fplot=TRUE+ argument inside of \verb+sctest.lavaan()+ function. Plots representing the statistics' fluctuations across levels of age group are displayed in Figure~\ref{fig:ordres}. The left panel displays the process associated with $\mathit{WDM}$. The right panel displays the process associated with $\mathit{maxLM}$. In both cases, the test statistics in the sequence assess a split of the observations up to age group $i$ vs. greater than $i$, and the null hypothesis is rejected if the maximum of the statistics is larger than its 5\% critical value(visualized by the horizontal red line). The final group is not displayed because it encompass all observations and always equals to zero. The age group 1:5 in the x-axis corresponds to 10-11, 12-13, 14,15,16 respectively. It is observed that both statistics generally increase with age. 

%% gefp1<gefp(reduced,fit=NULL,order.by=as.numeric(yg$agegroup),
%%        vcov=info_full,sandwich=FALSE,parm=1:4)
%% pval.ord=rep(NA,2)
%% pval.ord[1]<-sctest(gefp1,functional=ordwmax(gefp1))$p.value


%%pval.ord[2]<-sctest(gefp1, functional=opval1)$p.value
%% pval.ord
%% @

%Or alternatively, we could use the sctest.lavaan function, but assign ordinal statistics.
\begin{figure}[H]
\caption{Fluctuation processes for the WDM statistic(left panel) and the maxLM statistic(right panel)}
\label{fig:ordres}
\setkeys{Gin}{width=\textwidth}
<<ordres, fig=TRUE, height=3, width=6, echo=FALSE>>=
par(mfrow = c(1, 2), cex = 0.65)
WDMo<-sctest(reduced, as.numeric(yg$agegroup),parm=1:4, stat="WDMo", fplot=TRUE,ylim=c(0,3.5),xlab="Age group",ylab = "Weighted max statistics")

#WDMo 
maxLMo<-sctest(reduced,as.numeric(yg$agegroup),parm=1:4, stat="maxLMo", fnl=opval1, fplot=TRUE,ylim=c(0,14),xlab="Age group",ylab = "LM statistics")
#maxLMo 
@
\end{figure}

\seeme{can't change age group axis, since order.by argument needs agegroup as numeric}



%% TODO Describe graphs
%% Is there some argument for fplot=TRUE so user can change  axis-name and critical value line

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the above sections, we have illustrated the score-based tests'
computation in R.  We suspect that the ordinal tests will be most
popular with users, because measurement invariance tests are typically
carried out across categories (ordered or not), as opposed to
continuous variables.  Thus, in the sections below, we report
novel simulations to study the ordinal statistics' expected behavior
in practice.  In particular, we wish to study (i) the extent to which the
ordinal statistics attribute measurement invariance violations to the
correct parameter(s), and (ii) the extent to which the tests are
robust to model misspecification.

\SweaveOpts{engine = R, eps = FALSE, echo = FALSE, pdf=TRUE}
\section{Simulation}
\section{Simulation 1}
In Simulation 1, we examined the extent to which the proposed tests
are sensitive to the specific model parameter that violates measurement
invariance.  If, say, a factor loading violates measurement
invariance, it is plausible that this violation impacts other
parameters such as factor covariances or other loadings 
associated with the factor in question.  Thus, the goal of the
simulation was to examine the extent to which the proposed tests
attribute the measurement invariance violation to the parameters that
are truly in violation.  

\subsection{Methods}
To examine these specificity issues, we generated data from a
two-factor model with three indicators each (the same model used in
Merkle and Zeileis, \citeyearNP{MerZei13}). The measurement invariance
violation occurred in one of three places: the factor loadings
 $\lambda_{11}--\lambda_{62}$, the unique variance associated
 $\epsilon_{11}--\epsilon_{66}$, or the factor covariance $\sigma_{12}$.  
We then tested for measurement invariance in seven subsets of parameters: the three
individual parameters noted above, all six factor loadings $\lambda_{11}--\lambda_{62}$, 
all six unique variances $\epsilon_{11}--\epsilon_{66}$. The path diagram is shown in  
Figure~\ref{fig:path}.

\begin{figure}[H]
\caption{Path diagram representing the factor analysis model 
         used for simulations.}
\label{fig:path}
\includegraphics{PathDiagram}
\end{figure}

Power and Type I error were examined across three sample sizes
($n=120,480,960$), three numbers of categories ($m=4,8,12$) and
17 magnitudes of invariance violations. 
The measurement invariance violations began at level $1+m/2$ of $V$
and were consistent thereafter. These
violations were based on the auxiliary variable $V$: individuals below
the $1+m/2$ percentile of $V$ deviated from individuals above the $1+m/2$ 
percentile  by $d$ times the parameters' asymptotic standard errors
(scaled by $\sqrt n$), with $d=0,0,25,0.5,...,4$. 
For each combination of sample size ($n$) $\times$ violation
magnitude ($d$) $\times$ violating parameter $\times$ categories $m$, 5000 datasets were
generated and tested. Four statistics were examined above. In all conditions, we
maintained equal sample sizes at each level of the ordinal variable. 

\subsection{Results}
Full simulation results are presented in Figure~\ref{fig:sim11res} to 
Figure~\ref{fig:sim13res}; all three test statistics exhibited 
similar results, with unordered  $\max\mathit{LM}$ demonstrated lower powers across all situations. ordered $\max\mathit{LM}$ and double-max exhibited equivalent power curves since there is only one parameter violating measurement invariance. Thus, different ways of aggregating $\bm B(\hat{\theta})$ would be the same.
Figure~\ref{fig:sim11res} displays power curves as a function of 
violation magnitude for the first
factor loading $\lambda_{11}$, with panels reflecting the parameters 
being tested and lines reflecting $n$.
Figures~\ref{fig:sim12res} and Figure~\ref{fig:sim13res} display 
similar power curves when the factor covariance 
$\phi_{12}$ and error variance $\epsilon_{11}$ violate measurement
invariance, respectively. 

From these figures, one generally observe that the tests isolate 
the parameter violating measurement invariance.  Additionally, the tests 
have somewhat-higher power to detect measurement invariance violations 
in the factor loading and factor covariance parameters, as opposed to the error variance
parameter.  Finally, simultaneous tests of all factor loadings or all error
parameters result in decreased power, as compared to the situation
where one tests only the violating parameter.  This occurs because, in
testing a subset of parameters (only one of which violates measurement
invariance), we are effectively dampening the signal of a measurement
invariance violation.  


In summary, we found that the proposed tests can attribute
measurement invariance violations to the correct parameter.  This
provides evidence that, in practice, one can have confidence in the
tests' abilities to locate the measurement invariance violation.  Of
course, this statement is qualified by the fact that, in this
simulation, the model was correctly specified.  In the following
simulations, we examine the tests' performance when the model is
misspecified.

<<sim1>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim1.rda")) {
  load("sim1.rda")
} else {
  sim1 <- simulation(sim="sim1", nobs=480, parms=c("loading","error","var"))
  sim1$nlevels <- factor(sim1$nlevels)
  levels(sim1$nlevels) <- paste("m=",levels(sim1$nlevels),sep="")
 
  sim1$nobs <- factor(sim1$nobs)
  levels(sim1$nobs) <- paste("n=",levels(sim1$nobs),sep="")
  levels(sim1$test) <- c("maxLM_O","WDM_O","LM_uO")
  save(sim1, file="sim1.rda")
}
sim1$test <- factor(as.character(sim1$test),
  levels = c("ordmax","ordwmax","catdiff"),
  labels = c("maxLM_o","WDM_o","LM_uo"))
  levels(sim1$pars) <- c("Loading1","Covariance","Error1","All Loadings","All Errors")  

@ 

\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the double-max test and the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance 
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is Loading1.}
\label{fig:sim11res}
\setkeys{Gin}{width=\textwidth}
<<sim11res, fig=TRUE, height=7, width=7>>=
sim1.tmp <- sim1[sim1$parms %in% c("loading")& sim1$pars %in% c("Loading1","All Loadings","All Errors"),]
sim1.tmp$test <- factor(sim1.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim1.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}

\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the ordered double-max test the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is Covariance}
\label{fig:sim12res}
\setkeys{Gin}{width=\textwidth}
<<sim12res, fig=TRUE, height=7, width=7>>=
sim1.tmp <- sim1[sim1$test %in% c("maxLM_o","WDM_o","LM_uo")&sim1$parms %in% c("var") &sim1$pars %in% c("All Loadings", "Covariance","All Errors") ,]
sim1.tmp$test <- factor(sim1.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim1.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}

\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the ordered double-max test the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is Error1}
\label{fig:sim13res}
\setkeys{Gin}{width=\textwidth}
<<sim13res, fig=TRUE, height=7, width=7>>=
sim1.tmp <- sim1[sim1$test %in% c("maxLM_o","WDM_o","LM_uo")&sim1$parms %in% c("error") &sim1$pars %in% c("Error1","All Errors","All Loadings"),]
sim1.tmp$test <- factor(sim1.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim1.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}


\section{Simulation 2}
In Simulation 2, we examine the extent to which the results of
Simulation 1 are robust to model misspecification. Specifically, we
generate data from the factor analysis model used in the previous
section, but with adding an extra loading from the second factor to the first
indicator (of the first factor).  The estimated model lacks this extra
loading, however. The goal of this simulation is to examine the proposed statistics'
power and specificity under model misspecification.

\subsection{Method}
Measurement invariance violations could occur in
each of the three parameters from Simulation 1 (factor loading,factor covariance,unique
variance), and they could also occur in the extra, unmodeled loading. 
Sample size and magnitude of measurement invariance violation were manipulated 
in the same way as they were in Simulation 1.The tested parameters are the same as Simulation
1,too.

\subsection{Results}
Results are presented by the parameter that violated measurement invariance.
Figure~\ref{fig:sim21res} displays results when the unmodeled loading violates 
measurement invariance. One can generally observe that 
the first loading and error variance parameter showed high measurement invariance 
violation simultaneously, while factor covariance did not demonstrate violation.


When the loading $\lambda_{11}$ violates
measurement invariance, even though lacking one loading associated with the first indicator, 
statistic showed enough power to detect the first loading violation specifically. 
Similar pattern of specificity and power were observed when the violation parameter 
was $\sigma_{12}$ and $\epsilon_{11}$. Figures are shown in Appendix for simplicity.

In summary, the proposed test statistics appear robust to unmodeled loading parameters,so long
as the umodeled parameter does not violate measurment invariance. If the unmodeled parameter 
dose violate measurement invariance, however, then the tests assign this violation to other 
parameters that do not violate measurement invariance. The impacted parameters include the error
variance and other loadings associated with the manifest variables that had the unmodeled 
loading. Thus, prior to testing measurement invariance, it is important to study the extent to
which the hypothesized model includes all parameters of importance.

<<sim2>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim2.rda")) {
  load("sim2.rda")
} else {
  sim2 <- simulation(sim="sim2", nobs=480, parms=c("extra","extra+loading","extra+var","extra+error"))

  save(sim2, file="sim2.rda")
}
sim2$test <- factor(as.character(sim2$test),
  levels = c("ordmax","ordwmax","catdiff"),
  labels = c("maxLM_o","WDM_o","LM_uo"))
  sim2$nlevels <- factor(sim2$nlevels)
  levels(sim2$nlevels) <- paste("m=",levels(sim2$nlevels),sep="")
  sim2$nobs <- factor(sim2$nobs)
  levels(sim2$nobs) <- paste("n=",levels(sim2$nobs),sep="")
  levels(sim2$pars) <- c("Loading1","Covariance","Error1","All Loadings","All Errors") 

@ 

\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the double-max test and the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance 
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is the lacking loading.}
\label{fig:sim21res}
\setkeys{Gin}{width=\textwidth}
<<sim21res, fig=TRUE, height=7, width=7>>=
sim2.tmp <- sim2[sim2$test %in% c("maxLM_o","WDM_o","LM_uo")&sim2$parms %in% c("extra")&sim2$pars %in% c("Loading1","Error1","Covariance"),]
sim2.tmp$test <- factor(sim2.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim2.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}


\section{General Discussion}

In this paper, we examined the recently proposed ordinal statistics specificity property and robustness to model specification to study measurement invariance. As demonstrated in the results, the proposed statistics could select the parameter violating measurement invariance even though the model is misspecified in general. However, when an unmodeled parameter is violating measurement invariance, the statistics will demonstrating these variances in the related parameters, for example, associated loading and error terms. 

These ordinal tests are useful in behavioral and social science in general, since the truly continuous auxiliary variable is hard to find in real research context. It is very common to observe several individuals with the same age, IQ, income rank, etc. Therefore, the ordinal tests which dealing with multiple ties in auxiliary variable is more suitable than the continuous test. 

Moreover, even though researchers might be originally interested in comparing categorical differences. For example, researchers might want to test whether there is gender difference or cultural difference for the scale. Using traditional likelihood test or wald test, there might existing some differences regarding to the categorical variable. Then the next natural question would be why there is gender or culture differences? At this point, researchers might need to examine education level, social economic status, etc, which were often recorded in the ordinal format. Thus these test statistics offer an convenient assessing tool to further exploring research hypothesis without making complicated assumptions or fitting multiple different models.

We focused on testing for measurement invariance in factor analysis model in this paper, however, the core of the proposed ordinal test is to get the cumulative score process, which can be applied to any ML estimation functions or functions relating to maximizing or minimizing some statistics quantity. For example, studying DIF in IRT is immediate.  

In summary, the ordinal test statistic proposed have relatively-high power for detecting measurement invariance violation parameter specifically that are monotonic with the auxiliary ordinal variable. This
feature is robust as long as the violation parameter is included in the testing model. Furthermore, as illustrated in tutorial part, the use of these tests is convenient without changing the focal psychometric model. In all, the tests have advantageous properties that should be implemented in practice.
   
\section{Appendix}
\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the double-max test and the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance 
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is the lacking loading.}
\label{fig:sim22res}
\setkeys{Gin}{width=\textwidth}
<<sim22res, fig=TRUE, height=7, width=7>>=
sim2.tmp <- sim2[sim2$test %in% c("maxLM_o","WDM_o","LM_uo")&sim2$parms %in% c("extra+loading"),]
sim2.tmp$test <- factor(sim2.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim2.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}

\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the double-max test and the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance 
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is the lacking loading.}
\label{fig:sim23res}
\setkeys{Gin}{width=\textwidth}
<<sim23res, fig=TRUE, height=7, width=7>>=
sim2.tmp <- sim2[sim2$test %in% c("maxLM_o","WDM_o","LM_uo")&sim2$parms %in% c("extra+var"),]
sim2.tmp$test <- factor(sim2.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim2.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}

\begin{figure}[H]
\caption{Simulated power curves for the ordered 
      $\max\mathit{LM}$ tests, the double-max test and the unordered $\max\mathit{LM}$ across three
      levels of the ordinal variable $m$, and measurement invariance 
      violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is the lacking loading.}
\label{fig:sim24res}
\setkeys{Gin}{width=\textwidth}
<<sim24res, fig=TRUE, height=7, width=7>>=
sim2.tmp <- sim2[sim2$test %in% c("maxLM_o","WDM_o","LM_uo")&sim2$parms %in% c("extra+error"),]
sim2.tmp$test <- factor(sim2.tmp$test)
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2.tmp$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels+pars, group = ~ test, data = sim2.tmp, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@

\end{figure}



\section*{Computational Details}

All results were obtained using the {R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on package
{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} for fitting 
of the factor analysis models and
{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. {R}~and the packages {lavaan} and 
{strucchange} are
freely available under the General Public License~2 from the
Comprehensive {R} Archive Network at \url{http://CRAN.R-project.org/}.
{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.


\bibliography{refs}

\end{document}
