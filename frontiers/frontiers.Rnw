%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Editing Rules:                                                            %
%1. Ed's comment and questions:\readme{}                                   %     
%2. Ting's comment and questions:\seeme{}                                  % 
%3. When comments and questions are resovled, the corresponding \readme or %  
%   \seeme will be removed by Ting.                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[doc]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm,float}
\usepackage[english]{babel}
\usepackage{tikz}

% Seems necessary for texlive 2012?
\usetikzlibrary{arrows}

\title{Score-based tests of measurement invariance: Use in practice}
\twoauthors{Ting Wang and Edgar C.\ Merkle}{Achim Zeileis}
\twoaffiliations{University of Missouri}{Universit\"{a}t Innsbruck}

\abstract{
In this paper, we consider a family of 
recently-proposed measurement invariance tests that are based on the scores of a fitted model.  This family can be used to test for measurement invariance
w.r.t.\ a continuous auxiliary variable, without pre-specification of subgroups.
Moreover, the family can be used when one wishes to test for 
measurement invariance w.r.t.\ an ordinal auxiliary variable, yielding test
statistics that are sensitive to violations that are monotonically related to
the ordinal variable (and less sensitive to non-monotonic violations).  The paper is specifically aimed at potential users of the tests who may wish to know (i) how the tests can be employed for their data, and (ii) whether the tests can accurately identify measurement invariance violations in the presence of model misspecification.  After providing an overview of the tests, we illustrate their general use via the R packages lavaan and strucchange.  We then describe two novel simulations that provide evidence of the tests' practical abilities.  As a whole, the paper provides researchers with the tools and knowledge needed to apply these tests to general measurement invariance scenarios.}

\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. 
  Correspondence to Edgar Merkle. 
  Email: merklee@missouri.edu.}
\shorttitle{Score-based tests in practice}
\rightheader{Score-based tests in practice}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{Ed} (#1)}}
\newcommand{\seeme}[1]{\emph{\marginpar{Ting} (#1)}}


\spacing{1}

\begin{document}
\maketitle

\include{Sweave}
<<preliminaries1,echo=FALSE>>=
## packages
library("lavaan")
library("strucchange")
library("mvtnorm")
library("lattice")

## auxiliary code
source("simall-ordinal.R")
source("mz.R")
source("../www/efpFunctional-cat.R")
source("../pkg/sctest.lavaan.R")
source("../www/mz-ordinal.R")
source("../www/estfun-lavaan.R")


## turn off stars
options(show.signif.stars = FALSE)

## convenience function for plotting boundaries without color
get_boundary <- function(obj, fun, trim = 0) {
  bound <- fun$boundary(0:obj$nobs/obj$nobs)
  bound <- fun$computeCritval(0.05, ncol(obj$process)) * bound
  bound <- zoo(bound, time(obj$process))
  if(trim > 0) bound <- head(tail(bound, - floor(trim * obj$nobs)), - floor(trim * obj$nobs))
  return(bound)
}

## convenience function for applying tests to real data
info_full <- function(x, ...) solve(vcov(x) * nobs(x))
@

Many of the papers in this special issue focus on the topic of approximate measurement invariance: we know that strict hypotheses of measurement invariance do not hold exactly across different groups, and this should be reflected in corresponding tests of measurement invariance.  BSEM
(Bayesian Structural Equation Modeling) generally handles these ideas by replacing across-group equality constraints with informative prior distributions.  In this paper, we describe an alternative approach: the development of test statistics that are sensitive to invariance violations of interest and insensitive to ``anomalous'' invariance violations.  The test statistics are specifically applicable to situations where one wishes to test for measurement invariance with respect to an ordinal variable, and they are special cases of a family of tests that may generally be used to study measurement invariance w.r.t.\ continuous, categorical, and ordinal variables.

The family of tests described in this paper have recently been studied in the context of measurement invariance \cite{MerZei13,MerFanZei}, though their practical application has been limited to a small set of simulations and datasets.  In this paper, we provide a detailed illustration of the tests' use in practice and a detailed examination 
of the tests' performance under scenarios likely to be encountered in practice. 
%In order to fix the psychometric scale, we need to specify the violating parameter.  
%Moreover, in practice model misspecification is an inevitable issue to a certain extent 
%and may interfere with parameter invariance specificity. A family of tests derived from 
%stochastic process has been recently proposed to identify specific parameters impacted 
%by measurement invariance violation. However, these tests have only been used to a limited 
%type of parameter violation. It is this paper's intent to provide a detailed examination 
%of the tests' performance under practical research scenarios. 
In the following sections, we first briefly review the 
theoretical framework of the proposed tests and
provide a short tutorial illustrating the use of the tests in R.
Next, we study the tests' performance in simulations that mimic practical research scenarios. 
Finally, we provide some further discussion on the tests' use in practice.  

\section{Background}
This section contains background and discussion of the 
proposed statistics as applied to SEM; for a more detailed account, see
\citeA{MerZei13} and \citeA{MerFanZei}.  For details on the
statistics' application to general statistical models, see
\citeA{zeihor07}.

As currently implemented for SEM, the statistical tests described in
this paper can be applied to models that are estimated via a
multivariate normal or Wishart likelihood (or discrepancy) function,
with extension to other discrepancy functions being conceptually straightforward. 
The tests are carried out following model estimation, making use of output
associated with the fitted model.  In general, we fit a model that
restricts parameters to be equal across observations, then carry out a
posthoc test to examine whether specific parameters vary
across observations.  This procedure is similar in spirit to the
calculation of modification indices \cite{bentler90} and to Lagrange multiplier
tests \cite{sat89}, and, in fact, those statistics can be viewed as  
special cases of the family described here.

Following model estimation, the tests primarily work on the {\em
  scores} of the fitted model; these are defined as
%% TODO indicate that this is evaluated at theta hat
\begin{equation}
\label{eq:score}
s(\hat{\theta};x_{i}) = \left ( \frac{\partial
      \ell(\theta;x_{i})}{\partial(\theta_{1})},...,\frac{\partial
      \ell(\theta;x_{i})}{\partial(\theta_{k})} \right )^{T},
\end{equation} 
where $\ell(\theta; x_i)$ is the likelihood associated with individual
$i$, $\theta$ is a $k$-dimensional parameter vector, and
$\hat{\theta}$ is the maximum likelihood estimate.  The cross-product
of these scores forms the ``meat'' for the calculation of robust
(Huber-White) standard errors \cite<e.g.,>{zei06b}.

To verbally describe the above equation, each
individual has $k$ scores describing the extent to which the fitted
model describes that particular individual.  Scores close to zero
indicate a ``good'' description, and scores far from zero indicate a
``bad'' description.  Each of an individual's $k$ scores represent one
model parameter, so that the scores provide specific information about
each parameter's fit to each individual.

To use these scores for testing, we order individuals according to
an auxiliary variable (the variable against which we are testing 
measurement invariance) and look for ``trends'' in the
scores.  For example, imagine that we are testing
for measurement 
invariance w.r.t.\ age.  If the manifest variables violate measurement
invariance here, then some parameter estimates may be too large for
young individuals and too small for old individuals (say).  This
result would be reflected in the scores, where young individuals'
scores may be greater than zero and old individuals' scores 
less than zero (though the sign of the scores will depend on whether a
function is being minimized or maximized).  Conversely, if measurement
invariance holds, then all 
individuals' scores will fluctuate around zero.

To formalize the ideas in the previous paragraph, we define a cumulative
sum of the ordered scores.  This cumulative sum may be written as
\begin{equation} 
    \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ %\hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n \cdot t \rfloor} {\bm s}(\hat {\bm \theta}; x_{(i)})
  \qquad (0 \le t \le 1)
\end{equation}
where $\lfloor nt \rfloor$ is the integer part of $nt$ (i.e., a floor
operator) and $x_{(i)}$ reflects the individual with the
$i^{\text{th}}$-smallest value of the auxiliary variable.
We specifically focus on how the
cumulative sum fluctuates as more individuals' scores are added to it,
starting with the youngest and ending with the oldest individual
(assuming that age is the auxiliary variable of interest).  
The summation is also typically premultiplied by the inverse square
root of the information matrix, which serves to decorrelate the
fluctuation processes associated with individual model parameters 
(i.e., the process associated with one parameter is not correlated 
with the processes associated with other parameters).

Under the
hypothesis of measurement invariance, a central limit theorem can be
used to show that the fluctuation of the above cumulative sum follows a
Brownian bridge.  This result allows us to calculate $p$-values and
critical values for test statistics under the hypothesis of
measurement invariance.  We can obtain test statistics associated with
all model parameters and with subsets of model parameters.

%% TODO focus on ordinal
Multiple test statistics are available, depending on how one
summarizes the behavior of the cumulative sum of scores.  For example, 
one could take the absolute maximum that the cumulative sum attains for any
parameter of interest, resulting in a {\em double max} statistic 
(the maximum is taken across parameters and individuals).
Alternatively, one could sum the (squared) cumulative sum across parameters
of interest and take the maximum or the average across individuals, resulting in a 
{\em maximum Lagrange multiplier} statistic and Cram\'{e}r-von Mises statistic, respectively 
\cite<see>[for further discussion]{MerZei13}.  These statistics are given by

\begin{eqnarray}
    \label{eq:dmax}
    \mathit{DM} & = & \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} | \\
        \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2.
\end{eqnarray}

Critical values associated with $\mathit{DM}$ can be obtained analytically, 
while critical values associated with the other statistics can be obtained 
from direct simulation \cite{Zei06} or from more refined techniques \cite{han97}.  
This issue should not be important to the user, as critical values are obtained 
directly from the R implementation described later.


Importantly, the above statistics were derived for situations where
individuals are uniquely ordered according to the auxiliary variable.
This is not always the case for measurement invariance applications,
where the auxiliary variable is often ordinal.  To remedy this
situation, \citeA{MerFanZei} extended the framework to situations
where one has an ordinal auxiliary variable of interest.  Essentially,
one allows all individuals with the same value of the auxiliary
variable to enter into the cumulative sum at the same time.  Analogous test 
statistics are then computed, with
modified critical values being adopted to reflect the change in the
statistics' computation.  

For an ordinal auxiliary variable with $m$ levels, these modifications are 
based on $t_{\ell}$ $(\ell=1,\ldots,m-1)$, which are the empirical, cumulative 
proportions of individuals observed at the first $m-1$ levels.
The modified statistics are then given by
\begin{eqnarray}
    \label{eq:wdm}
      \mathit{WDM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~ \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1/2}      
                             \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,\\
    \label{eq:maxlmo}
      \max \mathit{LM}_o & = & \max_{i \in \{i_1, \dots, i_{m-1} \}} ~
                             \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
                             \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
where $i_{\ell}=\lfloor n \cdot t_{\ell} \rfloor$ $(\ell=1,\ldots,m-1)$.
Critical values associated with the $\mathit{WDM}_o$ statistic can be obtained 
directly from a multivariate normal distribution \cite<see>{hotzei08}, while 
critical values associated with $\max \mathit{LM}_o$ can be obtained via simulation.  
This simulation is somewhat computationally intensive and, in practice, takes about 
10 minutes on the authors' computers.  However, the wait is often worth it, 
as \citeA{MerFanZei} found the performance of the $\max \mathit{LM}_o$ statistic 
to be considerably better than the $\mathit{WDM}_o$ statistic.


Finally, if $V$ is only nominal/categorical, the cumulative sums of scores can be used to obtain the a Lagrange multiplier statistic.
This test statistic can be formally written as
\begin{equation}
    \label{eq:lmuo}
     \mathit{LM}_{uo} = \sum_{\ell = 1, \dots, m} \sum_{j = 1, \dots, k}
       \left( {\bm B}(\hat {\bm \theta})_{i_\ell j} - {\bm B}(\hat {\bm \theta})_{i_{\ell - 1}j} \right)^2,
\end{equation}
and it is asymptotically equivalent to the usual, likelihood ratio test statistic.  It is advantageous over the likelihood ratio test because it requires estimation of only one model (the restricted model).  We make use of this advantage in the simulations, described later.



\section{Tutorial}

In this section, we demonstrate how the above tests can be carried out in~R, 
using the package lavaan \cite{lavaan11} for model estimation and strucchange 
\cite{ZeiLei02,Zei06} for testing.  We use data from \citeA{FroFan11} concerning 
the applicability of adult gratitude scales to youth, available in the~R 
package psychotools \cite{zeilei12}.  The data consist of responses to three adult 
gratitude scales from $n=1401$ youth aged 10--19 years. The original authors 
were specifically interested in whether the scales were measurement invariant 
across age.  Because the sample size at each age was unbalanced, the authors 
created age groups of approximately equal sample size.  In the examples below, 
we test for measurement invariance across these age groups.

We focus on measurement invariance of the factor loadings associated with 
the GQ-6 scale, using a one-factor model. While the ``age group'' variable against 
which we are testing measurement invariance is best considered ordinal, 
for demonstration we consider its treatment as categorical, continuous, and ordinal.  
Each of these treatments is described below in a separate section.

%% THE FOLLOWING DETAILS ARE REMOVED FOR NOW
%% In general, a set of scales is defined to be measurement invariant with respect
%% to an auxiliary variable $V$ if: 

%% \begin{equation}
%% \label{equ:invariance}
%% f(x_{i}|t_{i},v_{i},...)=f(x_{i}|t_{i},...),
%% \end{equation}

%% where $x_{i}$ is the data vector for individual $i$, $t_{i}$ is the latent variable 
%% for variable $i$ that the scales purport to measure, and $f$ is the model's 
%% distributional form \cite{mel89}. If the cut point of $v$ is known in advance, i.e. 
%% gender, nested multiple group models \cite{bollen98} coupled with likelihood ratio test 
%% are most commonly applied. Suppose there are two groups A and B. The null hypothesis 
%% of measurement invariance is 


%% \begin{equation}
%% \label{equ:null}
%% H_{0}: \theta_{A}=\theta_{B},
%% \end{equation}

%% The alternative hypothesis is 

%% \begin{equation}
%% \label{equ:alternative}
%% H_{1}:\theta_{i}=
%% \begin{cases}
%% \theta^{(A)} & v_{i}\leq v\\
%% \theta^{(B)} & v_{i}\geq v
%% \end{cases}
%% \end{equation}

%% The parameter estimate $\hat{\theta}^{(A)}$ , $\hat{\theta}^{(B)}$ ,$\hat{\theta}$ 
%% (group A and group B) can be obtained by Maximum Likelihood(ML) 
%% from observations $i=1,...m(v_{i}\leq v),i=m+1,...n(v_{i}\geq v), i=1,...,n$,
%% respectively. The LR test statistic for the given threshold $v$ is then 

%% \begin{equation}
%% \label{equ:LRT}
%% LR(v)=-2[\ell(\hat{\theta};x_{1},,,,x_{n})-{\ell(\hat{\theta}^
%% {(A)};x_{1},...,x_{m})+\ell(\hat{\theta}^{(B)};x_{m+1},...,x_{n})
%% }],
%% \end{equation}

%% ,which has an asymptotic $\chi^{2}$ distribution with degrees of freedom equal 
%% to the number difference of parameters in $\theta$. 


\subsection{Categorical Treatment}

Measurement invariance is most often tested using multiple groups models \cite<see, e.g., >{vande12}.  
This amounts to assuming that our auxiliary variable is categorical (i.e., unordered), 
which is not true for the age groups in the data.  However, we demonstrate the procedure for completeness.

To conduct the analysis, we first load the data and keep only complete cases for simplicity 
(though the tests can be applied to incomplete data).
<<data>>=
## Reading in the data
data("YouthGratitude",package="psychotools")

## Remove cases with imputed values (not in 1,...,9)
compcases <- apply(YouthGratitude[,4:28], 1, function(x) all(x %in% 1:9))
yg <- YouthGratitude[compcases,]
@
Next, we fit two models in lavaan: a one-factor model where loadings are restricted 
to be equal across age groups, and a one-factor model where loadings are free across age groups.
<<modest>>=
## Restricted model
reduced <- cfa("f1 = ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5",
             data = yg, group = "agegroup", meanstructure = TRUE,
             group.equal = "loadings")

## Unrestricted model
full <- cfa("f1= ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5",
             data = yg, group = "agegroup", meanstructure = TRUE)
@
Finally, we can get the results of a likelihood ratio test via the \verb+anova()+ 
function, which implies that the GQ-6 violates measurement invariance.
<<LRT>>=
## LRT
anova(full, reduced)
@

To obtain the asymptotically equivalent $\mathit{LM}_\mathit{uo}$ (Equation~\eqref{eq:lmuo}), we can use the following command.
<<LM_UO>>=
## unordered LM
lm_uo <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "LMuo")
round(lm_uo$p.value, 4)
@
This command specifies that we wish to test model parameter numbers 1 through 4, which are the factor loadings supplied by lavaan.  The ordering of parameters can be obtained via the command \verb+coef(reduced)+. 

Because our sample size is large, the likelihood ratio test is known to be sensitive to 
small measurement invariance violations \cite{Ben80}.  That is, the above tests 
are sensitive to small measurement invariance violations that are not likely to be 
of interest to researchers.  For example, imagine that the 15-year-olds' 
parameters are slightly different than the other age groups.  
The 15-year-olds are in the middle of the age groups, and there 
is not likely to be any theoretical justification for 15-year-olds 
differing from every other age group.  One solution to this problem would be the {\em approximate invariance} methods proposed by Muth\'{e}n \cite{muthen13}.
Alternatively, we can use the proposed family of score-based statistics to obtain tests that are sensitive to the ordering of age.



\subsection{Continuous Treatment}
If we are interested in measurement invariance violations that are 
monotonic with the age groups, it is perhaps simplest to treat the 
age groups as continuous.  In doing so, we can use the statistics 
from Equations~\eqref{eq:dmax}, ~\eqref{eq:cvm} and~\eqref{eq:maxlm}.  
That is, we can fit a model whose parameters 
are restricted to be equal across all individuals and then examine 
how individuals' scores $s(\hat{\theta};x_{i})$ fluctuate with their
age (where age ties are broken arbitrarily).
This is demonstrated below, with similar code being useful when one is 
testing for measurement invariance w.r.t.\ truly continuous variables.


%% The multiple group test performs typically well when the $V$ 
%% is a relatively-small number of categories and the sample size 
%% is not too large. However, when $V$ (in this case, age) continuous variable, however, 
%% multiple-group analysis usually cannot be performed because there are 
%% no existing groups. Instead, we can follow the procedure described in
%% the Background section.

To proceed, we focus only on the restricted model that was fit in 
the previous section (stored in the object \verb+reduced+).  We obtain scores 
associated with the factor loadings from this model, then test the 
fluctuation of these scores across \verb+agegroup+.  
As demonstrated below, the score computation and testing can be efficiently carried out using \verb+sctest.lavaan()+.
%% Ting: I removed this because the model was already fit in the
%%       previous section
%%<<theta estimate>>=
%%theta<-cfa(
%%  'f1=~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
%%  data=yg,group="agegroup",meanstructure=TRUE,
%%  group.equal="loadings")
%%@


<<getestimate>>=
dm <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "DM")
cvm <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "CvM")
maxlm <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "maxLM")
round(c(dm$p.value, cvm$p.value, maxlm$p.value), 2)
@
%% move this code description to the cat2BB part. 
%In the code above, the \verb+parm=1:4+ argument means that 
%we wish to test model parameter numbers 1 through 4 (which are the factor loadings), 
%which are supplied by lavaan.  The ordering of parameters can be obtained via the 
%command \verb+coef(reduced)+.  
We see that two of the three $p$-values output at 
the end of the code are larger than that associated with the LRT (with the CvM statistic being non-significant).  

%% TODO Illustrate with graphs?


%% THE FOLLOWING HAS BEEN MOVED
%% \begin{figure}
%% \caption{Get Continuous Estimate DM Alternative Way}
%% \label{fig:conti1res}
%% \setkeys{Gin}{width=\textwidth}
%% <<conti1res, fig=TRUE, height=7, width=7>>=
%% DM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="DM", fplot=TRUE) 
%% DM
%% @
%% \end{figure}

%% \begin{figure}
%% \caption{Get Continuous Estimate CvM Alternative Way}
%% \label{fig:conti2res}
%% \setkeys{Gin}{width=\textwidth}
%% <<conti2res, fig=TRUE, height=7, width=7>>=
%% CvM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="CvM", fplot=TRUE) 
%% CvM
%% @
%% \end{figure}


%% <<conti3resmaxLM>>=
%% maxLM<-sctest(reduced, as.numeric(yg$agegroup), parm=1:4, stat="maxLM", fplot=FALSE) 
%% maxLM
%% @
The tests carried out here assume a unique ordering of individuals by age, but 
this is obviously not the case.  To compute the statistics and $p$-values, 
the strucchange package implicitly assumed an arbitrary ordering of 
individuals who are tied on age.  If we were to change this ordering, 
the resulting statistics and $p$-values would also change, which is obviously problematic.  
To accurately account for the multiple observations  
at the same age level, we must use the ordinal tests from 
Equations~\eqref{eq:wdm} and~\eqref{eq:maxlmo}.  These are described next.

\subsection{Ordinal Treatment}

%% As a matter of fact, there is only a partial ordering of individuals 
%% with respect to $V$,i.e. observations with the same level 
%% of $V$ have no unique ordering. The ordinal statistics 
%% proposed here are similar to those described in Equation 
%% and above, except that we focus on "bins" of individuals 
%% at each level of the ordinal variable.  
The main difference between the ordinal test statistics and their
continuous counterparts is that the ordinal statistics do not require
an ordering of individuals  
within the same age group.  To compute the test statistics, we allow
the scores of all tied individuals to enter the cumulative sum
(Equation~\eqref{eq:cumscore}) simultaneously.  This results in
modified critical values and test statistics that are sensitive to
measurement invariance violations that are monotonic with age group.
%% Therefore, this ordinal test should 
%% reflect more real status of the data. In terms of code, we still need the gefp 
%% function to get the B estimate. After that, we can use different 
%% functions to aggregate and scale B estimation. 
%% The function are called ordwmax and ol2bb1.fun, respectively. 

To carry out the tests, we can rely on the same function that we used
for the continuous test statistics.  As mentioned previously,
calculation of the $\max\mathit{LM}_o$ statistic (Equation~\eqref{eq:maxlmo})
can be lengthy from the need to simulate critical values.
%% This is more complicated than necessary, but it is written like
%% this so that we can load the ordinal critical values behind the
%% scenes without confusing the reader.
<<critvals,echo=FALSE,strip.white=all>>=
if(file.exists("opval1.rda")){
  load("opval1.rda")
} else {
  gefp1 <- gefp(reduced, fit = NULL, order.by = as.numeric(yg$agegroup),
                vcov = info_full, sandwich = FALSE, parm = 1:4)
  opval1 <- ordL2BB(gefp1)
  save(opval1, file="opval1.rda")
}
## Get test statistics using fnl=opval1 without showing it in the paper
wdmo <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "WDMo")
maxlmo <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "maxLMo",
                 fnl = opval1)
@ 
<<ordtest,eval=FALSE,strip.white=all>>=
wdmo <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "WDMo")
maxlmo <- sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "maxLMo")
@ 
<<pval,strip.white=all>>=
round(c(wdmo$p.value, maxlmo$p.value), 2)
@ 
In computing the ordinal test statistics, we
obtain~$p=\Sexpr{round(wdmo$p.value,2)}$
and~$p=\Sexpr{round(maxlmo$p.value,2)}$, respectively.
Both $p$-values are clearly larger than that of the 
likelihood ratio test and neither is significant at $\alpha=0.05$. 
This provides evidence that there is no measurement
invariance violation that is monotonic with age group.  Instead, given
the large sample size, the likelihood ratio test may be overly
sensitive to anomalous, non-monotonic violations at one (or a few) age groups.

In addition to test statistics, ``instability plots'' can be generated by using the \verb+fplot=TRUE+ argument within \verb+sctest.lavaan()+. Plots representing the statistics' fluctuations across levels of age group are displayed in Figure~\ref{fig:ordres}.  The left panel displays the process associated with $\mathit{WDM}_o$, and the right panel displays the process associated with $\max\mathit{LM}_o$. 
%The following sentence is not correct for all statistics:  
%In both cases, the test statistics in the sequence assess a split of the observations up to age group $i$ vs. greater than $i$, and the null hypothesis is rejected if the maximum of the statistics is larger than its 5\% critical value(visualized by the horizontal red line). 
These plots display the loadings' fluctuation across age groups, with the x-axis reflecting age group and the y-axis reflecting test statistic values (larger values reflect more instability).  The red lines reflect critical values, so that the hypothesis of measurement invariance is rejected if a black line crosses the red line.  While the measurement invariance tests are non-significant, the plots imply some instability in the older age groups (15 and 16).


%% gefp1<gefp(reduced,fit=NULL,order.by=as.numeric(yg$agegroup),
%%        vcov=info_full,sandwich=FALSE,parm=1:4)
%% pval.ord=rep(NA,2)
%% pval.ord[1]<-sctest(gefp1,functional=ordwmax(gefp1))$p.value


%%pval.ord[2]<-sctest(gefp1, functional=opval1)$p.value
%% pval.ord
%% @

%Or alternatively, we could use the sctest.lavaan function, but assign ordinal statistics.
\begin{figure}
\caption{Fluctuation processes for the $\mathit{WDM}_o$ statistic (left panel) and the $\max\mathit{LM}_o$ statistic (right panel).}
\label{fig:ordres}
\setkeys{Gin}{width=\textwidth}
<<ordres, fig=TRUE, height=3, width=6, echo=FALSE, results=hide>>=
par(mfrow = c(1, 2), cex = 0.65)
sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "WDMo", 
       fplot = TRUE, ylim = c(0,3.5), xlab = "Age group",
       ylab = "Weighted max statistics", axes = FALSE)
axis(1, at = 1:5, labels = c("10-11", "12-13", "14", "15", "16"))
box()

sctest(reduced, as.numeric(yg$agegroup), parm = 1:4, stat = "maxLMo", 
       fnl = opval1, fplot = TRUE, ylim = c(0,14), xlab = "Age group",
       ylab = "LM statistics", axes = FALSE)
axis(1, at = 1:5, labels = c("10-11", "12-13", "14", "15", "16"))
box()
@
\end{figure}


%% TODO Describe graphs
%% Is there some argument for fplot=TRUE so user can change  axis-name and critical value line

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the above sections, we have illustrated the score-based tests'
computation in R.  We suspect that the ordinal tests will be most
popular with users, because measurement invariance tests are typically
carried out across categories (ordered or not), as opposed to
continuous variables.  Thus, in the sections below, we conduct
novel simulations to study the ordinal statistics' expected behavior
in practice.  In particular, we wish to study (i) the extent to which the
ordinal statistics attribute measurement invariance violations to the
correct parameter(s), and (ii) the extent to which the tests are
robust to model misspecification.


\section{Simulation 1}

In Simulation 1, we examined the extent to which the proposed tests
are sensitive to the specific model parameter that violates measurement
invariance.  If, say, a factor loading violates measurement
invariance, it is plausible that this violation impacts other
parameter estimates, including factor covariances or other loadings 
associated with the factor in question.  Thus, the goal of the
Simulation 1 is to examine the extent to which the proposed tests
attribute the measurement invariance violation to the parameters that
are truly in violation.  

\subsection{Methods}

To examine these specificity issues, we generated data from a
two-factor model with three indicators each (see Figure~\ref{fig:path}).
The measurement invariance
violation occurred in one of three places: the factor loading associated with Scale 1 
 ($\lambda_{11}$), the unique variance associated with Scale 1
 ($\psi_{11}$), or the factor covariance $\sigma_{12}$.  
 We then tested for measurement invariance in five subsets of parameters: the three
individual parameters noted above, all six factor loadings, % $\lambda_{11}--\lambda_{62}$, and 
and all six unique variances. % $\epsilon_{11}--\epsilon_{66}$.


%\begin{figure}
%\caption{Path diagram representing the factor analysis model 
%         used for simulations.}
%\label{fig:path}
%\includegraphics{PathDiagram}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Plot Code

\begin{figure}
    \caption{General model used for the simulations.}
    \label{fig:path}
\begin{tikzpicture}
[latent/.style={circle,draw=black!50,fill=white!20,thick,
                inner sep=0pt, minimum width=20mm, minimum height=10mm},
 manifest/.style={rectangle,draw=black!50,fill=white!20,thick,
                inner sep=0pt,minimum width=20mm, minimum height=10mm},
 error/.style={circle,draw=black!50,fill=white!20,thick,
                inner sep=0pt, minimum width=10mm},
 post/.style={->,shorten >=1pt,>=stealth',semithick},
 sling/.style={<->,shorten >=1pt,>=stealth',shorten <=1pt,>=stealth',auto,distance=20mm,semithick},
 errorsling/.style={<->,shorten >=1pt,>=stealth',shorten <=1pt,>=stealth',auto,distance=10mm,semithick}]



%position objects.

\node[latent] (VERBAL) at (0,4) {VERBAL};
\node[latent] (MATH)   at (0,0) {MATH};

\node[manifest] (SCALE1) at(5,6) {SCALE1};
\node[manifest] (SCALE2) at (5,4.5) {SCALE2};
\node[manifest] (SCALE3) at (5,3) {SCALE3};
\node[manifest] (SCALE4) at(5,1) {SCALE4};
\node[manifest] (SCALE5) at (5,-0.5) {SCALE5};
\node[manifest] (SCALE6) at (5,-2) {SCALE6};

\node[error] (E1) at (7,6) {E1};
\node[error] (E2) at (7,4.5) {E2};
\node[error] (E3) at (7,3) {E3};
\node[error] (E4) at (7,1) {E4};
\node[error] (E5) at (7,-0.5) {E5};
\node[error] (E6) at (7,-2) {E6};

%arrows, slings and texts
\node[latent] (VERBAL) at (0,4) {VERBAL}
   edge [post] node[above=0.01cm,text width=2cm]{\scriptsize{$\lambda_{11}=4.92$}} (SCALE1)
   edge [post] node[above=0.001mm,text width=2cm]{\scriptsize{$\lambda_{21}=2.96$}} (SCALE2)
   edge [post] node[above=0.1cm,text width=2cm]{\scriptsize{$\lambda_{31}=5.96$}} (SCALE3)
   edge [sling,bend right=100] node[auto,swap]{1}(VERBAL.-180)
   edge [sling,bend right=70] node[auto,swap]{$\phi_{12}=-0.48$}(MATH)  ;

\node[latent] (MATH) at (0,0) {MATH}
   edge [post] node[above=0.01cm,text width=2cm]{\scriptsize{$\lambda_{42}=3.24$}}(SCALE4)
   edge [post] node[above=0.01cm,text width=2cm]{\scriptsize{$\lambda_{52}=4.32$}}(SCALE5)
   edge [post] node[above=0.25cm,text width=2cm]{\scriptsize{$\lambda_{62}=7.21$}}(SCALE6)
   edge [sling,bend right=100] node[auto,swap]{1}(MATH.270);

\node[error] (E1) at (7,6) {E1}
   edge [post] node[auto,swap]{\small{1}}(SCALE1)
   edge [errorsling, bend right=100]node[right=0.1,text width=2cm]{\scriptsize{$\psi_{11}=26.77$}} (E1.45);
\node[error] (E2) at (7,4.5) {E2}
   edge [post] node[auto,swap]{\small{1}} (SCALE2)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{22}=13.01$}}(E2.45);
\node[error] (E3) at (7,3) {E3}
   edge [post] node[auto,swap]{\small{1}}(SCALE3)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{33}=30.93$}}(E3.45);
\node[error] (E4) at (7,1) {E4}
   edge [post] node[auto,swap]{\small{1}}(SCALE4)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{44}=3.17$}}(E4.45);
\node[error] (E5) at (7,-0.5) {E5}
   edge [post] node[auto,swap]{\small{1}}(SCALE5)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{55}=8.82$}} (E5.45);
\node[error] (E6) at (7,-2) {E6}
   edge [post] node[auto,swap]{\small{1}}(SCALE6)
   edge [errorsling, bend right=100] node[right=0.1,text width=2cm]{\scriptsize{$\psi_{66}=22.5$}}(E6.45);

\end{tikzpicture}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Power and Type I error were examined across three sample sizes
($n=120,480,960$), three numbers of categories ($m=4,8,12$) and
17 magnitudes of invariance violations. 
The measurement invariance violations began at level $1+m/2$ of $V$
and were consistent thereafter: individuals below
the $1+m/2$ percentile of $V$ deviated from individuals above the $1+m/2$ 
percentile  by $d$ times the parameters' asymptotic standard errors
(scaled by $\sqrt n$), with $d=0,0,25,0.5,...,4$. 
For each combination of sample size ($n$) $\times$ violation
magnitude ($d$) $\times$ violating parameter $\times$ categories $m$, 5000 datasets were
generated and tested.  Statistics from Equations~\eqref{eq:wdm}, ~\eqref{eq:maxlmo} and~\eqref{eq:lmuo} were examined. In all conditions, we maintained equal sample sizes at each level of the ordinal variable. 

\subsection{Results}

Full simulation results are presented in Figure~\ref{fig:sim11res} to 
Figure~\ref{fig:sim13res}; 
Figure~\ref{fig:sim11res} displays power curves as a function of 
violation magnitude for the first
factor loading $\lambda_{11}$, with panels reflecting the parameters 
being tested and lines reflecting $n$.
Figures~\ref{fig:sim12res} and Figure~\ref{fig:sim13res} display 
similar power curves when the factor covariance 
$\phi_{12}$ and error variance $\epsilon_{11}$ violate measurement
invariance, respectively. 
All three test statistics exhibited 
similar results, with $\max\mathit{LM}_{uo}$ demonstrating lower power across all situations.  As described earlier, this statistic 
is asymptotically equivalent to the LRT.  $\mathit{WDM}_o$  and $\max \mathit{LM}_o$ exhibited equivalent power curves because, when only one parameter is tested, the statistics are equivalent. 


From these figures, one generally observes that the tests isolate 
the parameter violating measurement invariance.  Additionally, the tests 
have somewhat-higher power to detect measurement invariance violations 
in the factor loading and factor covariance parameters, as opposed to the error variance
parameter.  Finally, simultaneous tests of all factor loadings or all error
parameters result in decreased power, as compared to the situation
where one tests only the violating parameter.  This occurs because, in
testing a subset of parameters (only one of which violates measurement
invariance), we are effectively dampening the signal of a measurement
invariance violation.  


In summary, we found that the proposed tests can attribute
measurement invariance violations to the correct parameter.  This
provides evidence that, in practice, one can have confidence in the
tests' abilities to locate the measurement invariance violation.  Of
course, this statement is qualified by the fact that, in this
simulation, the model was correctly specified.  In the following
simulation, we examine the tests' performance when the model is
misspecified. 

<<sim1,echo=FALSE>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim1.rda")) {
  load("sim1.rda")
} else {
  sim1 <- simulation(sim = "sim1", nobs = 480, parms = c("loading", "error", "var"))
  sim1$nlevels <- factor(sim1$nlevels)
  levels(sim1$nlevels) <- paste("m=", levels(sim1$nlevels), sep="")
 
  sim1$nobs <- factor(sim1$nobs)
  levels(sim1$nobs) <- paste("n=", levels(sim1$nobs), sep="")
  levels(sim1$test) <- c("maxLM_O", "WDM_O", "LM_uO")
  save(sim1, file="sim1.rda")
}
sim1$test <- factor(as.character(sim1$test),
  levels = c("ordmax", "ordwmax", "catdiff"),
  labels = c("maxLM_o", "WDM_o", "LM_uo"))
  parlabs <- c(expression(lambda[11]), expression(phi[12]), 
               expression(psi[11]), expression(lambda[11] - lambda[62]), 
               expression(psi[11] - psi[66]))
  levels(sim1$pars) <- c("Loading1", "Covariance", "Error1", "All Loadings", "All Errors")  
@

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ test, $\mathit{WDM}_o$ test, and $\mathit{LM}_{uo}$ test across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$). The parameter violating measurement 
invariance is $\lambda_{11}$.}
\label{fig:sim11res}
\setkeys{Gin}{width=\textwidth}
<<sim11res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim1,
             subset = (parms == "loading" & 
                       pars %in% c("Loading1", "All Loadings", "All Errors") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab = "Power", key=mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(1, 4:5)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ tests, $\mathit{WDM}_o$ test $\mathit{LM}_{uo}$ across three levels of the ordinal variable $m$, and measurement invariance violations of 0--4 standard errors (scaled by $\sqrt{n}$). The parameter violating measurement invariance is $\sigma_{12}$}
\label{fig:sim12res}
\setkeys{Gin}{width=\textwidth}
<<sim12res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim1,
             subset = (parms == "var" & 
                       pars %in% c("Covariance", "All Loadings", "All Errors") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab="Power", key = mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(2, 4:5)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ test, $\mathit{WDM}_o$ test, and $\mathit{LM}_{uo}$ test across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$). The parameter violating measurement invariance is $\psi{11}$}
\label{fig:sim13res}
\setkeys{Gin}{width=\textwidth}
<<sim13res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim1$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim1,
             subset = (parms == "error" & 
                       pars %in% c("Error1", "All Loadings", "All Errors") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab = "Power", key = mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(3,4:5)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}




\section{Simulation 2}
In Simulation 2, we examine the extent to which the results of
Simulation 1 are robust to model misspecification.  Specifically, we
generate data from the factor analysis model used in the previous
section, except that the model contains an extra loading from the second factor to Scale 1.
The estimated model matches that displayed in Figure~\ref{fig:path}, however, resulting in model misspecification.  The goal of this simulation is to examine the proposed statistics'
power and specificity under this misspecification.

\subsection{Method}
Measurement invariance violations could occur in
each of the three parameters from Simulation 1 (factor loading, factor covariance, and unique variance), and they could also occur in the extra, unmodeled loading. In each condition, a single parameter exhibited the violation.
Sample size and magnitude of measurement invariance violation were manipulated 
in the same way as they were in Simulation 1.  The tested parameters were also the same as Simulation
1.

\subsection{Results}
Results are presented by the parameter that violated measurement invariance.
Of primary interest is Figure~\ref{fig:sim21res}, which displays results when the unmodeled loading violates 
measurement invariance.  One can generally observe that 
tests of the first loading and error variance parameter exhibited high power, reflecting a high Type I error rate.  Tests associated with the factor covariance did not demonstrate this error, however. In terms of specific statistic performance, $\max \mathit{LM}_o$ test and $\mathit{WDM}_o$ test demonstrated higher Type I error than $\mathit{LM}_{uo}$ in each panel, especially with increasing levels.  This is likely because the unmodeled loading's noninvariance was monotonic with $V$; if it were not monotonic, we would expect $\mathit{LM}_{uo}$ to have higher Type I error. 

When the modeled factor loading, $\lambda_{11}$, violated
measurement invariance, the statistics were generally able to pick up the violation despite the misspecification.
A similar pattern of specificity and power were observed when the unique variance and factor covariance parameters violated measurement invariance; the figures associated with these results are shown in the Appendix. Also, the power of ordered statistics $\max \mathit{LM}_o$ test and $\mathit{WDM}_o$ test showed higher power than unordered $\mathit{LM}_{uo}$ in each of these panels. 

In summary, the proposed test statistics appear robust to unmodeled loading parameters, so long
as the umodeled parameter does not violate measurement invariance.  If the unmodeled parameter 
dose violate measurement invariance, however, then the tests assign this violation to other 
parameters that do not violate measurement invariance.  The impacted parameters include the error
variance and other loadings associated with the manifest variables that had the unmodeled 
loading.  Thus, as it is with other tests of measurement invariance, it is important to study the extent to
which the hypothesized model includes all parameters of importance.

<<sim2,echo=FALSE>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim2.rda")) {
  load("sim2.rda")
} else {
  sim2 <- simulation(sim = "sim2", nobs = 480, 
  parms = c("extra", "extra+loading", "extra+var", "extra+error"))

  save(sim2, file="sim2.rda")
}
sim2$test <- factor(as.character(sim2$test),
  levels = c("ordmax", "ordwmax", "catdiff"),
  labels = c("maxLM_o", "WDM_o", "LM_uo"))
  sim2$nlevels <- factor(sim2$nlevels)
  levels(sim2$nlevels) <- paste("m=", levels(sim2$nlevels), sep="")
  sim2$nobs <- factor(sim2$nobs)
  levels(sim2$nobs) <- paste("n=", levels(sim2$nobs), sep="")
  parlabs <- c(expression(lambda[11]), expression(phi[12]), 
               expression(psi[11]), expression(lambda[11] - lambda[62]), 
               expression(psi[11] - psi[66]))
  levels(sim2$pars) <- c("Loading1", "Covariance", "Error1", "All Loadings", "All Errors") 

@ 



\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ test, $\mathit{WDM}_o$ test, and $\mathit{LM}_{uo}$ test across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$). The parameter violating measurement invariance is the unmodeled loading.}
\label{fig:sim21res}
\setkeys{Gin}{width=\textwidth}
<<sim21res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
             subset = (parms == "extra" & 
                       pars %in% c("Loading1", "Error1", "Covariance") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab = "Power", key = mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(1, 2:3)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}


\section{General Discussion}


In this paper, we first described a novel family of test statistics for measurement invariance and illustrated their use via the R package lavaan.  Next, we examined these statistics' abilities to identify the parameter violating measurement invariance under well-specified and misspecified models.  We found the proposed statistics could generally isolate the model parameter violating measurement invariance, so long as the violating parameter is included in the model.

In the reminder of the paper, we will first consider the applicability of these tests as compared to traditional tests.  Next, we discuss test extension to other fit functions and to other specialized models.


\subsection{Applications}

Many of the applications in this volume, along with many applications in general, focus on testing for measurement invariance across unordered categories such as nations or gender.  As discussed earlier in this paper, the score-based tests for unordered categories are essentially equivalent to the usual likelihood ratio test.  Given a measurement invariance violation across these unordered categories, however, researchers typically wish to know why the violation occurred.  At this point, researchers may examine education level, socioeconomic status, income levels, and so on across the unordered categories.  These variables are often ordinal or continuous in nature, so that the family of tests described in this paper are applicable.  This is a first step towards describing why measurement invariance violations occur, as opposed to simply detecting measurement invariance violations. \readme{In the abstracts for the special issue (which the special editors sent us), one paper was proposed along these lines.  I will get a draft of that paper and then we can cite it here.}
The tests are convenient for this purpose, as they do not require a new model to be estimated for each ordinal variable.  Instead, each ordinal variable defines an ordering of observations, which in turn yields a test statistic that is specific to that ordinal variable.

%% I'm not sure we want to make a big deal of this.  If there are only a small number of ties, we are probably better off with the continuous tests:
%These ordinal tests are useful in behavioral and social science in general, since the truly continuous auxiliary variable is hard to find in real research context. It is very common to observe several individuals with the same age, IQ, income rank, etc. Therefore, the ordinal tests which dealing with multiple ties in auxiliary variable is more suitable than the continuous test. 

%Moreover, even though researchers might be originally interested in comparing categorical differences. For example, researchers might want to test whether there is gender difference or cultural difference for the scale. Using traditional likelihood test or wald test, there might existing some differences regarding to the categorical variable. Then the next natural question would be why there is gender or culture differences? . Thus these test statistics offer an convenient assessing tool to further exploring research hypothesis without making complicated assumptions or fitting multiple different models.

\subsection{Extension}
In this paper, We focused on testing for measurement invariance in factor analysis models that assume multivariate normality and that are estimated via ML.  The family of tests described here generally apply to estimation methods that maximize/minimize a fit function, however \cite<see>{zeihor07}, so they are potentially applicable to alternative SEM discrepancy functions such as Weighted Least Squares \cite<e.g.,>{broarm95}.  Score calculation for these alternative discrepancy functions has not been implemented (to our knowledge), though the calculation certainly could be implemented.  Test statistic calculation and inference would then proceed in exactly the same manner as the calculation and inference illustrated in this paper.

In addition to alternative fit functions, the tests can be extended to other models estimated via ML.  Of primary interest to the topic of measurement invariance, the tests can be extended to item response models to examine differential item functioning.  In particular, \citeA{strkop13} studied application of these tests to the Rasch model, using them as the basis of a recursive partioning procedure that segments subgroups of individuals who exhibit DIF.  Further study and extension of these tests for IRT seem warranted.

% Removed for now:
%% \subsection{Conclusion}
%% \readme{Not sure whether we need this paragraph, but I still need to think about it.}
%% In summary, the ordinal test statistic proposed have relatively-high power for detecting measurement invariance violation parameter specifically that are monotonic with the auxiliary ordinal variable. This
%% feature is robust as long as the violation parameter is included in the testing model. Furthermore, as illustrated in tutorial part, the use of these tests is convenient without changing the focal psychometric model. In all, the tests have advantageous properties that should be implemented in practice.
   




\section*{Computational Details}

All results were obtained using the {R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on package
{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} for fitting 
of the factor analysis models and
{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. {R}~and the packages {lavaan} and 
{strucchange} are
freely available under the General Public License~2 from the
Comprehensive {R} Archive Network at \url{http://CRAN.R-project.org/}.
{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.


\bibliography{refs}

\section{Appendix}

This Appendix includes the results for Simulation 2 when there exists model misspecification (lacking one path from Scale 1 to Math). Figure~\ref{fig:sim22res} to Figure~\ref{fig:sim24res} display results when the loading $\lambda_{11}$, covariance $\sigma_{12}$, and 
error term $\psi_{11}$ violate invariance, respectively. 

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ test, $\mathit{WDM}_o$ test, and $\mathit{LM}_{uo}$ test across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is $\lambda_{11}$.}
\label{fig:sim22res}
\setkeys{Gin}{width=\textwidth}
<<sim22res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
             subset = (parms=="extra+loading" & 
                       pars %in% c("Loading1", "All Loadings", "All Errors") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab = "Power", key = mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(1, 4:5)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ test, $\mathit{WDM}_o$ test, and $\mathit{LM}_{uo}$ test across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is $\sigma_{12}$.}
\label{fig:sim23res}
\setkeys{Gin}{width=\textwidth}
<<sim23res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
             subset = (parms=="extra+var" & 
                       pars %in% c("Covariance", "All Loadings", "All Errors") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab = "Power", key = mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(2, 4:5)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}

\begin{figure}
\caption{Simulated power curves for $\max \mathit{LM}_o$ test, $\mathit{WDM}_o$ test, and $\mathit{LM}_{uo}$ test across three levels of the ordinal variable $m$ and measurement invariance 
violations of 0--4 standard errors (scaled by $\sqrt{n}$). The violation parameter is $\psi_{11}$.}
\label{fig:sim24res}
\setkeys{Gin}{width=\textwidth}
<<sim24res, fig=TRUE, height=7, width=7, echo=FALSE>>=
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(levels(sim2$test), points = TRUE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + pars, group = ~ test, data = sim2,
             subset = (parms == "extra" & 
                       pars %in% c("Error1", "All Errors", "All Loadings") & diff %% 0.5 == 0),
             type = "b", xlab = "Violation Magnitude", ylab = "Power", key = mykey,
             strip = function(..., which.given, factor.levels){
                 if(which.given == 2){
                     strip.default(which.given, factor.levels = parlabs[c(3, 4:5)], ...)
                 } else {
                     strip.default(which.given, factor.levels = factor.levels, ...)
                 }
             }))
@

\end{figure}

\end{document}
