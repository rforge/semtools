Reviewer 1

Nice paper, very interesting. This is cased on, and so disseminates, excellent recent work (the Merkle papers). R implementation are a great contribution in addition to the theoretical work. I have some comments, which the authors may wish to consider. 

comments 

Comment 1.1. The exact contribution could be made clearer. I understand that the method has already been developed and implemented and applied to real data and in simulation. In the present paper, the method is explained and applied to real data and in simulation. Do the simulations results add to the existing results? This the application new? As mentioned, I do not think that the explanation of the method per se is particularly tutorial in nature. If the R worked example is the main message, please state this. 

Response 1.1. We intended the "tutorial" part to include the method overview (less technical than previous papers) and the R examples.  The simulations that follow the tutorial are novel, in the sense that they examine test properties that were not examined in previous simulations.  In general, we see the paper as being useful for applied researchers who are mainly interested in the method's practical use.  We have added some detail on this to the introduction.

Ting: In the paragraph before "Background", you can add some small details to emphasize the unique contributions of this paper.


Comment 1.2. p. 2 " the development of test statistics that are sensitive to invariance violations of interest and insensitive to "anomalous" invariance violations". 

Quite unclear. Restate for clarity. I mean: from the preceding single sentence "anomalous" is not clear. You mean that the tests are sensitive to the violations of interest and insensitive to violations not of interest? 

Response 1.2. We have edited this sentence for clarification.


Comment 1.3. p.2 "The test statistics are specifically applicable to situations where one wishes to test for measurement invariance with respect to an ordinal variable, and they are special cases of a family of tests that may be used to study measurement invariance w.r.t. continuous, categorical, and ordinal variables" 

The reader may know MI w.r.t. nominal variables (e.g., sex), but not w.r.t continuous variables, which is more complicated. Please add references, and perhaps elaborate a little on the framework? 

Response 1.3. We add references of Meredith, 1993; Dolan & van der Maas, 1998; Lubke & Muthen, 2005. Readers who want to know more about the framework could refer to the reference. Elaboration at this part might divert readers from the core of this paper.  

Ting: I will add some detail here.


Comment 1.4. p.2-3. "The cross-product of these scores forms the "meat" for the calculation of robust (Huber-White) standard errors (e.g., Zeileis, 2006b)." That is true, but why is this mentioned? This paper is not about robust standard errors. 

Response 1.4. We agree. This sentence is deleted. 


Comment 1.5. p.3. "To verbally describe the above equation, each individual has k scores describing the extent to which the fitted model describes that particular individual. Scores close to zero indicate a \good" description, and scores far from zero indicate a \bad" description". Strange to my ears: the score varies naturally in a correctly specified model applied to a finite sample, representative of the population of interest. If each person's observed scores are realizations of the process of interest, how does in this situation the score count as an measure of individual goodness of fit? The parameters in the model pertain to covariance matrices or mean vectors (aspects of distributions). Below we read: "Conversely, if measurement invariance holds, then all individuals' scores will fluctuate randomly around zero". So here the fluctuation is consistent with well fitting model? 

Response 1.5. We have revised this text.  If all individuals arise from the same population, the scores will fluctuate around zero.  Some scores may indeed be far from zero, but this will not occur often.  On the other hand, if there exist multiple subgroups of individuals with different parameter values, the scores should systematically stray from zero.  So the general answer is that fluctuation always occurs, but the fluctuation should be around zero under measurement invariance (and should trend away from zero under noninvariance).


Comment 1.6. p.3 "If the manifest variables violate measurement invariance here,…" As "a test is MI w.r.t a variable", or "MI w.r.t. a variable may be violated", this is a strange personification of "manifest variables", do they do the violating? 

Response 1.6. We changed the sentence to state "If there exists measurement invariance w.r.t. age". 


Comment 1.7. p.3. eq. 2. Hard to follow. Does one choose increasing values of t? If so, how (given that t varies continuously between 0 and 1)? "Thus, the process associated with one parameter is not correlated with the processes associated with other parameters". This transform the scores to uncorrelated standardized variables, right? Following this transformation, how can I relate the fluctuation in a component of B(t,theta) to the original parameter? 

Response 1.7. Because we take the integer part of nt, we can allow t to vary from 1/n, 2/n, 3/n, ..., n/n.  We have added this detail to the paper.  Additionally, it is correct that premultiplication by the square root of the information matrix creates uncorrelated, standardized variables.  The decorrelation still preserves information about individual variables within the original rows, however.

 
Comment 1.8. p.3. Under the hypothesis of measurement invariance, a central limit theorem can be used to show that the fuctuation of the above cumulative sum follows a Brownian bridge." Perhaps add ref for Brownian bridge? Or can we assume that the readership is familiar with this?

Response 1.8. We add reference (Hjort & Koning, 2002). 

Ting: I think we also need a more general reference about Brownian bridges; I can find one.


Comment 1.9. p.5. "We focus on measurement invariance of the factor loadings associated with the GQ-6 scale, using a one-factor model". Now many items? 5 I gather later on. How scaled? By fixing 1 factor loading to 1 (I assume?). The latent variance varies over group? It would be useful to state explicitly the exact model which provides the scores. The full MI includes equality of factor loadings, intercepts and residual variances, but not common factor means (alpha_i) or common factor (co)variances (Phi_i), where i is group in the standard multivariate case (but continuous here). In applying this method with continuously varying age in mind, how does one fit the MI model given that the grouping variable is continuous and alpha_i and Phi_i are free to vary conditional on the grouping variable? Does the R cfa restr <- cfa("f1 = ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5", data = yg, group = "agegroup", meanstructure = TRUE, group.equal = "loadings") only include equal loadings? Does one implement this method in the full MI model, or partial MI model? This should be made clear as it is important. 

Response 1.9. We have added model details to the paper.  In particular, we set the scale by fixing the first factor loading to 1 and fit a partial MI model by restricting only the loadings to be equal across group.  Additionally, as we now state, the method can generally be applied to full MI and partial MI models so long as the grouping variable is ordinal.

The "continuous V" situation is somewhat different: here, we have no ties along V, and we cannot fit a model where the factor mean varies for every individual in the sample.  If the model is sufficiently identified, we can at least test whether an estimated factor mean fluctuates with V (the data example of Merkle & Zeileis, 2013 contains one example).  If the factor mean does not fluctuate with V, then we can continue with further tests of other model parameters.

Ting: There is a subtle issue for continuous V, and I added that detail to this response..


Comment 1.10. p. 9. "The measurement invariance violation occurred in one of three places: the factor loading associated with Scale 1 (lambda11), the unique variance associated with Scale 1 (psi11), or the factor covariance phi12." I do not understand that phi12 can be the locus of a violation of MI, as the definition of MI does not include any constraints on the common factor covariance matrix. It would make more sense to consider an intercept. 

Response 1.10. Correct, the condition with phi12 is not "measurement invariance" per se, but it is still an instability that could occur in the model.  We have added more detail here and also added a condition for the intercept.

Ed: I remember the intercepts simulation power are always near zero, regardless of the magnitude. But my question is also why intercepts' measurement invariance violation can't be detected? Do you think we should run the simulation to verify that? (The code is easy to adapt, time is probably the issue.)


Thanks; we appreciate the feedback.



Reviewer 2

Comment 2.1. This paper appears to aim for an audience of practitioners, who want to know how score-based testing can be implemented and what could be obtained from it. The explanation of the use of R-routines is particularly helpful, although I am a bit skeptical as to its use in large covariance structure analyses (LISREL type). 

Response 2.1. The theory underlying these tests implies that they are applicable to general models fit via ML.  We have not examined models that are more complex than those in the paper, though our R implementation would make this easy to do so in the future.
 

Comment 2.2. Your exposition of the logic of the approach may be too short for your intended audience, your other papers are much more informative. But if the paper is part of a special issue where other authors also deal with the same issues, a further elaboration is perhaps not needed(?). 

Response 2.2. We agree that there is some missing technical detail, and we are attempting to write the description in such a way that applied researchers can get the idea and carry out the methods.  We have added some detail but suspect that it may still not be enough for sophisticated readers (who we can at least refer to our Psychometrika papers).  


Comment 2.3. For expository purposes, making it more concrete, it might be helpful though to specify how it would work for GLS: the cumulative sum would be some matrix, with a probability limit, times terms containing the cross-products of individual observation vectors minus sigma (the same under the null hypothesis). 

Response 2.3. Thanks for the suggestion. Reviewer 1 also mentioned about this. We added illustration to the cumulative sum score matrix. 

Ed: I think this point is the same as reviewer 1 wanted to some illustration for eq 2. 

Ting: I'm not sure what he means by "GLS": is he talking about regression or SEM?  I guess regression?


Some additional comments: 

Comment 2.4. I find your reference to the Huber-White robust standard errors a bit 'cavalier'. Are you referring to the situation where the model specifies a covariance structure, say, but is otherwise agnostic about the distribution, and “i.i.d.” can be maintained as a null hypothesis? For more general cases, with varying exogenous variables .e.g. the case for Huber-White is much less clearcut. See e.g. Chapter 17, 'On the so-called 'Huber Sandwich Estimator' and 'Robust Standard Errors'', in 'Statistical Models and Causal Inference by David Freedman (2010). 

Response 2.4. Because this sentence is not relevant to the current paper (and both reviewers commented on it), we have deleted it. 


Comment 2.5. The last paragraph on p.6 starting with 'Because' is not clear to me. You point out essentially that with a fixed p-value the LRT will eventually pick up even very small and inconsequential deviations from the null-hypothesis, and you offer the family of score-based testing as an alternative. So do they have less power? But you also claim somewhere that (8) is (asymptotically) equivalent to the LRT. 

Response 2.5. The test from (6) has less power to pick out inconsequential deviations than does the test from (8) or the LRT.  The LRT and test from (8) are asymptotically equivalent, but not the test from (6).  We have added this detail. 


Comment 2.6. P-values are very prominent in this paper, and 5% is close to sacred (this may be your perception of what practitioners think, which is a fair assumption in my experience, but may not be representative of what you personally believe, I for one fail to understand how this level has become so decisive). Nevertheless, I am concerned that the use of many statistics, each judged with respect to p=5%, makes it very hard to control the overall-level. The p-values are also not independent, so an aggregation using the log of the p-values (Fisher), will not be appropriate. In addition, you advocate the use of pictures and diagrams in testing the null-hypothesis. The end result will be a model that is random as well (a new sample could with the same approach easily lead to another model), based on an informal procedure that would not allow of a structured Monte Carlo type of sensitivity analysis. It appears that the statistical inference problems as induced by modeling and testing on the same data are unsurmountable: see e.g. H. Leeb and B.M. Poetscher (2005), 'Model selection and inference: facts and fiction', Econometric Theory, 21, 21-59. So I would emphasize that the end-result of the excercise is tentative, that the whole excercise is best seen as exploratory only, and that new data are needed for further testing and confirmation. 

Response 2.6. The p value is based on the data. The critical value can be got for any designated criteria, e.g. alpha=0.1 or 0.01. The traditional problem of testing inflating type I error does not apply in this context. The reason is that there is one hypothesis when we test multiple parameters. It is not the case that we test single parameters for multiple times. The plots are visual demonstration of the tests, so reflecting if the p value is larger or smaller than alpha. The test is not about replication. It is just based on the data at hand. 

Ting: I think we will want to modify this comment.  We can have multiple tests: say, we test 6 loadings then test 1 loading then test 6 error variances, etc.  So we can have inflated Type I error.  I think the best thing to do is add a sentence acknowledging the shortcomings of p-values and frequentist statistics.  Additionally, we can do Monte Carlo on the pictures/diagrams by identifying the peaks and seeing how often the peaks are in the right place (as we do in the next paper).


Comment 2.7. On the last lines on p. 13, just above the General Discussion, you point out that it is 'important to study to what extent the hypothesized model includes all parameters of importance, and that none of the tests inform about model misspecification'. The first statement imposes a rather daunting task, and will amplify the 'dangers' alluded to in 2.6. A pragmatic approach would be to use GLS as well: if the model is wrong, ML and GLS should not produce the same estimates, since they project the data along different angles on the model space. But at the end of the day the necessity to cross-validate on new data will still be paramount. 

R: The proposed tests aim to detect measurement invariance w.r.t. an auxilliary variable. Detecting model misspecification is not the purpose. Moreover, model misspecification won't be detected by different estimation method, either. 

Ed: I don't think there is difference in producing the score matrix and estimates. Is it true?

Ting: I think this is another one where we acknowledge shortcomings of the approach.  Also, it appears that "GLS" means "fitting an SEM by generalized least squares".


Thanks for the comments and suggestions. They helped to make the paper better. 
