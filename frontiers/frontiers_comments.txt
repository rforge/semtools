Reviewer 1

Nice paper, very interesting. This is cased on, and so disseminates, excellent recent work (the Merkle papers). R implementation are a great contribution in addition to the theoretical work. I have some comments, which the authors may wish to consider. 

comments 

The exact contribution could be made clearer. I understand that the method has already been developed and implemented and applied to real data and in simulation. In the present paper, the method is explained and applied to real data and in simulation. Do the simulations results add to the existing results? This the application new? As mentioned, I do not think that the explanation of the method per se is particularly tutorial in nature. If the R worked example is the main message, please state this. 

R: This paper in general serves to be a guidance to the proposed tests' use in practice. The tutorial part is supposed to show researchers how to implement the tests in R; The simulations results demonstrats the tests' two properties, which are of vital interest for application. Simulation 1 aims to show the specificity of the tests. Simulation 2 explores the robustness of tests to model misspecification. So to answer the reviwer's question, the simulations results have their own contributions and add to the existing literature.  

Ed: I don't know how to make changes in the paper for this point. What I responded above is already in the paper.

p. 2 " the development of test statistics that are sensitive to invariance violations of interest and insensitive to "anomalous" invariance violations". 

Quite unclear. Restate for clarity. I mean: from the preceding single sentence "anomalous" is not clear. You mean that the tests are sensitive to the violations of interest and insensitive to violations not of interest? 

R: Thanks for the suggestion. We changed that sentence to "the development of test statistics that are sensitive to monotonic w.r.t. ordinal variables of interest and less sensitive to non-monotonic violations."

p.2 "The test statistics are specifically applicable to situations where one wishes to test for measurement invariance with respect to an ordinal variable, and they are special cases of a family of tests that may be used to study measurement invariance w.r.t. continuous, categorical, and ordinal variables" 

The reader may know MI w.r.t. nominal variables (e.g., sex), but not w.r.t continuous variables, which is more complicated. Please add references, and perhaps elaborate a little on the framework? 

R: We add references of Meredith, 1993; Dolan & van der Maas, 1998; Lubke & Muth ́en, 2005. Readers who want to know more about the framework could refer to the reference. Elaboration at this part might divert readers from the core of this paper.  

Ed: I am not sure about these references.

p.2-3. "The cross-product of these scores forms the "meat" for the calculation of robust (Huber-White) standard errors (e.g., Zeileis, 2006b)." That is true, but why is this mentioned? This paper is not about robust standard errors. 

R: We agree. This sentence is deleted. 

p.3. "To verbally describe the above equation, each individual has k scores describing the extent to which the fitted model describes that particular individual. Scores close to zero indicate a \good" description, and scores far from zero indicate a \bad" description". Strange to my ears: the score varies naturally in a correctly specified model applied to a finite sample, representative of the population of interest. If each person's observed scores are realizations of the process of interest, how does in this situation the score count as an measure of individual goodness of fit? The parameters in the model pertain to covariance matrices or mean vectors (aspects of distributions). Below we read: "Conversely, if measurement invariance holds, then all individuals' scores will fluctuate randomly around zero". So here the fluctuation is consistent with well fitting model? 

R: If the parameter fits the individual well, the individual's score will be close to zero(no individual's score will be exactly zero, the score does naturally fluctuate.). The key word here is "close to zero", which indicates good description. On the other hand, if the individual's score is far from zero, which indicates bad description. The key word here is "far from". Below the sentence describes equation 2. Fluctuation randomly around zero is consistent with well fitting model. The key word is "around zero". 

Ed: I think the reviewer's question is that he missed the point of "around zero". Is it polite to say above responses? 

p.3 "If the manifest variables violate measurement invariance here,…" As "a test is MI w.r.t a variable", or "MI w.r.t. a variable may be violated", this is a strange personification of "manifest variables", do they do the violating? 

R:  Thanks for the suggestion. We changed that sentence part to "If there exists measurement invariance w.r.t. age". 

p.3. eq. 2. Hard to follow. Does one choose increasing values of t? If so, how (given that t varies continuously between 0 and 1)? "Thus, the process associated with one parameter is not correlated with the processes associated with other parameters". This transform the scores to uncorrelated standardized variables, right? Following this transformation, how can I relate the fluctuation in a component of B(t,theta) to the original parameter? 

R:  Because we take integer part of nt,  t can be interpreted as in the form of 1/n, 2/n, 3/n,...n/n. The decorrelation is done by \hat{I}^{-1/2}. This "transformation" didn't change the dimension of original score matrix. We just replace the scores by cumulative scores (ordering by auxillary variable V). We add some illustration to the paper. 

 
p.3. Under the hypothesis of measurement invariance, a central limit theorem can be used to show that the fuctuation of the above cumulative sum follows a Brownian bridge." Perhaps add ref for Brownian bridge? Or can we assume that the readership is familiar with this?

R: Thanks for the suggetion. We add reference (Hjort & Koning, 2002). 

p.5. "We focus on measurement invariance of the factor loadings associated with the GQ-6 scale, using a one-factor model". Now many items? 5 I gather later on. How scaled? By fixing 1 factor loading to 1 (I assume?). The latent variance varies over group? It would be useful to state explicitly the exact model which provides the scores. The full MI includes equality of factor loadings, intercepts and residual variances, but not common factor means (alpha_i) or common factor (co)variances (Phi_i), where i is group in the standard multivariate case (but continuous here). In applying this method with continuously varying age in mind, how does one fit the MI model given that the grouping variable is continuous and alpha_i and Phi_i are free to vary conditional on the grouping variable? Does the R cfa restr <- cfa("f1 = ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5", data = yg, group = "agegroup", meanstructure = TRUE, group.equal = "loadings") only include equal loadings? Does one implement this method in the full MI model, or partial MI model? This should be made clear as it is important. 

R: The scale is 1 to 9(We add that description to the paper). By fixing the first factor loading to 1(lavaan default setting). The latent variance varies over group(lavaan default setting). The full MI model described by the reviewer could be done by setting equal.group=c("loading", "intercepts", "residuals"). The R command for restr model shown in the paper only include equal loadings. The partial MI model could be done by argument group.partial=c("gq6_2~1") (the value in c() is an example, user can put any parameter they want to control). These are important to understand/specify the model , but not important for the proposed tests, for the reason that the tests only work on the cumulative score matrix.  As long as the model could get Maximum Likelihood estimation, the tests could be implemented. We add reference for researcher who wants to know more about model specification. 

Ed: I add the scale 1 to 9 to the paper. But I don't think it is a good idea to get down to the model specification part. I just add some sentence to direct readers to Yves' references.  

p. 9. "The measurement invariance violation occurred in one of three places: the factor loading associated with Scale 1 (lambda11), the unique variance associated with Scale 1 (psi11), or the factor covariance phi12." I do not understand that phi12 can be the locus of a violation of MI, as the definition of MI does not include any constraints on the common factor covariance matrix. It would make more sense to consider an intercept. 

R: We choose these parameters because they are the "locus" parameters for any factor analysis. phi12 is one of them. The MI definition mentioned by the reviewer is one realization of the general measurement invariance definition proposed by Mellenbergh, 1989. The intercepts' measurement invariance violation can't be detected by this method. 

Ed: I remember the intercepts simulation power are always near zero, regardless of the magnitude. But my question is also why intercepts' measurement invariance violation can't be detected? Do you think we should run the simulation to verify that? (The code is easy to adapt, time is probably the issue.)


Reviewer 2

This paper appears to aim for an audience of practitioners, who want to know how score-based testing can be implemented and what could be obtained from it. The explanation of the use of R-routines is particularly helpful, although I am a bit skeptical as to its use in large covariance structure analyses (LISREL type). 

R: As we replied to Reviewer 1, as long as there existes Maximum Likelihood estimation. Model complexity should not be the issue for the proposed tests. 
 
Your exposition of the logic of the approach may be too short for your intended audience, your other papers are much more informative. But if the paper is part of a special issue where other authors also deal with the same issues, a further elaboration is perhaps not needed(?). 

R: The length of this paper is constrained by the special issue's recommendation. For readers who are interested in the theoretical background of those tests, they can refer to Merkle and Zeileis, 2013.  

For expository purposes, making it more concrete, it might be helpful though to specify how it would work for GLS: the cumulative sum would be some matrix, with a probability limit, times terms containing the cross-products of individual observation vectors minus sigma (the same under the null hypothesis). 

R: Thanks for the suggestion. Reviewer 1 also mentioned about this. We added illustration to the cumulative sum score matrix. 

Ed: I think this point is the same as reviewer 1 wanted to some illustration for eq 2. 

Some additional comments: 

1. I find your reference to the Huber-White robust standard errors a bit 'cavalier'. Are you referring to the situation where the model specifies a covariance structure, say, but is otherwise agnostic about the distribution, and “i.i.d.” can be maintained as a null hypothesis? For more general cases, with varying exogenous variables .e.g. the case for Huber-White is much less clearcut. See e.g. Chapter 17, 'On the so-called 'Huber Sandwich Estimator' and 'Robust Standard Errors'', in 'Statistical Models and Causal Inference by David Freedman (2010). 

R: Thanks for the suggestion. As Reviewer 1 pointed out, this sentence is not closely related to the context here. So we deleted this sentence. 

Ed: I don't know how to answer the question. Which situation are we referring to?

2.The last paragraph on p.6 starting with 'Because' is not clear to me. You point out essentially that with a fixed p-value the LRT will eventually pick up even very small and inconsequential deviations from the null-hypothesis, and you offer the family of score-based testing as an alternative. So do they have less power? But you also claim somewhere that (8) is (asymptotically) equivalent to the LRT. 

R: Thanks for the suggestion. Here the "above tests" refers to the "above LRT and LMuo test(asymptotically equivalent to LRT)". We add that for clearification. These two tests are too sensitive to large sample size, meaning they will always give significant results when sample size is large. 

3. P-values are very prominent in this paper, and 5% is close to sacred (this may be your perception of what practitioners think, which is a fair assumption in my experience, but may not be representative of what you personally believe, I for one fail to understand how this level has become so decisive). Nevertheless, I am concerned that the use of many statistics, each judged with respect to p=5%, makes it very hard to control the overall-level. The p-values are also not independent, so an aggregation using the log of the p-values (Fisher), will not be appropriate. In addition, you advocate the use of pictures and diagrams in testing the null-hypothesis. The end result will be a model that is random as well (a new sample could with the same approach easily lead to another model), based on an informal procedure that would not allow of a structured Monte Carlo type of sensitivity analysis. It appears that the statistical inference problems as induced by modeling and testing on the same data are unsurmountable: see e.g. H. Leeb and B.M. Poetscher (2005), 'Model selection and inference: facts and fiction', Econometric Theory, 21, 21-59. So I would emphasize that the end-result of the excercise is tentative, that the whole excercise is best seen as exploratory only, and that new data are needed for further testing and confirmation. 

R: The p value is based on the data. The critical value can be got for any designated criteria, e.g. alpha=0.1 or 0.01. The traditional problem of testing inflating type I error does not apply in this context. The reason is that there is one hypothesis when we test multiple parameters. It is not the case that we test single parameters for multiple times. The plots are visual demonstration of the tests, so reflecting if the p value is larger or smaller than alpha. The test is not about replication. It is just based on the data at hand. 
 

4. On the last lines on p. 13, just above the General Discussion, you point out that it is 'important to study to what extent the hypothesized model includes all parameters of importance, and that none of the tests inform about model misspecification'. The first statement imposes a rather daunting task, and will amplify the 'dangers' alluded to in 3. A pragmatic approach would be to use GLS as well: if the model is wrong, ML and GLS should not produce the same estimates, since they project the data along different angles on the model space. But at the end of the day the necessity to cross-validate on new data will still be paramount. 

R: The proposed tests aim to detect measurement invariance w.r.t. an auxilliary variable. Detecting model misspecification is not the purpose. Moreover, model misspecification won't be detected by different estimation method, either. 

Ed: I don't think there is difference in producing the score matrix and estimates. Is it true?  

Finally, to avoid possible misunderstandings: I am not one of those reviewers who expects to find every scrap of his presumed “wisdom” to be reflected in the new version, if any, of the paper. My comments are meant to be helpful, and if ignored, my ego will survive. 

R: Thanks for the comments and suggestions. They helped to make the paper better. 
