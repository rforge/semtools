Reviewer 1

Nice paper, very interesting. This is cased on, and so disseminates, excellent recent work (the Merkle papers). R implementation are a great contribution in addition to the theoretical work. I have some comments, which the authors may wish to consider. 

comments 

Comment 1.1. The exact contribution could be made clearer. I understand that the method has already been developed and implemented and applied to real data and in simulation. In the present paper, the method is explained and applied to real data and in simulation. Do the simulations results add to the existing results? This the application new? As mentioned, I do not think that the explanation of the method per se is particularly tutorial in nature. If the R worked example is the main message, please state this. 

Response 1.1. We intended the "tutorial" part to include the method overview (less technical than previous papers) and the R examples.  The simulations that follow the tutorial are novel, in the sense that they examine test properties that were not examined in previous simulations.  In general, we see the paper as being useful for applied researchers who are mainly interested in the method's practical use.  We have added some detail on this to the introduction.


Comment 1.2. p. 2 " the development of test statistics that are sensitive to invariance violations of interest and insensitive to "anomalous" invariance violations". 

Quite unclear. Restate for clarity. I mean: from the preceding single sentence "anomalous" is not clear. You mean that the tests are sensitive to the violations of interest and insensitive to violations not of interest? 

Response 1.2. We have edited this sentence for clarification.


Comment 1.3. p.2 "The test statistics are specifically applicable to situations where one wishes to test for measurement invariance with respect to an ordinal variable, and they are special cases of a family of tests that may be used to study measurement invariance w.r.t. continuous, categorical, and ordinal variables" 

The reader may know MI w.r.t. nominal variables (e.g., sex), but not w.r.t continuous variables, which is more complicated. Please add references, and perhaps elaborate a little on the framework? 

Response 1.3. We have added some brief discussion of alternative methods for studying measurement invariance w.r.t. continuous variables.


Comment 1.4. p.2-3. "The cross-product of these scores forms the "meat" for the calculation of robust (Huber-White) standard errors (e.g., Zeileis, 2006b)." That is true, but why is this mentioned? This paper is not about robust standard errors. 

Response 1.4. We agree. This sentence is deleted. 


Comment 1.5. p.3. "To verbally describe the above equation, each individual has k scores describing the extent to which the fitted model describes that particular individual. Scores close to zero indicate a \good" description, and scores far from zero indicate a \bad" description". Strange to my ears: the score varies naturally in a correctly specified model applied to a finite sample, representative of the population of interest. If each person's observed scores are realizations of the process of interest, how does in this situation the score count as an measure of individual goodness of fit? The parameters in the model pertain to covariance matrices or mean vectors (aspects of distributions). Below we read: "Conversely, if measurement invariance holds, then all individuals' scores will fluctuate randomly around zero". So here the fluctuation is consistent with well fitting model? 

Response 1.5. We have revised this text.  If all individuals arise from the same population, the scores will fluctuate around zero.  Some scores may indeed be far from zero, but this will not occur often.  On the other hand, if there exist multiple subgroups of individuals with different parameter values, the scores should follow a trend (say, most scores are negative for one subgroup, then positive for another subgroup).  So the general answer is that fluctuation always occurs, but the fluctuation should be around zero under measurement invariance (and should trend away from zero under noninvariance).


Comment 1.6. p.3 "If the manifest variables violate measurement invariance here,…" As "a test is MI w.r.t a variable", or "MI w.r.t. a variable may be violated", this is a strange personification of "manifest variables", do they do the violating? 

Response 1.6. We changed the sentence to state "If there exists measurement invariance w.r.t. age". 


Comment 1.7. p.3. eq. 2. Hard to follow. Does one choose increasing values of t? If so, how (given that t varies continuously between 0 and 1)? "Thus, the process associated with one parameter is not correlated with the processes associated with other parameters". This transform the scores to uncorrelated standardized variables, right? Following this transformation, how can I relate the fluctuation in a component of B(t,theta) to the original parameter? 

Response 1.7. Because we take the integer part of nt, we can allow t to vary from 1/n, 2/n, 3/n, ..., n/n.  We have added this detail to the paper.  Additionally, it is correct that premultiplication by the square root of the information matrix creates uncorrelated, standardized variables.  The decorrelation still preserves information about individual variables within the original rows, however.

 
Comment 1.8. p.3. Under the hypothesis of measurement invariance, a central limit theorem can be used to show that the fuctuation of the above cumulative sum follows a Brownian bridge." Perhaps add ref for Brownian bridge? Or can we assume that the readership is familiar with this?

Response 1.8. We added a reference here. 


Comment 1.9. p.5. "We focus on measurement invariance of the factor loadings associated with the GQ-6 scale, using a one-factor model". Now many items? 5 I gather later on. How scaled? By fixing 1 factor loading to 1 (I assume?). The latent variance varies over group? It would be useful to state explicitly the exact model which provides the scores. The full MI includes equality of factor loadings, intercepts and residual variances, but not common factor means (alpha_i) or common factor (co)variances (Phi_i), where i is group in the standard multivariate case (but continuous here). In applying this method with continuously varying age in mind, how does one fit the MI model given that the grouping variable is continuous and alpha_i and Phi_i are free to vary conditional on the grouping variable? Does the R cfa restr <- cfa("f1 = ~gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5", data = yg, group = "agegroup", meanstructure = TRUE, group.equal = "loadings") only include equal loadings? Does one implement this method in the full MI model, or partial MI model? This should be made clear as it is important. 

Response 1.9. We have added model details to the paper.  In particular, we set the scale by fixing the first factor loading to 1 and fit a partial MI model by restricting only the loadings to be equal across group.  Additionally, as we now state, the method can generally be applied to full MI and partial MI models so long as the grouping variable is ordinal.

The "continuous V" situation is somewhat different: here, we have no ties along V, and we cannot fit a model where the factor mean varies for every individual in the sample.  If the model is sufficiently identified, we can at least test whether an estimated factor mean fluctuates with V (the data example of Merkle & Zeileis, 2013 contains one example).  If the factor mean does not fluctuate with V, then we can continue with further tests of other model parameters.


Comment 1.10. p. 9. "The measurement invariance violation occurred in one of three places: the factor loading associated with Scale 1 (lambda11), the unique variance associated with Scale 1 (psi11), or the factor covariance phi12." I do not understand that phi12 can be the locus of a violation of MI, as the definition of MI does not include any constraints on the common factor covariance matrix. It would make more sense to consider an intercept. 

Response 1.10. Correct, the condition with phi12 is not "measurement invariance" per se, but it is still an instability that could occur in the model.  We have added more detail here and also added a condition for the intercept.


Thanks; we appreciate the feedback.



Reviewer 2

Comment 2.1. This paper appears to aim for an audience of practitioners, who want to know how score-based testing can be implemented and what could be obtained from it. The explanation of the use of R-routines is particularly helpful, although I am a bit skeptical as to its use in large covariance structure analyses (LISREL type). 

Response 2.1. The theory underlying these tests implies that they are applicable to general models fit via ML.  We have not examined models that are more complex than those in the paper, though our R implementation would make this easy to do so in the future.


Comment 2.2. Your exposition of the logic of the approach may be too short for your intended audience, your other papers are much more informative. But if the paper is part of a special issue where other authors also deal with the same issues, a further elaboration is perhaps not needed(?). 

Response 2.2. We agree that there is some missing technical detail, and we are attempting to write the description in such a way that applied researchers can get the idea and carry out the methods.  We have added some detail but suspect that it may still not be enough for sophisticated readers (who we can at least refer to our Psychometrika papers).  


Comment 2.3. For expository purposes, making it more concrete, it might be helpful though to specify how it would work for GLS: the cumulative sum would be some matrix, with a probability limit, times terms containing the cross-products of individual observation vectors minus sigma (the same under the null hypothesis). 

Response 2.3. We have added some brief detail on score calculation when scores are first introduced (around Eq (1)).  We feel that explicit detail of score calculation under various discrepancy functions will be more distracting than enlightening.  


Some additional comments: 

Comment 2.4. I find your reference to the Huber-White robust standard errors a bit 'cavalier'. Are you referring to the situation where the model specifies a covariance structure, say, but is otherwise agnostic about the distribution, and “i.i.d.” can be maintained as a null hypothesis? For more general cases, with varying exogenous variables .e.g. the case for Huber-White is much less clearcut. See e.g. Chapter 17, 'On the so-called 'Huber Sandwich Estimator' and 'Robust Standard Errors'', in 'Statistical Models and Causal Inference by David Freedman (2010). 

Response 2.4. Because this sentence is not relevant to the current paper (and both reviewers commented on it), we have deleted it. 


Comment 2.5. The last paragraph on p.6 starting with 'Because' is not clear to me. You point out essentially that with a fixed p-value the LRT will eventually pick up even very small and inconsequential deviations from the null-hypothesis, and you offer the family of score-based testing as an alternative. So do they have less power? But you also claim somewhere that (8) is (asymptotically) equivalent to the LRT. 

Response 2.5. The tests from (6) and (7) have less power to pick out inconsequential deviations than does the test from (8) or the LRT.  The LRT and test from (8) are asymptotically equivalent while the tests from (6) and (7) are structurally different because they employ the ordering of the categories.  We have added this detail in the paper.  Furthermore, one could derive an LRT-based ordered test that is asymptotically equivalent to (7) (i.e., maxLR_o in our notation).


Comment 2.6. P-values are very prominent in this paper, and 5% is close to sacred (this may be your perception of what practitioners think, which is a fair assumption in my experience, but may not be representative of what you personally believe, I for one fail to understand how this level has become so decisive). Nevertheless, I am concerned that the use of many statistics, each judged with respect to p=5%, makes it very hard to control the overall-level. The p-values are also not independent, so an aggregation using the log of the p-values (Fisher), will not be appropriate. In addition, you advocate the use of pictures and diagrams in testing the null-hypothesis. The end result will be a model that is random as well (a new sample could with the same approach easily lead to another model), based on an informal procedure that would not allow of a structured Monte Carlo type of sensitivity analysis. It appears that the statistical inference problems as induced by modeling and testing on the same data are unsurmountable: see e.g. H. Leeb and B.M. Poetscher (2005), 'Model selection and inference: facts and fiction', Econometric Theory, 21, 21-59. So I would emphasize that the end-result of the excercise is tentative, that the whole excercise is best seen as exploratory only, and that new data are needed for further testing and confirmation. 

Response 2.6. Several important issues are raised in this comment and model selection is indeed a very complicated issue. However, the tests we propose are more about model diagnostics (specifically, assessment of measurement invariance) than about model selection. Hence, we have not commented about potential issues regarding model selection.

As for the combination of multiple test statistics on the same data, one has to distinguish two situations: a combination of multiple test statistics within a single p-value (e.g., in a maximum test) and a combination of p-values from different tests. The former case (as shown in Figure 1, for example) is appropriately accounted for by employing the corresponding limiting distribution so that the conventional properties of p-values hold. In the latter case, however, it is clear that conducting all of the proposed tests simultaneously (as done in the illustration) would require adjustment of the significance level employed. We do not apply any correction because we simply want to show the readers what the interpretation would be if each test were the only test for measurement invariance conducted. This is pointed out at the beginning of the tutorial section now.


Comment 2.7. On the last lines on p. 13, just above the General Discussion, you point out that it is 'important to study to what extent the hypothesized model includes all parameters of importance, and that none of the tests inform about model misspecification'. The first statement imposes a rather daunting task, and will amplify the 'dangers' alluded to in 2.6. A pragmatic approach would be to use GLS as well: if the model is wrong, ML and GLS should not produce the same estimates, since they project the data along different angles on the model space. But at the end of the day the necessity to cross-validate on new data will still be paramount. 

Response 2.7. We have added some detail on these issues: comparing estimates from different discrepancy functions and validating results with new data.



Thanks for the comments and suggestions. They helped to make the paper better. 
