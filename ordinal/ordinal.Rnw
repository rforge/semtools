\documentclass[man]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm}
%% need no \usepackage{Sweave}
\SweaveOpts{engine = R, eps = FALSE, echo = FALSE, results = hide}

\title{Testing for measurement invariance with respect to an ordinal variable}
\threeauthors{Edgar C. Merkle}{Jinyan Fan}{Achim Zeileis}
\threeaffiliations{University of Missouri}{Auburn University}{Universit\"{a}t Innsbruck}

\abstract{Researchers are often interested in testing for 
  measurement invariance with respect to an ordinal auxiliary variable such as
  age group, income class, or school grade.  In a factor-analytic
  context, these tests are traditionally carried out via a likelihood
  ratio test statistic comparing a model where parameters differ across groups
  to a model where parameters are equal across groups.  This test
  neglects the fact that the auxiliary variable is ordinal, and it
  is also known to be overly sensitive at large sample sizes.  In this
  paper, we propose test statistics that
  explicitly account for the ordinality of the auxiliary variable.
  The statistics are derived from a family of tests based on stochastic
  processes that have recently received attention in the psychometric
  literature.  The statistics are illustrated via an application
  involving real data, and their performance is studied via simulation.
}

\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. 
  Correspondence to Edgar C.\ Merkle, Department of  
  Psychological Sciences, University of Missouri, Columbia,
  MO 65211.
  Email: {\texttt{merklee@missouri.edu}}.}
\shorttitle{Ordinal measurement invariance}
\rightheader{Ordinal measurement invariance}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}

%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}

\spacing{1}

\begin{document}
\maketitle

<<preliminaries>>=
## packages
library("lavaan")
library("strucchange")
library("mvtnorm")
library("lattice")

## auxiliary code
source("mzo.R")
source("../www/estfun-lavaan.R")
source("../prelim_code/efpFunctional-cat.R")
source("sim_ordinal.R")

## convenience function for plotting boundaries without color
get_boundary <- function(obj, fun, trim = 0) {
  bound <- fun$boundary(0:obj$nobs/obj$nobs)
  bound <- fun$computeCritval(0.05, ncol(obj$process)) * bound
  bound <- zoo(bound, time(obj$process))
  if(trim > 0) bound <- head(tail(bound, - floor(trim * obj$nobs)), - floor(trim * obj$nobs))
  return(bound)
}
@

%% TODO add some more citations to these initial paragraphs
The study of measurement invariance and differential item functioning
(DIF) 
has received considerable attention in the psychometric literature
(see, e.g., \citeNP{Mill11} for a thorough review).  A set of
psychometric scales ${\bm X}$ are defined to be measurement invariant
with respect to an auxiliary variable $V$ if \cite{Mel89}
\begin{equation}
    \label{eq:midef}
      f(x_i | t_i, v_i, \dots) = f({\bf x}_i | t_i, \dots),
\end{equation}
where $T$ is the latent variable that the scales measure, $f$ is the
model's distributional form, and the $i$ subscript refers to
individual cases.  If the above equation does not hold, then there
exists a measurement invariance violation.  We focus here on
situations where $f()$ is parametric, and the measurement invariance
violation occurs because the model parameters are
unequal across individuals (and related to $V$).

As a concrete example of the study of measurement invariance, consider
a situation where ${\bm X}$ contains some ``high stakes'' tests of
ability and $V$ is ethnicity.
One's ethnicity should be unrelated to the measurement parameters
within $f()$, and this expectation can be studied within a
psychometric model by fitting the model examining whether or not
measurement parameters 
vary across different ethnicities.  Statistical tools that can be used
to carry out this study include Likelihood Ratio Tests, Lagrange
Multiplier tests, and Wald tests \cite{Sat89}.
These tools have greatly aided in
the development of improved, ``fairer'' psychometric tests and
scales.

Along with ethnicity, researchers are often interested in studying
measurement invariance with respect to ordinal $V$.
Such variables can arise from multiple choice surveys, where
continuous variables such as age or income are binned into a small number
of categories.  Alternatively, the variables may arise from gross,
qualitative assessments of a particular measure of interest, where
individuals may be categorized as having a
``low,'' ``medium,'' or ``high'' level of the variable of interest.
While these variables are relatively easy to find in the literature,
there exist very few measurement invariance methods that specifically
account for the fact that $V$ is ordinal.  More often, $V$ is simply
treated as categorical so that the traditional tests can be applied.
It is the intent of this paper to propose
two test statistics that fill this gap and to show that the statistics
possess good properties to be used in practice.

The test statistics proposed here are derived from a family of tests
that were recently applied to the study of measurement invariance in
psychometric models \cite{KopZei10,MerZei12}.
In the following section, we provide an overview of the family and
describe the proposed statistics in detail.  Next, we report on the
results of two simulation studies designed to compare the proposed
test statistics to existing tests of measurement
invariance.  Next, we illustrate the proposed statistics using
psychometric data on scales purported to measure youth gratitude.  
Finally, we provide some detail on the tests' use in practice.

\section{Theoretical Detail}

We will consider situations in which a $p$-dimensional variable $X$
with observations $\bm{x}_i, i=1,\dots,n$ is described by a 
model with density $f(\bm{x}_i; \bm{\theta})$ and
associated joint log-likelihood
\begin{equation} \label{eq:loglik}
  \ell(\bm{\theta}; \bm{x}_1, \dots, \bm{x}_n) ~=~
    \sum_{i = 1}^n \ell(\bm{\theta}; \bm{x}_i) ~=~
    \sum_{i = 1}^n  \log f(\bm{x}_i; \bm{\theta}),
\end{equation}
where ${\bm \theta}$ is some $k$-dimensional parameter vector that characterizes
the distribution.  

We focus on applications where the density $f(\bm{x}_i; \bm{\theta})$ arises
from a structural equation model with assumed multivariate normality,
though the proposed tests extend beyond this family of models.  Under
the usual regularity conditions (e.g., \citeNP{Fer96}), the model parameters
$\bm{\theta}$ can 
be estimated by maximum likelihood (ML), i.e.,
\begin{equation} \label{eq:ml}
  \hat{\bm{\theta}} ~=~ \argmax_{\bm{\theta}} \ell(\bm{\theta}; x_1, \dots, x_n),
\end{equation}
or equivalently by solving the first order conditions
\begin{equation}
    \label{eq:ml1}
  \sum_{i=1}^{n} {\bm s}(\hat{\bm{\theta}}; \bm{x}_i) ~=~ 0,    
\end{equation}
where 
\begin{equation}
  \label{eq:score}
  {\bm s}({\bm \theta}; x_i) ~=~ \left(
    \frac{\partial \ell({\bm \theta}; x_i)}{\partial \theta_1},
    \dots,
    \frac{\partial \ell({\bm \theta}; x_i)}{\partial \theta_k}
  \right)^\top,
\end{equation}
is the score function of the model (the partial derivative of the casewise
likelihood contributions w.r.t.\ the parameters $\bm{\theta}$).
Evaluation of the score function at $\hat{\bm{\theta}}$ for $i=1,
\dots, n$ essentially measures the extent to which the model maximizes
each individual's likelihood: as an individual's scores stray further
from zero, the model provides a poorer description of that individual.

In studying measurement invariance, we are essentially testing the
assumption that all  
individuals arise from the same 
parameter vector ${\bm \theta}$.
Thus, a hypothesis of invariance can be written as
\begin{equation}
    \label{eq:h0}
    H_0:~ {\bm \theta}_i = {\bm \theta}_0,\quad (i=1,\ldots,n),
\end{equation}
where ${\bm \theta}_i$ reflects the parameter vector for individual
$i$ (and modifications for subsets of ${\bm \theta}$ are immediate).  This
hypothesis is typically tested against an alternative
\begin{equation}
  \label{eq:h1*}
  H_1^*:~ {\bm \theta}_i = \left\{ \begin{array}{ll}
    {\bm \theta}^{(A)} & \mbox{if } v_i \le \nu, \\
    {\bm \theta}^{(B)} & \mbox{if } v_i >   \nu,
  \end{array} \right.
\end{equation}
where $v_i$ reflects individual $i$'s value on an auxiliary variable
$V$ and $\nu$ is a threshold dividing individuals into groups based on
$V$.  In this paper, we generally focus on situations where $V$ is
ordinal and 
where $\nu$ is unknown.  In the section below, we review tests where
$V$ is continuous (and $\nu$ is unknown) before proceeding to the 
proposed tests for ordinal $V$.

\subsection{Tests for Continuous $V$}

When $V$ is categorical with a relatively-small number of categories,
tests of measurement invariance typically proceed via multiple-group
models.  In this situation, we use likelihood ratio tests to compare a
model whose parameters differ across groups to a model whose
parameters are constrained to be equal across groups.  When $V$ is
continuous, however, multiple-group models obviously cannot be used 
because there are no existing groups.  Instead, we can fit a model
whose parameters are restricted to be equal across all individuals, then
examine individuals' scores ${\bm s}(\hat{{\bm \theta}}; x_i)$
fluctuate with their values of $V$.  If measurement invariance holds
with respect to $V$, then the scores should randomly fluctuate around
zero.  Conversely, if measurement invariance does not hold, then the
scores should systematically depart from zero.  These ideas are
related to those underlying the Lagrange multiplier test; see
\citeNP{MerZei12} for more details.

To formalize these ideas, we define the $k$-dimensional {\em
  cumulative score process} as 
\begin{equation} \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ \hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n t \rfloor} {\bm s}(\hat {\bm \theta}; x_i)
  \qquad (0 \le t \le 1)
\end{equation}
where $\lfloor nt \rfloor$ is the integer part of $nt$ and
$\hat I$ is some consistent estimate of the covariance matrix of the
scores.  Equation~\eqref{eq:cumscore} simultaneously accounts for the
ordering of individuals w.r.t.\ $V$ and decorrelates the scores
associated with each of the $k$ model parameters (which allows us to
potentially make inferences separately for each individual model
parameter).  Using ideas similar to those that were outlined in the previous
paragraph, the cumulative score process associated with each
model parameter should randomly fluctuate around zero under
measurement invariance.  Further, there exists a functional central
limit theorem that allows us to make formal inference with this
cumulative score process.  Assuming that individuals are independent
and the usual ML regularity conditions hold, it is possible to show
that \citeA{HjoKon02}
\begin{equation} \label{eq:fclt}
  {\bm B}(\cdot; \hat {\bm \theta}) ~\overset{d}{\rightarrow}~ {\bm B}^{0}(\cdot),
\end{equation}
where $\overset{d}{\rightarrow}$ denotes convergence in distribution
and ${\bm B}^{0}(\cdot)$ is a $k$-dimensional Brownian bridge.
Thus, we can construct tests of measurement invariance by comparing
the cumulative score process's behavior to that of a Brownian bridge.
This is accomplished by comparing a scalar statistic associated with
the cumulative score process to the analogous statistic of a Brownian
bridge.

In practice, we have a finite sample size $n$ and so the
{\em empirical} cumulative score can be represented within an $n
\times k$ matrix with elements ${\bm B}(i/n; \hat {\bm \theta})_j$ that
we also denote ${\bm B}(\hat {\bm \theta})_{ij}$ below for brevity.
Each row of the matrix contains cumulative sums of the scores of
individuals who were at the $i/n$ percentile of $V$ or below.  Scalar
test statistics are then obtained by collapsing over rows
(individuals) and columns (parameters) of the matrix, with asymptotic
distributions of the test statistics under~\eqref{eq:h0}  being
obtained by applying the 
same functional to the Brownian bridge \cite{HjoKon02,ZeiHor07}.

%% Paragraph on test statistics
Specific test statistics commonly obtained under this framework
include the double maximum statistic
\begin{equation}
    \label{eq:dmax}
    \mathit{DM} = \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,
\end{equation}
which essentially tests whether any component of the cumulative score
process strays too far from zero.  This test discards information
related to multiple parameters fluctuating simultaneously, and Merkle
and Zeileis \citeyear{MerZei12} found it to have relatively-low power
for simultaneously testing multiple factor analysis parameters for
measurement invariance.  

Test statistics with higher power
aggregate information across parameters and possibly also across
individuals.  These test statistics include
\begin{eqnarray}
    \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
with the former being a Cram{\'e}r-von Mises statistic and the latter
corresponding to a ``maximum'' Lagrange multiplier test, where the
maximum is taken across all possible divisions of individuals into two
groups w.r.t.\ $V$.  Additionally, the $\max \mathit{LM}$ statistic is
scaled by the asymptotic variance $t (1 - t)$ of the process ${\bm
  B}(t, \hat {\bm \theta})$.  In simulations, Merkle and Zeileis found that the
$\mathit{CvM}$ test exhibited the highest power for testing multiple
factor analysis parameters for measurement invariance w.r.t.\
continuous $V$.  These simulations included situations in which
subsets of model parameters were tested; such situations are handled
by focusing only on those columns of ${\bm B}(\hat {\bm \theta})_{ij}$
that correspond to the parameters of interest.

\subsection{Proposed Tests for Ordinal $V$}

The theory described above was designed for situations where
$V$ is continuous, so that there is a unique
ordering of individuals with respect to $V$.  In
situations where $V$ is categorical, it is possible
to obtain a test statistic by first summing scores within each of the
$m$ levels of the
auxiliary variable, then ``summing the sums'' to obtain a test
statistic \cite{HjoKon02}.  This test statistic can be formally
written as
\begin{equation}
    \label{eq:lmuo}
     \mathit{LM}_\mathit{uo} = \sum_{\ell = 1, \dots, m} \sum_{j = 1, \dots, k}
       \left( {\bm B}(\hat {\bm \theta})_{i_\ell j} - {\bm B}(\hat {\bm \theta})_{i_{\ell - 1}j} \right)^2,
\end{equation}
where, again, tests of subsets of model parameters can be obtained by
taking the inner sum over only the $k^* < k$ parameters of interest.
This test statistic discards the ordinal nature of the auxiliary
variable.  A similar issue is observed in testing for measurement
invariance via multiple groups models and Likelihood Ratio tests (or,
equivalently, via Wald tests or Lagrange multiplier tests): we
can allow $\bm{\theta}$ to be unique at each level of the ordinal
variable, but the ordinality of the auxiliary variable is lost.
In contrast, the statistics proposed below explicitly account for the fact
that $V$ is ordinal.

The statistics proposed here are
similar to those described in
Equations~\eqref{eq:dmax},~\eqref{eq:cvm}, and~\eqref{eq:maxlm}
above, except that we focus on ``bins'' of individuals at each level of the
ordinal variable.  That is, instead of aggregating over all $i = 1,
\dots, n$ individuals, we first compute cumulative proportions
$t_\ell$ ($\ell = 1, \dots, m-1$) associated with the first $m-1$
levels of $V$.  We then aggregate the 
cumulative scores only over $i_\ell = \lfloor n
\cdot t_\ell\rfloor$.  Test statistics related to~\eqref{eq:dmax}
and~\eqref{eq:maxlm} above can then be written as
%% TODO insert equation
\begin{eqnarray}
    \label{eq:wdm}
      \mathit{WDM}_o & = & \max_{i \in \{i_1, \dots, i_m \}} ~ \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}      
                             \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,\\
    \label{eq:maxlmo}
      \max \mathit{LM}_o & = & \max_{i \in \{i_1, \dots, i_m \}} ~
                             \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
                             \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2.\\
\end{eqnarray}
Critical values associated with these test statistics can be obtained
by applying the same functionals to bins of a Brownian bridge, where the
bin sizes result in the cumulative proportions $t_\ell$ ($\ell=1, \dots,
m-1$) associated with the observed $V$.
Closed-form solutions for
these particular functionals of a Brownian bridge are unavailable, but
critical values and $p$-values can be obtained through repeated
simulation of a Brownian bridge.  This functionality is built in to
R's strucchange package \cite{strucchange}, which can be used to
generally carry out the tests.

As we demonstrate in the simulations below, the test
statistics proposed above are sensitive to the measurement invariance
violations that 
an analyst would typically expect from an ordinal $V$.
These include violations that increase or decrease as we move up
levels of $V$, as well as violations that abruptly
begin at a single point on $V$ and continue after
that.  The test statistics are insensitive to anomolies in a small
number of categories of $V$ that are
unrelated to the ordering of $V$.  This is especially relevant to situations
where the analyst has a large sample size, where the usual
Likelihood Ratio Test is notoriously sensitive to minute parameter
instabilities (e.g., \citeNP{Ben80}).

\section{Simulation 1: Detecting Ordinal Invariance Violations}

In this simulation, we demonstrate that the proposed test statistics are
sensitive to ordinal measurement invariance violations, moreso than
traditional statistics.  We generate data from a two-factor,
six-indicator model, with a measurement invariance violation occurring
in the three unique variances associated with the first factor.  We
use the proposed test statistics to test for measurement invariance
simultaneously across all six unique variances, mimicking the first
step of the ``prescribed'' course of measurement invariance tests. % cite

For comparison, we also compute two statistics that treat the ordinal
auxiliary variable as categorical.  These include the likelihood ratio
test of measurement 
invariance in the six unique variance parameters, along with the
unordered LM test from~\eqref{eq:lmuo}.

\subsection{Method}
As described above, data were generated from a two-factor model
lacking measurement invariance in three of six unique variance
parameters.  Magnitude of measurement invariance violation, type of
measurement invariance violation, sample
size, and number of categories of the ordinal variable were manipulated.
We examined three sample sizes ($n=120, 480, 960$), three numbers of
categories ($m=4, 8, 12$), and
seven magnitudes of invariance 
violations.  The measurement invariance violations began
at level $1+l/2$ of $V$ and were constant thereafter
  The unique variances for
the ``violating'' levels deviated from the lower levels' unique
variances by $d$~times the parameters' asymptotic standard
errors (scaled by $\sqrt{n}$), with $d=0, 0.25, 0.5, \dots, 1.5$.  

For each combination of $n \times m \times d$, 5,000 datasets were
generated and tested via the XX statistics described above.  In all
conditions, we maintained equal sample sizes at each level of the
ordinal variable.

%% sweave code here

\subsection{Results}

\section{Simulation 2: Minor Anomolies and Large $n$}

In this simulation, we demonstrate that the proposed statistic is
relatively insensitive to minor parameter violations that are
unrelated to the ordering of the auxiliary variable.  As noted
earlier, this feature is especially applicable to situations where
one's sample size is very large.  Analysts often resort to informal
fit measures in this case, because the traditional LRT is nearly
guaranteed to result in significance.  This simulation is intended to
show that the proposed ordinal test remains viable for very large $n$.

\subsection{Method}

\subsection{Results}

\section{Application: Youth Gratitude}

\subsection{Background}

\subsection{Method}

\subsection{Results}

\subsection{Summary}

\section{General Discussion}

%% application to other psychometric models

%% should we care about non-ordinal violations when using an ordinal variable?

\subsection{Summary}

\section*{Computational Details}

All results were obtained using the {R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on package
{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} for fitting of the factor analysis models and
{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. {R}~and the packages {lavaan} and {strucchange} are
freely available under the General Public License~2 from the
Comprehensive {R} Archive Network at \url{http://CRAN.R-project.org/}.
{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.


\bibliography{refs}

\end{document}
