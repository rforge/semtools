\documentclass[man]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm}
%% need no \usepackage{Sweave}
\SweaveOpts{engine = R, eps = FALSE, echo = FALSE, results = hide}

\title{Testing for measurement invariance with respect to an ordinal variable}
\threeauthors{Edgar C. Merkle}{Jinyan Fan}{Achim Zeileis}
\threeaffiliations{University of Missouri}{Auburn University}{Universit\"{a}t Innsbruck}

\abstract{Researchers are often interested in testing for 
  measurement invariance with respect to an ordinal auxiliary variable such as
  age group, income class, or school grade.  In a factor-analytic
  context, these tests are traditionally carried out via a likelihood
  ratio test statistic comparing a model where parameters differ across groups
  to a model where parameters are equal across groups.  This test
  neglects the fact that the auxiliary variable is ordinal, and it
  is also known to be overly sensitive at large sample sizes.  In this
  paper, we propose test statistics that
  explicitly account for the ordinality of the auxiliary variable.
  The statistics are derived from a family of tests based on stochastic
  processes that have recently received attention in the psychometric
  literature.  The statistics are illustrated via an application
  involving real data, and their performance is studied via simulation.
}

\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. 
  Correspondence to Edgar C.\ Merkle, Department of  
  Psychological Sciences, University of Missouri, Columbia,
  MO 65211.
  Email: {\texttt{merklee@missouri.edu}}.}
\shorttitle{Ordinal measurement invariance}
\rightheader{Ordinal measurement invariance}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}

%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}

\spacing{1}

\begin{document}
\maketitle

<<preliminaries>>=
## packages
library("lavaan")
library("strucchange")
library("mvtnorm")
library("lattice")
library("foreign")

## auxiliary code
source("mzo.R")
source("../www/estfun-lavaan.R")
source("../prelim_code/efpFunctional-cat.R")
source("sim_ordinal.R")

## convenience function for plotting boundaries without color
get_boundary <- function(obj, fun, trim = 0) {
  bound <- fun$boundary(0:obj$nobs/obj$nobs)
  bound <- fun$computeCritval(0.05, ncol(obj$process)) * bound
  bound <- zoo(bound, time(obj$process))
  if(trim > 0) bound <- head(tail(bound, - floor(trim * obj$nobs)), - floor(trim * obj$nobs))
  return(bound)
}

## convenience function for applying tests to real data
info_full <- function(x, ...) solve(vcov(x) * nobs(x))
@

%% TODO add some more citations to these initial paragraphs
The study of measurement invariance and differential item functioning
(DIF) 
has received considerable attention in the psychometric literature
(see, e.g., \citeNP{Mil11} for a thorough review).  A set of
psychometric scales $X$ are defined to be measurement invariant
with respect to an auxiliary variable $V$ if \cite{Mel89}
\begin{equation}
    \label{eq:midef}
      f(x_i | t_i, v_i, \dots) = f(x_i | t_i, \dots),
\end{equation}
where $T$ is the latent variable that the scales measure, $f$ is the
model's distributional form, the $i$ subscript refers to
individual cases, capital letters signify random variables, and lowercase
letters signify realizations of the variables.  If the above equation
does not hold, then there 
exists a measurement invariance violation.  We focus here on
situations where $f()$ is the probability density function of $X$,
and the measurement invariance
violation occurs because the model parameters are
unequal across individuals (and related to $V$).

As a concrete example of the study of measurement invariance, consider
a situation where $X$ includes ``high stakes'' tests of
ability and $V$ is ethnicity.
One's ethnicity should be unrelated to the measurement parameters
within $f()$, and this expectation can be studied by fitting the model
and examining whether or not 
measurement parameters 
vary across different ethnicities.  Statistical tools that can be used
to carry out this study include Likelihood Ratio tests, Lagrange
Multiplier tests, and Wald tests (e.g., \citeNP{Sat89}).
These tools have greatly aided in
the development of improved, ``fairer'' psychometric tests and
scales.

Along with categorical variables such as ethnicity, researchers are
often interested in studying 
measurement invariance with respect to ordinal $V$.
Such variables can arise from multiple choice surveys, where
continuous variables such as age or income are binned into a small number
of categories.  Alternatively, the variables may arise from gross,
qualitative assessments of a particular measure of interest, where
individuals may be categorized as having a
``low,'' ``medium,'' or ``high'' level of the variable of interest.
While these variables are relatively easy to find in the literature,
there exist very few measurement invariance methods that specifically
account for the fact that $V$ is ordinal.  More often, $V$ is simply
treated as categorical so that the traditional tests can be applied.
It is the intent of this paper to propose
two test statistics that fill this gap and to show that the statistics
possess good properties for use in practice.

The test statistics proposed here are derived from a family of tests
that were recently applied to the study of measurement invariance in
psychometric models \cite{KopZei10,MerZei12}.
In the following section, we provide an overview of the family and
describe the proposed statistics in detail.  Subsequently, we report on the
results of two simulation studies designed to compare the proposed
test statistics to existing tests of measurement
invariance.  Moreover, we illustrate the proposed statistics using
psychometric data on scales purported to measure youth gratitude.  
Finally, we provide some detail on the tests' use in practice.

\section{Theoretical Detail}

This section contains background on the theory underlying the
proposed statistics; for a more detailed
account, see Merkle and Zeileis \citeyear{MerZei12}.

We will consider situations in which a $p$-dimensional variable $X$
with observations $\bm{x}_i, i=1,\dots,n$ is described by a 
model with density $f(\bm{x}_i; \bm{\theta})$ and
associated joint log-likelihood
\begin{equation} \label{eq:loglik}
  \ell(\bm{\theta}; \bm{x}_1, \dots, \bm{x}_n) ~=~
    \sum_{i = 1}^n \ell(\bm{\theta}; \bm{x}_i) ~=~
    \sum_{i = 1}^n  \log f(\bm{x}_i; \bm{\theta}),
\end{equation}
where ${\bm \theta}$ is some $k$-dimensional parameter vector that characterizes
the distribution.  

We focus on applications where the density $f(\bm{x}_i; \bm{\theta})$ arises
from a structural equation model with assumed multivariate normality,
though the proposed tests extend beyond this family of models.  Under
the usual regularity conditions (e.g., \citeNP{Fer96}), the model parameters
$\bm{\theta}$ can 
be estimated by maximum likelihood (ML), i.e.,
\begin{equation} \label{eq:ml}
  \hat{\bm{\theta}} ~=~ \argmax_{\bm{\theta}} \ell(\bm{\theta}; x_1, \dots, x_n),
\end{equation}
or equivalently by solving the first order conditions
\begin{equation}
    \label{eq:ml1}
  \sum_{i=1}^{n} {\bm s}(\hat{\bm{\theta}}; \bm{x}_i) ~=~ 0,    
\end{equation}
where 
\begin{equation}
  \label{eq:score}
  {\bm s}({\bm \theta}; x_i) ~=~ \left(
    \frac{\partial \ell({\bm \theta}; x_i)}{\partial \theta_1},
    \dots,
    \frac{\partial \ell({\bm \theta}; x_i)}{\partial \theta_k}
  \right)^\top,
\end{equation}
is the score function of the model (the partial derivative of the casewise
likelihood contributions w.r.t.\ the parameters $\bm{\theta}$).
Evaluation of the score function at $\hat{\bm{\theta}}$ for $i=1,
\dots, n$ essentially measures the extent to which the model maximizes
each individual's likelihood: as an individual's scores stray further
from zero, the model provides a poorer description of that individual.

In studying measurement invariance, we are essentially testing the
assumption that all  
individuals arise from the same 
parameter vector ${\bm \theta}$.
Thus, a hypothesis of invariance can be written as
\begin{equation}
    \label{eq:h0}
    H_0:~ {\bm \theta}_i = {\bm \theta}_0,\quad (i=1,\ldots,n),
\end{equation}
where ${\bm \theta}_i$ reflects the parameter vector for individual
$i$ (and modifications for subsets of ${\bm \theta}$ are immediate).  
The most general alternative hypothesis related to $V$ may then be
written as
\begin{equation}
  \label{eq:h2*}
  H_1^*:~ {\bm \theta}_i = {\bm \theta}_{v_i},
\end{equation}
stating that the parameter vector differs for every unique realization
of $V$.  This alternative is commonly employed when $V$ is
categorical.  In these situations, the likelihood ratio test compares
a model where 
parameters are restricted across groups (i.e., across values of $V$)
to a model where parameters are free across groups; the exact
parameter values within each group are completely unrestricted.
However, in situations where $V$ is categorical or
continuous,~\eqref{eq:h2*} includes non-monotonic violations of
measurement invariance.   This allows for instances where, e.g., the
parameter values initially increase with $V$ and then decrease.
Researchers typically do not expect such a result when testing
measurement invariance wrt continuous or ordinal $V$, and 
researchers often cannot interpret such violations.  Monotonic
parameter changes wrt $V$ are of much more interest in these
situations, with the simplest type of change given by the alternative
hypothesis
\begin{equation}
  \label{eq:h1*}
  H_2^*:~ {\bm \theta}_i = \left\{ \begin{array}{ll}
    {\bm \theta}^{(A)} & \mbox{if } v_i \le \nu, \\
    {\bm \theta}^{(B)} & \mbox{if } v_i >   \nu,
  \end{array} \right.
\end{equation}
where $v_i$ reflects individual $i$'s value on an auxiliary variable
$V$ and $\nu$ is a threshold dividing individuals into groups based on
$V$.  This alternative is implicitly employed in ``median split''
analyses, % TODO cite preacher
where $\nu$ is given as the sample median of $V$.  The threshold $\nu$
is usually unknown, however, so it is generally of interest to
test~\eqref{eq:h1*} across all possible values of $\nu$.  The tests
proposed below generally allow for this.

In this paper, we generally focus on situations where $V$ is
ordinal and where the measurement invariance violation is related to the ordinal
variable (e.g., the violation is of the type from~\eqref{eq:h1*} or
the violation grows/shrinks with $V$).  Researchers typically test for
measurement invariance w.r.t.\ ordinal $V$ by employing the alternative
from~\eqref{eq:h2*}, which implicitly treats $V$ as categorical.
Thus, test statistics that explicitly treat $V$ as ordinal should have
higher power to detect measurement invariance violations that are
monotonic with $V$.

In the section below, we review tests where
$V$ is continuous (and $\nu$ is unknown) before proceeding to the 
proposed tests for ordinal $V$.

\subsection{Tests for Continuous $V$}

As mentioned previously, when $V$ is categorical with a
relatively-small number of categories, 
tests of measurement invariance typically proceed via multiple-group
models.  In this situation, we use likelihood ratio tests to compare a
model whose parameters differ across groups to a model whose
parameters are constrained to be equal across groups.  When $V$ is
continuous, however, multiple-group models obviously cannot be used 
because there are no existing groups.  Instead, we can fit a model
whose parameters are restricted to be equal across all individuals and then
examine how individuals' scores ${\bm s}(\hat{{\bm \theta}}; x_i)$
fluctuate with their values of $V$.  If measurement invariance holds
with respect to $V$, then the scores should randomly fluctuate around
zero.  Conversely, if measurement invariance does not hold, then the
scores should systematically depart from zero.  These ideas are
related to those underlying the Lagrange multiplier test and are
discussed by Merkle and Zeileis \citeyear{MerZei12} in detail. Here,
we review the tests' properties that are relevant for extending them
to the ordinal case.

To formalize the ideas discussed in the previous paragraph, we assume
that the observations are ordered 
w.r.t.\ $V$ (so that $v_i \le v_{i + 1}$) and define the $k$-dimensional
{\em cumulative score process} as 
\begin{equation} \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ \hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n t \rfloor} {\bm s}(\hat {\bm \theta}; x_i)
  \qquad (0 \le t \le 1)
\end{equation}
where $\lfloor nt \rfloor$ is the integer part of $nt$ and
$\hat I$ is some consistent estimate of the covariance matrix of the
scores, e.g., based on the information matrix or an outer product of the scores.
Equation~\eqref{eq:cumscore} simultaneously accounts for the
ordering of individuals w.r.t.\ $V$ and decorrelates the scores
associated with each of the $k$ model parameters (which allows us to
potentially make inferences separately for each individual model
parameter).  Using ideas similar to those that were outlined in the previous
paragraph, the cumulative score process associated with each
model parameter should randomly fluctuate around zero under
measurement invariance.  Further, there exists a functional central
limit theorem that allows us to make formal inference with this
cumulative score process.  Assuming that individuals are independent
and the usual ML regularity conditions hold, it is possible to show
that \cite{HjoKon02}
\begin{equation} \label{eq:fclt}
  {\bm B}(\cdot; \hat {\bm \theta}) ~\overset{d}{\rightarrow}~ {\bm B}^{0}(\cdot),
\end{equation}
where $\overset{d}{\rightarrow}$ denotes convergence in distribution
and ${\bm B}^{0}(\cdot)$ is a $k$-dimensional Brownian bridge.
Thus, we can construct tests of measurement invariance by comparing
the behavior of the cumulative score process to that of a Brownian bridge.
This is accomplished by comparing a scalar statistic associated with
the cumulative score process to the analogous statistic of a Brownian
bridge.

In practice, we have a finite sample size $n$ and so the
{\em empirical} cumulative score can be represented within an $n
\times k$ matrix with elements ${\bm B}(i/n; \hat {\bm \theta})_j$ that
we also denote ${\bm B}(\hat {\bm \theta})_{ij}$ below for brevity.
Each row of the matrix contains cumulative sums of the scores of
individuals who were at the $i/n$ percentile of $V$ or below.  Scalar
test statistics are then obtained by collapsing over rows
(individuals) and columns (parameters) of the matrix, with asymptotic
distributions of the test statistics under~\eqref{eq:h0}  being
obtained by applying the 
same functional to the Brownian bridge \cite{HjoKon02,ZeiHor07}.


%% Paragraph on test statistics
Specific test statistics commonly obtained under this framework
include the double maximum statistic
\begin{equation}
    \label{eq:dmax}
    \mathit{DM} = \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,
\end{equation}
which essentially tests whether any component of the cumulative score
process strays too far from zero and is easily visualized.  This test
discards information 
related to multiple parameters fluctuating simultaneously, resulting
in it having relatively-low power for assessing measurement
invariance when multiple factor analysis parameters change
simultaneously \cite{MerZei12}.

Test statistics that exhibit better performance in such situations 
aggregate information across parameters and possibly also across
individuals.  These test statistics include
\begin{eqnarray}
    \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
with the former being a Cram{\'e}r-von Mises statistic and the latter
corresponding to a ``maximum'' Lagrange multiplier test, where the
maximum is taken across all possible divisions of individuals into two
groups w.r.t.\ $V$.  Additionally, the $\max \mathit{LM}$ statistic is
scaled by the asymptotic variance $t (1 - t)$ of the process
${\bm B}(t, \hat {\bm \theta})$.  In simulations, Merkle and Zeileis
\citeyear{MerZei12} found 
that both tests perform well when assessing simultaneous changes
in multiple factor analysis parameters, with the
$\mathit{CvM}$ test being somewhat advantageous in their particular
simulation setup. These simulations included 
situations in which subsets of model parameters were tested; such
situations are handled 
by focusing only on those columns of ${\bm B}(\hat {\bm \theta})_{ij}$
that correspond to the parameters of interest.

\subsection{Proposed Tests for Ordinal $V$}

The theory described above was designed for situations where
$V$ is continuous, so that there is a unique ordering of individuals with respect to $V$.
However, in situations where $V$ is ordinal, there is only a partial ordering
of all individuals, i.e., observations with the same level of $V$ have no unique
ordering. (Note that the same also applies if $V$ is metric in nature but is only
discretely measured leading to many ties.) 

The ordinal statistics proposed here are
similar to those described in
Equations~\eqref{eq:dmax} and~\eqref{eq:maxlm}
above, except that we focus on ``bins'' of individuals at each level of the
ordinal variable.  That is, instead of aggregating over all $i = 1,
\dots, n$ individuals, we first compute cumulative proportions
$t_\ell$ ($\ell = 1, \dots, m-1$) associated with the first $m-1$
levels of $V$.  We then aggregate the 
cumulative scores only over $i_\ell = \lfloor n
\cdot t_\ell\rfloor$.  Test statistics related to~\eqref{eq:dmax}
and~\eqref{eq:maxlm} above can then be written as
\begin{eqnarray}
    \label{eq:wdm}
      \mathit{WDM}_o & = & \max_{i \in \{i_1, \dots, i_m \}} ~ \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1/2}      
                             \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,\\
    \label{eq:maxlmo}
      \max \mathit{LM}_o & = & \max_{i \in \{i_1, \dots, i_m \}} ~
                             \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
                             \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2.
\end{eqnarray}
Critical values associated with these test statistics can be obtained
by applying the same functionals to bins of a Brownian bridge, where the
bin sizes result in the cumulative proportions $t_\ell$ ($\ell=1, \dots,
m-1$) associated with the observed $V$.


For $\mathit{WDM}_o$ the resulting asymptotic distribution is
$\max_{j = 1, \dots, k} \max_{\ell = 1, \dots, m-1} {\bm B}^{0}(t_\ell) / \sqrt{t_\ell (1 - t_\ell)}$.
Note that the effect of the outer maximum can be easily captured by a Bonferroni
correction as the $k$~components of the Brownian bridge are asymptotically independent.
Moreover, the inner maximum is taken over $m-1$ variables
${\bm B}^{0}(t_\ell) / \sqrt{t_\ell (1 - t_\ell)}$ which are standard normal
(due to the scaling with the standard deviation of a Brownian bridge) and have
a simple correlation structure: $\sqrt{s (1 - t)}/\sqrt{t (1 - s)}$ for
$s \le t$ and both $\in \{t_1, \dots, t_{m-1}\}$. Therefore, critical
values and $p$-values can be easily computed from a multivariate normal
distribution with standard normal marginals and this particular correlation
matrix; see also \citeNP{hotzei08} for more details. In R, this can be
accomplished using the mvtnorm package \cite{mvtnorm}.

For $\max \mathit{LM}_o$ the resulting asymptotic distribution is
$\max{\ell = 1, \dots, m-1} || {\bm B}^{0}(t_\ell) ||_2^2 / (t_\ell (1 - t_\ell))$
for which no simple closed-form solution is available. However,
critical values and $p$-values can be obtained through repeated
simulation of Brownian bridges.  This functionality is built in to
R's strucchange package \cite{Zei06}, which can be used to
generally carry out the tests. Note that for models with only a single
parameter to be tested (i.e., $k = 1$) both test statistics are
equivalent because then $\max \mathit{LM}_o = \mathit{WDM}_o^2$.


If $V$ is only nominal/categorical,
there is not even a partial ordering, i.e., measurement invariance tests should neither
exploit the ordering of $V$'s levels nor of the observations within the level.
In this situation, it is possible to obtain a test statistic by first summing scores within
each of the $m$ levels of the auxiliary variable, then ``summing the sums'' to obtain a test
statistic \cite{HjoKon02}.  This test statistic can be formally written as
\begin{equation}
    \label{eq:lmuo}
     \mathit{LM}_\mathit{uo} = \sum_{\ell = 1, \dots, m} \sum_{j = 1, \dots, k}
       \left( {\bm B}(\hat {\bm \theta})_{i_\ell j} - {\bm B}(\hat {\bm \theta})_{i_{\ell - 1}j} \right)^2,
\end{equation}
where, again, tests of subsets of model parameters can be obtained by
taking the inner sum over only the $k^* < k$ parameters of interest.
This test statistic discards the ordinal nature of the auxiliary
variable, essentially employing the alternative hypothesis
from~\eqref{eq:h2*}.  A similar issue is observed in testing for
measurement 
invariance via multiple groups models and likelihood ratio tests (or,
equivalently, via Wald tests or Lagrange multiplier tests): we
can allow $\bm{\theta}$ to be unique at each level of the ordinal
variable, but the ordinality of the auxiliary variable is lost.
In contrast, the statistics proposed below explicitly account for the fact
that $V$ is ordinal.


As demonstrated in the simulations below, the ordinal test
statistics proposed above are sensitive to the measurement invariance
violations that an analyst would typically expect from an ordinal $V$.
In particular, due to computing cumulative sums in ${\bm B}(\hat {\bm \theta})$,
violations that occur as we move along the levels of $V$ can be captured
wll. This includes abrupt shifts in the parameters $\bm \theta$ at a
certain level of $V$ as well as smooth increases/decreases in the parameters.
Taking a maximum over the $k$~parameters as in $\mathit{WDM}_o$ will be
more sensitive to changes that occur only in one out of many
parameters, 
while $\max \mathit{LM}_o$ will be more sensitive to changes occuring
in several (or even all of the) parameters simultaneously.
Moreover, the test statistics are rather insensitive to anomolies in a small
number of categories of $V$ that are
unrelated to the ordering of $V$.  This is especially relevant to situations
where the analyst has a large sample size, where the usual
likelihood ratio test is notoriously sensitive to minor parameter
instabilities (e.g., \citeNP{Ben80}).

\section{Simulation 1: Detecting Ordinal Invariance Violations}

In this simulation, we demonstrate that the proposed test statistics are
sensitive to ordinal measurement invariance violations, moreso than
traditional statistics.  We generate data from a two-factor,
six-indicator model, with a measurement invariance violation occurring
in the three unique variances associated with the first factor.  We
use the proposed test statistics to test for measurement invariance
simultaneously across all six unique variances, which mimics the
comparison of a tau-equivalent model to a congeneric model (e.g.,
\citeNP{VanLan00}).

For comparison, we also compute two statistics that treat the ordinal
auxiliary variable as categorical.  These include the likelihood ratio
test of measurement 
invariance in the six unique variance parameters, along with the
unordered LM test from~\eqref{eq:lmuo}.

\subsection{Method}
As described above, data were generated from a two-factor model
lacking measurement invariance in the six unique variance
parameters.  Magnitude of measurement invariance violation, 
sample
size, and number of categories of the ordinal variable were manipulated.
We examined three sample sizes ($n=120, 480, 960$), three numbers of
categories ($m=4, 8, 12$), and
seven magnitudes of invariance 
violations.  The measurement invariance violations began
at level $1+m/2$ of $V$ and were constant thereafter.
  The unique variances for
the ``violating'' levels deviated from the lower levels' unique
variances by $d$~times the parameters' asymptotic standard
errors (scaled by $\sqrt{n}$), with $d=0, 0.25, 0.5, \dots, 1.5$.  

For each combination of $n \times m \times d$, 5,000 datasets were
generated and tested via the 4 statistics described above.  In all
conditions, we maintained equal sample sizes at each level of the
ordinal variable (i.e., $t_\ell = \ell/m$).

<<sim1>>=
## seed for replication
RNGkind(kind = "default", normal.kind = "default")
set.seed(1163)

if(file.exists("sim1.rda")) {
  load("sim1.rda")
} else {
  sim1 <- simulation()
  sim1$nlevels <- factor(sim1$nlevels)
  levels(sim1$nlevels) <- paste("m=",levels(sim1$nlevels),sep="")
  sim1$nobs <- factor(sim1$nobs)
  levels(sim1$nobs) <- paste("n=",levels(sim1$nobs),sep="")
  levels(sim1$test) <- c("LM_uo", "LRT", "LM_o", "WDM_o")
  save(sim1, file="sim1.rda")
}
@ 

\subsection{Results}

Simulation results are presented in Figure~\ref{fig:sim1res}.  Rows of
the figure 
correspond to $n$, columns of the figure correspond to $m$, the x-axis
of each panel corresponds to $d$, and the y-axis of each panel
corresponds to power.  It is seen that one of the proposed test
statistics, the $\max \mathit{LM}_o$ statistic from~\eqref{eq:maxlmo},
generally has the largest power to detect the ordinal measurement
invariance violations.  The other three tests are considerably closer
in power, with the second proposed ordinal statistic
(the double-max test from~\eqref{eq:wdm}) exhibiting the lowest power
at large violation magnitudes.  This is because the double-max
test discards information about multiple parameters changing together
at specific levels of the ordinal variable
(see Merkle and Zeileis, 2012, for related discussion), while the
three other tests under consideration make use of this information.
Finally, it is seen that, in the small $n$ and large $m$ conditions,
the likelihood ratio test exhibits large Type-I error rates (i.e.,
power greater than 0.05 at $d=0$).  This is because the likelihood
ratio test requires estimation of a multiple-groups model, which is very
unstable with large numbers of groups and small sample sizes as only
$n/m$ observations are available in each subsample.  The proposed
statistics are all of the LM-type and just require estimation of the single-group model,
leading to a clear advantage in these conditions.

\begin{figure}
\caption{Simulated power curves for the ordered and unordered
      $\max \mathit{LM}$ tests, the ordered double-max test, and the
      likelihood ratio test across three sample sizes $n$, three
      levels of the ordinal variable $m$, and measurement invariance
      violations of 0--1.5 standard errors (scaled by $\sqrt{n}$).}
\label{fig:sim1res}
\setkeys{Gin}{width=\textwidth}
<<sim1res, fig=TRUE, height=7, width=7>>=
mykey <- simpleKey(levels(sim1$test), points = FALSE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + nobs, group = ~ test, data = sim1, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@
\end{figure}

To summarize, we found the $\max \mathit{LM}_o$ statistic to be
advantageous for detecting measurement invariance violations that are
related to an ordinal auxiliary variable.  In particular, power is
generally higher, and the test does not require estimation of a
multiple group model.  Thus, the statistic allows reasonable
measurement invariance tests to be carried out at small $n$/large $m$
combinations.  To further illustrate that the proposed statistics are
useful for testing violations related to an ordinal variable, we
now compare their performance to the likelihood ratio test at large
$n$ and small $d$.

\section{Simulation 2: Minor Anomolies and Large $n$}

In this simulation, we demonstrate that the proposed statistic is
relatively insensitive to minor parameter violations that are
unrelated to the ordering of the auxiliary variable.  As noted
earlier, this feature is especially applicable to situations where
one's sample size is very large.  Analysts often resort to informal
fit measures in this case, because the traditional LRT is nearly
guaranteed to result in significance.  This simulation is intended to
show that the proposed ordinal test remains viable for large $n$.

\subsection{Method}
Data were generated from the same factor analysis model that was used
in Simulation 1, with measurement invariance violations in the unique
variance parameters.  To implement a minor measurement invariance
violation, the unique variances were equal across all levels of the
ordinal variable except one (level $1+m/2$).  At this particular
level, the unique variances were greater by a factor of $d$~times the
parameters' asymptotic standard errors (scaled by $\sqrt{n}$), with
$d=0, 0.5, 1.0, \dots, 3.0$.  The number of levels of the ordinal
variable were the same as those in Simulation 1 ($m=4,8,12$), and
sample sizes were set at $n=1200,4800,9600$.  All other simulation
features matches those from Simulation 1.

<<sim2>>=
if(file.exists("sim2.rda")) {
  load("sim2.rda")
} else {
  sim2 <- simulation(diff = seq(0, 3, by = 0.5), nobs = c(1200, 4800, 9600),
                     anomaly=TRUE)
  sim2$nlevels <- factor(sim2$nlevels)
  levels(sim2$nlevels) <- paste("m=",levels(sim2$nlevels),sep="")
  sim2$nobs <- factor(sim2$nobs)
  levels(sim2$nobs) <- paste("n=",levels(sim2$nobs),sep="")
  levels(sim2$test) <- c("LM_uo", "LRT", "LM_o", "WDM_o")
  save(sim2, file="sim2.rda")
}
@ 

\subsection{Results}
Simulation results are presented in Figure~\ref{fig:sim2res}.  It is
observed that results are very consistent across the sample sizes
tested, implying that ``practical infinity'' is reached for this model
by $n=1200$. \readme{Also implying that we don't need all three sample
  sizes or could try values smaller than 1200.}  We also observe
a negative 
relationship between power and $m$; this is because the measurement
invariance violation occurred at only one level of the auxiliary
variable.  As $m$ increases (and $n$ is held
constant), the number of individuals violating measurement invariance
therefore decreases.  As a result, power to detect the violation decreases with
increasing $m$.

The more interesting result of this simulation lies in the comparison
of the four test statistics within each panel of the figure.  The
two ``unordered'' test statistics both have relatively-high power to
detect the measurement invariance violation, illustrating the finding
of Bentler and Bonett \citeyear{Ben80} and others that the
likelihood ratio test statistic picks out minor 
parameter discrepancies at large $n$.  In contrast, the two ordinal
test statistics that we proposed have considerably lower power, with
the $\text{WDM}_o$ statistic being the lowest and the $\text{LM}_o$
statistic being higher at larger values of $d$.  
This demonstrates that the proposed ordinal test
statistics can be especially useful at large sample sizes, where
traditional test statistics result in frequent significance.
Both statistics exhibited much lower power to detect a measurement
invariance violation occurring at a single level of the auxiliary
variable.  

\begin{figure}
\caption{Simulated power curves for the ordered and unordered
      $\max \mathit{LM}$ tests, the ordered double-max test, and the
      likelihood ratio test across three sample sizes $n$, three
      levels of the ordinal variable $m$, and measurement invariance
      violations of 0--3 standard errors (scaled by $\sqrt{n}$)
      occurring at a single level (the $(1 +
      m/2)^{\text{th}}$ level) of the ordinal auxiliary variable.}
\label{fig:sim2res}
\setkeys{Gin}{width=\textwidth}
<<sim2res, fig=TRUE, height=7, width=7>>=
mykey <- simpleKey(levels(sim2$test), points = FALSE, lines = TRUE)
print(xyplot(power ~ diff | nlevels + nobs, group = ~ test, data = sim2, 
             type = "b", xlab="Violation Magnitude", ylab="Power", key=mykey))
@
\end{figure}

Taken together, the results from Simulation 1 and Simulation
2 provide evidence that the $\text{LM}_o$ statistic should be
preferred to the $\text{WDM}_o$ statistic for testing measurement
invariance. \readme{This is not surprising given that the models
have quite a few parameters and we change many of them. We could 
try to set up a simulation where only a single out of many parameters
changes where the WDM should perform better. Also,
in models that are simpler than most CFA models, the WDM may be more useful.
I'm not sure how much we want to comment on this or illustrate this.}
The $\text{LM}_o$ statistic has higher power to detect
ordinal violations, and its power to detect non-ordinal violations was
similar to that of $\text{WDM}_o$ when the violation magnitude was
small (e.g., for $d \leq 1.5$).  The $\text{LM}_o$ statistic is
advantageous because it can make use of invariance violations that
simultaneously 
occur in multiple parameters, whereas the $\text{WDM}_o$ focuses only
on the parameter with the largest invariance violation.  
Thus, the statistics are likely to exhibit
similar performance if only a single model parameter violated
measurement invariance.

In the next section, we compare the proposed statistics to the
likelihood ratio test with real data.

\section{Application: Youth Gratitude}

\subsection{Background}

With the positive psychology movement, the construct of gratitude has
received much research attention (for a review, see \citeNP{EmmMcc04}).
Recently, scholars have begun to explore gratitude
in youth. However, one potential problem with this research is that
scholars, with no exception, have used adult gratitude inventories to
measure youth gratitude, thus raising the question of whether the
existing gratitude scales used with adults are valid in research with
youth. Addressing this issue, \citeNP{FroFan11} had a
large sample of 
youth ($n$ = 1401, ranging from late childhood (10 years old) to
late adolescent (19 years old)) complete the three most widely used
adult gratitude inventories, including Gratitude Questionnaire~6
(GQ-6; \citeNP{MccEmm02}), Gratitude Adjective
Checklist (GAC; \citeNP{MccEmm02}), and Gratitude, Resentment,
Appreciation Test-Short Form (GRAT-Short Form;
\citeNP{ThoWat03}). The authors were interested in whether the
youth factor structure 
for the gratitude scales resembles that of 
adults, and whether the gratitude scales are invariant across the
youth age groups. 

% references
% Emmons, R. A., & McCullough, M. E. (Eds.). (2004). The psychology of gratitude. New York, NY: Oxford University Press. 
% McCullough, M. E., Emmons, R. A., & Tsang, J.-A. (2002). The grateful disposition: A conceptual and empirical topography. Journal of Personality and Social Psychology, 82, 112-127. doi: 10.1037/0022-3514.82.1.112 
% Thomas, M., & Watkins, P. (2003, April). Measuring the grateful trait: Development of the revised GRAT. Poster session presented at the Annual Convention of the Western Psychological Association, Vancouver, British Columbia, Canada. 

\subsection{Method}

\citeNP{FroFan11} used confirmatory factor analysis
models to study the invariance of three youth gratitude scales across
students aged 10 to 19 years.  Due to sample size constraints, the age
variable included six categories: 10--11 years, 12--13 years, 14 years,
15 years, 16 years, and 17--19 years.  Thus, age is an ordinal variable
with which the proposed tests can be applied.

To test for measurement invariance w.r.t.\ age, each of the three scales
was individually 
factor-analyzed using the items that comprised the scale.
For each model, the authors 
first fit a congeneric model (all parameters free for each level of age),
followed by a tau-equivalent model (factor loadings restricted to be
equal across each level of age) and a parallel model (all parameters restricted
to be equal across levels of age).  Because their sample size was large ($n
\approx 1400$), they could not rely solely on likelihood ratio tests
(i.e., $\chi^2$ difference tests) for model comparison because the
tests were overly sensitive at their sample size.  To supplement these
tests, \citeNP{FroFan11} examined a set of alternative fit indices, including
the non-normed fit index, the comparative fit index, and the
incremental fit index. %% TODO cite
The authors generally found support for the tau-equivalent models
through these alternative fit indices; the likelihood ratio test often
resulted in significance event when the alternative indices indicated
good fit.

In the analyses described below, we re-analyze the \citeNP{FroFan11} data using
the ordinal test statistics proposed in this paper.  This results in a
series of tests that are less sensitive than the likelihood ratio test
to minor parameter discrepancies,
while being more sensitive to ordinal violations of measurement invariance.
We focus on two analyses from \citeNP{FroFan11} where the likelihood
ratio test resulted in significance (indicating that the restricted
model did not fit as well as the less-restricted model), but the
alternative fit measures employed by \citeNP{FroFan11} indicated the opposite.
These include
comparison of a one-factor congeneric model to a one-factor
tau-equivalent model using the 
GQ6 and comparison of a one-factor tau-equivalent model to a one-factor
parallel model 
using the GAC.  To conduct equivalent analyses via the proposed tests, we
fit the more-restricted model in each case and test for instability in
the focal model parameters.

Of the 1401 cases originally collected by \citeNP{FroFan11}, we use here all
subjects with complete data (resulting in $n=1327$).

<<frohdata>>=
yg <- read.spss("grat data combined_9.29.09.sav", to.data.frame=TRUE)
names(yg) <- tolower(names(yg))

## Remove cases with 'imputed' values
yg <- yg[yg$ao_4 <= 9,]
decimals <- apply(yg[,4:28]%%1 > 0, 1, sum)
yg <- yg[decimals==0,]

## TODO Simulate critical values for ordL2BB
@ 

\subsection{Results}

The results section is divided into two subsections, one for each of
the analyses described previously.  The first section contains an
example of the ordinal statistics disagreeing with the likelihood
ratio tests, while the second section contains the opposite.

<<gq6>>=
m1 <- cfa('f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
          data=yg, group="agegroup", group.equal="loadings",
          meanstructure=TRUE)
gefp1 <- gefp(m1, fit = NULL, scores=estfun.lavaan, order.by = yg$agegroup, 
              vcov = info_full, sandwich = FALSE, parm=1:4)
if(file.exists("ol2bb1.rda")){
  load("ol2bb1.rda")
} else {
  ol2bb1.fun <- ordL2BB(gefp1)
  save(ol2bb1.fun, file="ol2bb1.rda")
}
omax1 <- sctest(gefp1, functional=ordwmax(gefp1))
ol2bb1 <- sctest(gefp1, functional=ol2bb1.fun)

## Full model
m1.f <- cfa('f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
            data=yg, group="agegroup", meanstructure=TRUE)
lrt1 <- anova(m1.f, m1)
@ 

\subsubsection{GQ-6} In fitting a tau-equivalent model and a congeneric
model to the GQ-6 data, \citeNP{FroFan11} used alternative fit indices to
conclude that the tau-equivalent model was as good as the congeneric
model.  However, the likelihood ratio test comparing these two models
was significant ($\chi^2_{20} = \Sexpr{round(lrt1[[5]][2],1)}, p=\Sexpr{round(lrt1[[7]][2],2)}$ for the data considered
here).  

We can use the proposed ordinal statistics to compare the
tau-equivalent and congeneric models,
fitting the tau-equivalent model and testing whether or
not the factor loadings fluctuate with respect to age group.  In doing
so, we obtain~$\text{WDM}_o=\Sexpr{round(omax1$statistic,1)}, p=\Sexpr{round(omax1$p.value,2)}$
 and~$\text{LM}_o=\Sexpr{round(ol2bb1$statistic,1)}, p=\Sexpr{round(ol2bb1$p.value,2)}$.
Neither statistic is significant at an $\alpha$ of 0.05,
which supports the conclusions that \citeNP{FroFan11} obtained from
alternative fit statistics.  This provides further evidence that the
likelihood ratio statistic is overly sensitive for this particular
analysis.

<<gac>>=
m2 <- cfa('f1 =~ gac_1 + gac_2 + gac_3
           f1 ~ 0*1', data=yg, group="agegroup",
           group.equal=c("loadings","residuals","lv.variances"), 
           meanstructure=TRUE)
gefp2 <- gefp(m2, fit = NULL, scores=estfun.lavaan, order.by = yg$agegroup, 
              vcov = info_full, sandwich = FALSE, parm=3:6)
if(file.exists("ol2bb2.rda")){
  load("ol2bb2.rda")
} else {
  ol2bb2.fun <- ordL2BB(gefp2)
  save(ol2bb2.fun, file="ol2bb2.rda")
}
omax2 <- sctest(gefp2, functional=ordwmax(gefp2))
ol2bb2 <- sctest(gefp2, functional=ol2bb2.fun)

## Full model
m2.f <- cfa('f1 =~ gac_1 + gac_2 + gac_3
           f1 ~ 0*1', data=yg, group="agegroup",
           group.equal="loadings", meanstructure=TRUE)
lrt2 <- anova(m2.f, m2)
@ 

\subsubsection{GAC} In fitting tau-equivalent and parallel models to the
GAC data, \citeNP{FroFan11} obtained mixed results.  The alternative fit
indices did not all agree with one another, and the likelihood ratio test
indicated that the parallel model fit worse than the tau-equivalent
model ($\chi^2_{20} = \Sexpr{round(lrt2[[5]][2],1)}, p<0.01$
for the data considered here).  \citeNP{FroFan11} ultimately 
concluded that the tau-equivalent model provided a better fit than did
the parallel model.

To apply the ordinal statistics proposed in this paper, we fit the
parallel model and test for instability in the variance parameters
(unique variance and factor variance) w.r.t.\ age.
This results in~$\text{WDM}_o=\Sexpr{round(omax2$statistic,1)}, p<0.01$
and~$\text{LM}_o=\Sexpr{round(ol2bb2$statistic,1)}, p<0.01$.
Both of these statistics agree with the likelihood ratio test and with
the general conclusion that the tau-equivalent model is better than
the parallel model.  This provides further evidence that the
significant likelihood ratio test is not simply an artifact of the
large sample size.

\subsection{Summary}
The application considered above shows that the ordinal test
statistics can provide useful information in situations where one
might question significant likelihood ratio test statistics.  While
researchers use rules of thumb to obtain decisions from other
alternative fit measures, the proposed statistics are proper tests of
the hypothesis of interest.  They can be used to either supplement or
replace the likelihood ratio test, depending upon the measurement
invariance violations in which the researcher is interested a priori.
We further describe the issue of supplementing vs.\ replacing the
likelihood ratio test in the general discussion.

\section{General Discussion}

In this paper, we proposed two statistics for studying measurement
invariance that can be used when one has an auxiliary ordinal
variable.    To our knowledge,
the ordinal measurement invariance statistics proposed here are the
only ones that treat auxiliary variables as ordinal.  Other methods
treat the auxiliary variable as either continuous or categorical, in a
manner similar to the treatment of ordinal predictor variables in
linear regression.  In the remainder of the paper, we provide 
detail on test choice and on the tests' applicability to other
models.

\paragraph{Choice of Test}
The results presented in this paper imply that the proposed
ordinal statistics may ``miss'' measurement invariance violations that
are not monotonic w.r.t.\ $V$, moreso than the likelihood ratio test.  We
speculate that, in most applications, this will not be a major issue
because the researcher's a priori hypotheses exclusively focus on
monotonic measurement 
invariance violations.  For example, in the youth gratitude
application, we tested for measurement invariance across six age
groups.  If we observed a measurement invariance violation whereby
factor loadings were equal at all age groups except 14 years,
we would
have a hard time explaining the violation as anything but an anomaly
in the 14-year-olds.  Further, if $n$ is large, we are likely to
suspect that the result arises from the large sample size.
We may still be interested in why the
14-year-olds differed, but the analysis is purely exploratory at this
point because this type of violation was unexpected.  
However, there is generally a tradeoff between the ordinal statistics
and the likelihood ratio statistic.  The
proposed ordinal statistics usually provide sharper tests of one's a
priori hypothesis regarding measurement invariance w.r.t.\ ordinal
$V$, while the likelihood ratio statistic provides a sharper test of
general (non-monotonic) measurement invariance w.r.t.\ $V$.  While the
latter feature may be important in some high-stakes applications, many
researchers are likely to find the former feature appealing for their
work. 

\paragraph{Extension to Other Models}
We focused on testing for measurement invariance in factor
analysis models here, but the proposed test statistics are applicable to
other psychometric models that are estimated via ML.  The only
requirement for carrying out the tests is that the casewise scores
(Equation~\eqref{eq:score}) be available following model estimation.
As a result, applications to studying DIF in IRT are immediate,
as are general psychometric applications to studying parameter
stability w.r.t.\ ordinal auxiliary variables.  We expect the
same general results to hold for these applications, whereby the
proposed test statistics are better than the LRT for detecting
monotonic instabilities.   The strucchange package \cite{Zei06} noted
previously can be used for these more-general applications.

\subsection{Summary}
The test statistics proposed in this paper have high power for
detecting measurement 
invariance violations that are monotonic with the ordinal variable,
and they have low power for detecting minor violations that are not
monotonic.  The former feature implies that the statistics are good at
detecting measurement invariance violations that are interpretable to
the researcher, while the latter feature implies that the statistics
are feasible in situations where the likelihood ratio test commonly
rejects $H_0$ in practice (e.g., \citeNP{Bent80}).  Furthermore, the
focal psychometric model does not have to be modified in any way,
which differs from approaches that may treat the ordinal variable as
continuous 
(e.g., \citeNP{BauHus09,MolDol10,NeaAgg06}).  In all, the tests have
advantageous properties that should be useful in practice.


\section*{Computational Details}

All results were obtained using the {R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on package
{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} for fitting of the factor analysis models and
{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. {R}~and the packages {lavaan} and {strucchange} are
freely available under the General Public License~2 from the
Comprehensive {R} Archive Network at \url{http://CRAN.R-project.org/}.
{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.


\bibliography{refs}

\end{document}
