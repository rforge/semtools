\documentclass[man]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm}
%% need no \usepackage{Sweave}
\SweaveOpts{engine = R, eps = TRUE, echo = FALSE, results = hide}

\title{Generalized measurement invariance tests with application to
  factor analysis}
\twoauthors{Edgar C. Merkle}{Achim Zeileis}
\twoaffiliations{University of Missouri}{Universit\"{a}t Innsbruck}

\abstract{
  The issue of measurement invariance commonly arises in factor-analytic
  contexts, with methods for assessment including likelihood ratio tests,
  Lagrange multiplier tests, and Wald tests. These tests all require advance
  definition of the number of groups, group membership, and offending model
  parameters. In this paper, we construct tests of measurement invariance based on
  stochastic processes of casewise derivatives of the likelihood function. These
  tests can be viewed as generalizations of the Lagrange multiplier test, and they
  are especially useful for: (1)~isolating specific parameters affected by
  measurement invariance violations, and (2)~identifying subgroups of individuals
  that violated measurement invariance based on a continuous auxiliary variable. 
  The tests are presented and illustrated in detail, along with simulations
  examining the tests' abilities in controlled conditions.
}

\acknowledgements{This work was supported by National Science
  Foundation grant SES-1061334. Correspondence to Edgar C.\ Merkle,
  Department of  
  Psychological Sciences, University of Missouri, Columbia,
  MO 65211.
  Email: {\texttt{merklee@missouri.edu}}.}
\shorttitle{Generalized measurement invariance tests}
\rightheader{Generalized measurement invariance tests}

\newcommand{\argmax}{\operatorname{argmax}\displaylimits}

%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}

\spacing{1}

\begin{document}
\maketitle

<<preliminaries>>=
library("OpenMx")
library("lavaan")
library("strucchange")
library("mvtnorm")
library("lattice")
source("mz.R")
source("wdh.R")
source("sim.R")
@

The assumption that parameters are
invariant across observations is a
fundamental tenet of many statistical models.  A specific type of 
parameter invariance, measurement invariance, has implications for the
general design and use of psychometric scales.
This concept is 
particularly important because violations can render the scales
difficult to interpret.  
That is, if a set of scales violates measurement invariance,
then individuals with the same ``amount'' of a latent variable 
may systematically receive 
different scale scores.
This may lead researchers to conclude subgroup
differences on a wide variety of interesting constructs 
when, in reality, the scales impact the magnitude of the 
differences.  Further, it can be inappropriate to incorporate scales
violating measurement invariance into structural equation
models, where relationships between latent variables are hypothesized.
\citeA{HorMca92} concisely summarize the impact of
these issues, stating ``Lack of evidence of measurement 
invariance equivocates conclusions and casts doubt on theory in the
behavioral sciences'' (p.~141).  \citeA{Bor06a} further 
notes that researchers often fail to assess whether measurement
invariance holds.

In this paper, we consider a new family of tests for assessing
measurement invariance that has important advantages over existing
tests.  We begin by developing a general framework for the tests.
This leads to a discussion of theoretical results relevant to the
proposed tests, as well as a comparison of the proposed tests to the 
existing tests.  Next,
we study the 
proposed tests' abilities through example and simulation.  Finally,
we discuss some interesting extensions of the tests.
Throughout the manuscript, we use the term {\em{test}} to refer to a
statistical test and the term {\em{scale}} to refer to a psychometric 
test or scale.

\section{Framework}

The methods proposed here are generally relevant to situations where the
$p$-dimensional random variable $X$ with associated observations $\bm{x}_i, i=1,\cdots,n$
is specified to arise from a model with density $f(\bm{x}_i; \bm{\theta})$ and
associated joint log-likelihood
\begin{equation} \label{eq:loglik}
  \ell(\bm{\theta}; \bm{x}_1, \dots, \bm{x}_n) ~=~
    \sum_{i = 1}^n \ell(\bm{\theta}; \bm{x}_i) ~=~
    \sum_{i = 1}^n  \log f(\bm{x}_i; \bm{\theta}),
\end{equation}
where ${\bm \theta}$ is some $k$-dimensional parameter vector that characterizes
the distribution. 
The methods are applicable under very general conditions, essentially
whenever standard assumptions for maximum likelihood inference hold (for more
details see below). For the measurement invariance applications
considered in this paper, we employ
a factor analysis model with assumed multivariate normality:
\begin{eqnarray}
    \label{eq:mvndensity}
    f(\bm{x}_i; \bm{\theta}) & = & \frac{1}{(2\pi)^{p/2} |
      \bm{\Sigma}(\bm{\theta}) |^{1/2}} ~ \exp \left\{ -\frac{1}{2}(\bm{x}_i -
    \bm{\mu}(\bm{\theta}))^{\top} \bm{\Sigma}(\bm{\theta})^{-1} (\bm{x}_i -
    \bm{\mu}(\bm{\theta}) \right\}, \\
    \label{eq:caselik}
    \ell(\bm{\theta}; \bm{x}_i) & = & -\frac{1}{2} \left\{
      (\bm{x}_i - \bm{\mu}(\bm{\theta}))^{\top} \bm{\Sigma}(\bm{\theta})^{-1} (\bm{x}_i - \bm{\mu}(\bm{\theta}))
      ~+~ \log | \bm{\Sigma}(\bm{\theta}) | ~+~ p \log(2 \pi) \right\},
\end{eqnarray}
with model-implied mean vector ${\bm{\mu}}({\bm{\theta}})$ and
covariance matrix ${\bm{\Sigma}}({\bm{\theta}})$. As pointed out above,
the assumptions for the tests introduced here do not require this specific
form of the likelihood, but it is presented for illustration due to
its importance in practice.  Many expositions of factor analysis
utilize the likelihood for the sample covariance matrix, which is
based on a Wishart distribution when the $\bm{x}_i$ are assumed to be
multivariate normal.
However, the techniques presented below require the casewise contributions
to the likelihood; this situation is also generally
encountered in structural equation models with missing data (e.g.,
\citeNP{Wot00}).

Within the general framework outlined above and under the usual
regularity conditions (e.g., \citeNP{Fer96}), the model parameters
$\bm{\theta}$ can 
be estimated by maximum likelihood (ML), i.e.,
\begin{equation} \label{eq:ml}
  \hat{\bm{\theta}} ~=~ \argmax_{\bm{\theta}} \ell(\bm{\theta}; x_1, \dots, x_n),
\end{equation}
or equivalently by solving the first order conditions
\begin{equation}
    \label{eq:ml1}
  \sum_{i=1}^{n} {\bm s}(\hat{\bm{\theta}}; \bm{x}_i) ~=~ 0,    
\end{equation}
where 
\begin{equation}
  \label{eq:score}
  {\bm s}({\bm \theta}; x_i) ~=~ \left(
    \frac{\partial \ell({\bm \theta}; x_i)}{\partial \theta_1},
    \dots,
    \frac{\partial \ell({\bm \theta}; x_i)}{\partial \theta_k}
  \right)^\top,
\end{equation}
is the score function of the model, i.e., the partial derivative of the casewise
likelihood contributions w.r.t.\ the parameters $\bm{\theta}$.
Evaluation of the score function at $\hat{\bm{\theta}}$ for $i=1,
\dots, n$ essentially measures the extent to which each individual's
likelihood is maximized.

One central assumption -- sometimes made implicitly -- is that
the same model parameters $\bm{\theta}$ hold for all individuals $i = 1, \dots, n$.
If this is not satisfied, the estimates $\hat{\bm{\theta}}$ are typically
not meaningful and cannot be easily interpreted.
One potential source of deviation from this assumption is lack of
measurement invariance, investigated in the following section.



\section{Tests of Measurement Invariance}

In general terms, a set of scales is defined to be measurement
invariant with respect to an auxiliary variable $V$ if:
\begin{equation}
    \label{eq:midef}
      f({\bf X} | T, V, \dots) = f({\bf X} | T, \dots),
\end{equation}
where ${\bf X}$ is a data matrix, $T$ is the latent
variable that the scales purport to measure, and $f$ is the model's
distributional form \cite{Mel89}.  In the parametric,
factor-analytic framework
adopted here, this implies that the measurement parameters are equal
across subgroups of individuals and, thus, do not vary with any
variable $V$ \cite{Mer93}.

To frame this as a formal hypothesis, we assume that -- in principle --
Model~(\ref{eq:loglik}) holds for all individuals but with a
potentially individual-specific 
parameter vector ${\bm \theta}_i$. The null hypothesis of measurement invariance
is then equivalent to the null hypothesis of parameter constancy
\begin{equation}
    \label{eq:h0}
    H_0:~ {\bm \theta}_i = {\bm \theta}_0,\quad (i=1,\ldots,n),
\end{equation}
which should be tested against the alternative that the parameters
are some nonconstant function ${\bm \theta}(\cdot)$ of the variable $V$ with observations
$v_1, \dots, v_n$, i.e.,
\begin{equation}
    \label{eq:h1}
    H_1:~ {\bm \theta}_i = {\bm \theta}(v_i),\quad (i=1,\ldots,n).
\end{equation}
where the pattern ${\bm \theta}(V)$ of deviation from measurement invariance is
typically not known (exactly) in practice. If it were (see below for
some concrete examples), then standard inference methods -- such as likelihood
ratio, Wald, or Lagrange multiplier tests -- could be employed. However,
if the pattern is unknown, it is difficult to develop a single test
that is well-suited for all conceivable patterns. But it is possible to
derive a family of tests so that representatives from this family are well-suited
for a wide range of possible patterns. One pattern of particular interest
involves $V$ dividing the individuals into two subgroups with different
parameter vectors
\begin{equation}
  \label{eq:h1*}
  H_1^*:~ {\bm \theta}_i = \left\{ \begin{array}{ll}
    {\bm \theta}^{(A)} & \mbox{if } v_i \le \nu, \\
    {\bm \theta}^{(B)} & \mbox{if } v_i >   \nu,
  \end{array} \right.
\end{equation}
where ${\bm \theta}^{(A)} \neq {\bm \theta}^{(B)}$. This could pertain to 
two different age groups, income groups, genders, etc.

Note that even when adopting $H_1^*$ as the relevant alternative, the pattern
${\bm \theta}(V)$ is not completely specified unless the cutpoint $\nu$ is known
in advance (i.e., unless there is observed heterogeneity).  In this situation, all individuals can be grouped based on $V$, and
we can apply standard theory: nested multiple group models (e.g.,
\citeNP{Jor71,Bol89}) coupled with likelihood ratio (LR) tests are most common,
although the asymptotically equivalent  Lagrange multiplier
(LM) and Wald tests may also be constructed for this purpose (see
\citeNP{Sat89}). If $\nu$
is unknown (as is often the case for continuous $V$), however, then
there is unobserved heterogeneity and standard theory 
is not easily applied.   Nonstandard inference methods, such as those
proposed in this paper, are then required.

In the following section, we describe the standard approaches to
testing measurement invariance with $\nu$ known.  We then contrast
these approaches with the tests proposed in this paper.
We assume throughout that the observations $i = 1, \dots, n$ are
ordered with respect to the random variable $V$ of interest such that
$v_1 \le v_2 \le \dots \le v_n$.  We also assume that the measurement
model is correctly specified, as is implicitly assumed under traditional
measurement invariance approaches.  In particular, violations of
normality may lead to spurious results in the proposed tests just as
they do in other approaches (e.g., \citeNP{BauCur04}).


\subsection{Likelihood Ratio, Wald, and Lagrange Multiplier Test for Fixed Subgroups}

To employ the LR~test for assessing measurement invariance, model
parameters are estimated separately for a certain number of subgroups
of the data (with some parameters potentially restricted to be equal across
subgroups).  For ease of exposition, we describe
the case where there are no such parameter restrictions; as shown in
the example and simulation below, however, it is
straightforward to extend all methods to the more general case.
After fitting the model to each subgroup, the sum of maximized likelihoods 
from the subgroups are compared with the original maximized full-sample likelihood
in a $\chi^2$~test. For the special case of two subgroups,
the alternative $H_1^*$ from (\ref{eq:h1*}) with fixed and prespecified $\nu$ is adopted
and the null hypothesis $H_0$ from (\ref{eq:h0}) reduces to ${\bm \theta}^{(A)} = {\bm \theta}^{(B)}$.
The parameter estimates $\hat {\bm \theta}^{(A)}$ can then be obtained from the
observations $i = 1, \dots, m$, say, for which $v_i \le \nu$. Analogously,
$\hat {\bm \theta}^{(B)}$ is obtained by maximizing the likelihood for the
observations $i = m + 1, \dots, n$, for which $v_i > \nu$. The LR~test statistic
for the given threshold $\nu$ is then
\begin{equation} \label{eq:lr}
  \mathit{LR}(\nu) ~=~ -2 \left[
         \ell(\hat {\bm \theta}; x_1, \dots, x_n)
   ~-~ \{\ell(\hat {\bm \theta}^{(A)}; x_1, \dots, x_m)
    +    \ell(\hat {\bm \theta}^{(B)}; x_{m+1}, \dots, x_n)\}
    \right],
\end{equation}
which, when \eqref{eq:h1*} holds, has an asymptotic $\chi^2$ with degrees
of freedom equal to the number of parameters in~${\bm \theta}$.

Analogously to the LR~test, the Wald test and LM test (also known as score test)
can be employed to test the null hypothesis $H_1^*$ for a fixed threshold $\nu$.
For the Wald test, the idea is to compute the Wald statistic $W(\nu)$ as a quadratic
form in $\hat {\bm \theta}^{(A)} - \hat {\bm \theta}^{(B)}$, utilizing its estimated
covariance matrix for standardization. For the LM test, the LM statistic
$\mathit{LM}(\nu)$ is a quadratic form in ${\bm s}(\hat {\bm \theta}; x_1, \dots, x_m)$
and ${\bm s}(\hat {\bm \theta}; x_{m+1}, \dots, x_n)$. Thus, the three tests all assess
differences that should be zero under $H_0$: for the LR~test the difference of maximized
likelihoods; for the Wald test, the difference of parameter estimates; and for the
LM test, the differences of likelihood scores from zero. In the LR~case, the parameters
have to be estimated under both the null hypothesis and alternative.
Conversely, the Wald case requires  
only the estimates under the alternative, while the LM case requires
only the estimates under the null hypothesis.


\subsection{Extensions for Unknown Subgroups}

For assessing measurement invariance in psychometric models, the major limitation of
the three tests is that the potential subgroups have to be known in advance. 
Even if the variable $V$ w.r.t.\ which the violation of invariance occurs is
known, the threshold $\nu$ from (\ref{eq:h1*}) is often unknown in practice.
For example, if $V$ represents yearly income, there are many possible
values of $\nu$ that could be used to divide individuals into poorer and richer
groups.  The ultimate $\nu$ that we
choose could potentially impact our
conclusions about whether or not a scale is measurement invariant, 
in the same way that dichotomization of continuous variables impacts
general psychometric analyses \cite{MacZha02}.

Instead of choosing a specific $\nu$, a natural idea is to compute $\mathit{LR}(\nu)$
for each possible value in some interval $[\underline{\nu}, \overline{\nu}]$ and
reject if their maximum
\begin{equation} \label{eq:maxlr}
  \max_{\nu \in [\underline{\nu}, \overline{\nu}]} \mathit{LR}(\nu)
\end{equation}
becomes large. Note that this corresponds to maximizing the likelihood w.r.t.\
an additional parameter, namely $\nu$. Hence, the asymptotic distribution of the
maximum $\mathit{LR}$ statistic is not $\chi^2$ anymore. \citeA{And93}
showed that the asymptotic distribution is in fact tractable but nonstandard.
Specifically, the asymptotic distribution of (\ref{eq:maxlr}) is the maximum of a
certain tied-down Bessel process whose specifics also depend on the minimal
and maximal thresholds $\underline{\nu}$ and $\overline{\nu}$, respectively.
See Andrews for the original results and further references, and see 
below for more details on the results' application to measurement invariance.

Analogously, one can consider $\max W(\nu)$ and
$\max \mathit{LM}(\nu)$, respectively, which both have the same asymptotic properties
as $\max \mathit{LR}(\nu)$ and are asymptotically equivalent \cite{And93}.
From a computational perspective, the $\max \mathit{LM}(\nu)$ test is
particularly convenient 
because it requires just a single set of estimated parameters $\hat {\bm \theta}$
which is employed for all thresholds $\nu$ in $[\underline{\nu},
\overline{\nu}]$.  
The other two tests require reestimation of the subgroup model for each
$\nu$.

So far, the discussion focused on the alternative $H_1^*$: The maximum LR, Wald, and LM
tests are designed for a situation where there is a single threshold at which all
parameters in the vector ${\bm \theta}$ change. While this is plausible and intuitive
in many applications, it would also be desirable to obtain tests that direct their power
against other types of alternatives, i.e., against $H_1$ with other patterns ${\bm \theta}(V)$.
For example, the parameters may fluctuate randomly or there might be multiple thresholds
at which the parameters change. Alternatively, only one (or just a few) of the parameters in
the vector ${\bm \theta}$ change while the remaining parameters are
constant (a common occurrence in psychometric models).
To address such situations in a unified way, the next section contains 
a general framework for testing measurement invariance along a
(continuous) variable $V$ that
includes the maximum LM test as a special case.


\section{Stochastic Processes for Measurement Invariance}

As discussed above, factor analysis models are typically
estimated by fitting the model to all $i = 1, \dots, n$ individuals, assuming
that the parameter vector ${\bm \theta}$ is constant across individuals.
Having estimated the parameters $\hat {\bm \theta}$, the goal is to check that
all subgroups of individuals conform with the model (for all 
of the parameters). Hence, some measure of model deviation or residual is required
that captures the lack of fit for the $i$-th individual at the $j$-th parameter
($i = 1, \dots, n$, $j = 1, \dots, k$). A natural measure -- that employs the ideas
of the LM test -- is ${\bm s}(\hat {\bm \theta}; x_i)_j$: the $j$-th component of the
contribution of the $i$-th observation to the score function. By construction, the sum
of the score contributions over all individuals is zero for each
component; see
(\ref{eq:ml1}). Moreover, if there are no systematic deviations, the score contributions
should fluctuate randomly around zero.  Conversely, the score
contributions should be shifted away from zero for
subgroups where the model does not fit.

Therefore, to employ this quantity for tests of measurement invariance against alternatives
of type (\ref{eq:h1}), we need to overcome two obstacles: (1)~make use of the ordering of
the observations w.r.t.\ $V$ because we want to test for changes ``along'' $V$; (2)~account
for potential correlations between the $k$~components of the parameters to be able to detect
which parameter(s) change (if any).

\subsection{Theory}

The test problem of the null hypothesis (\ref{eq:h0}) against the alternatives
(\ref{eq:h1}) and (\ref{eq:h1*}), respectively, has been studied extensively
in the statistics and econometrics literature under the label ``structural change
tests'' (see e.g., \citeNP{BroDur75,And93}) where the focus of interest is the
detection of parameter instabilities of time series models ``along'' time.
Specifically, it has been shown (e.g., \citeNP{Nyb89,Han92,HjoKon02,ZeiHor07})
that cumulative sums of the empirical scores follow specific stochastic processes, allowing
us to use them to generally test measurement invariance. Here, we review
some of the main results from that literature and adapt it to the specific challenges
of factor analysis models. More detailed accounts of the underlying structural
change methods include \citeA{HjoKon02} and \citeA{ZeiHor07}.

For application to measurement invariance, the most important
theoretical result involves the fact that, under the $H_0$ in \eqref{eq:h0}, the
\emph{cumulative score process} converges to a specific asymptotic
process. The $k$-dimensional cumulative score process is defined as
\begin{equation} \label{eq:cumscore}
  {\bm B}(t; \hat {\bm \theta}) ~=~ \hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i = 1}^{\lfloor n t \rfloor} {\bm s}(\hat {\bm \theta}; x_i)
  \qquad (0 \le t \le 1)
\end{equation}
where $\lfloor nt \rfloor$ is the integer part of $nt$ and
$\hat I$ is some consistent estimate of the covariance matrix of the scores,
e.g., their outer product or the observed information matrix.
The $k$ dimensions of the 
process arise from the fact that a separate cumulative score is
maintained for each of the $k$ model parameters.  
As the equation shows, the cumulative score process adds subsets of
casewise score contributions across individuals along the ordering
w.r.t.\ the variable $V$ of interest.  At $t=1/n$, only the
first individual's contribution enters into the summation; at
$t=2/n$, the first two individuals' contributions enter into the
summation, etc., until $t = n/n$
where all contributions enter into the summation. Thus, due to (\ref{eq:ml1}),
the cumulative score process always equals zero at $t = 0$ and
returns to zero at $t = 1$. Furthermore, multiplication by
$\hat {\bm I}^{-1/2}$ ``decorrelates'' the $k$ cumulative score
processes, such that each univariate process (i.e., each
process for a single model parameter) is unrelated to (and asymptotically independent of) all other
processes. Therefore, this cumulative process ${\bm B}(t; \hat {\bm \theta})$
accomplishes the challenges discussed at the beginning of this section:
it makes use of the ordering of the observations by taking cumulative sums,
and it decorrelates the contributions of the $k$ different parameters.

Inference can then be based on an extension of the usual central limit
theorem. Under the assumption of independence of individuals (implicit
already in Equation~\ref{eq:loglik}) and under
the usual ML regularity conditions (assuring asymptotic normality
of $\hat {\bm \theta}$), \citeA{HjoKon02} show
that 
\begin{equation} \label{eq:fclt}
  {\bm B}(\cdot; \hat {\bm \theta}) ~\overset{d}{\rightarrow}~ {\bm B}^{0}(\cdot),
\end{equation}
where $\overset{d}{\rightarrow}$ denotes convergence in distribution
and ${\bm B}^{0}(\cdot)$ is a $k$-dimensional Brownian bridge.
In words, there are $k$ cumulative score processes, one for each
model parameter.  This collection of processes follows a
multidimensional Brownian bridge as score contributions accumulate in the 
summation from individual 1 (with lowest value of $V$) to individual $n$
(with highest value of $V$).

The empirical cumulative score process from (\ref{eq:cumscore}) can also be viewed
as an $n \times k$ matrix with elements ${\bm B}(i/n; \hat {\bm \theta})_j$ that
we also denote ${\bm B}(\hat {\bm \theta})_{ij}$ below for brevity.
That is, assuming that individuals are ordered by $V$, the first row
of ${\bm B}(\hat {\bm \theta})$ corresponds to the first individual's
scores.  The second row of ${\bm B}(\hat {\bm \theta})$ corresponds to
the sum of the first two individuals' scores, etc., until the last row
of ${\bm B}(\hat {\bm \theta})$ corresponds to the sum of all
individuals' scores (which will be a row of zeroes).
Under this setup, each column of ${\bm B}(\hat {\bm \theta})$
converges to a univariate Brownian bridge and pertains 
to a single factor analysis parameter. To carry out a test of $H_0$, the process/matrix
needs to be aggregated to a scalar test statistic by collapsing across
rows (individuals) and columns (parameters) of the matrix. The asymptotic distribution
of this test statistic is then easily obtained by applying the same
aggregation to the asymptotic Brownian bridge \cite{HjoKon02,ZeiHor07},
so that corresponding $p$-values can be derived.

As argued above, no single aggregation function will have high power for all
conceivable patterns of measurement invariance ${\bm \theta}(V)$, while any
(reasonable) aggregation function will have non-trivial power under $H_1$.
Thus, various aggregation strategies should be employed depending on which
pattern ${\bm \theta}(V)$ is most plausible (because the exact pattern
is typically
unknown). A particularly agnostic aggregation strategy is to reject $H_0$
if any component of the the cumulative score process ${\bm B}(t; \hat {\bm \theta})$
strays ``too far'' from zero at any time, i.e., if
\begin{equation}
    \label{eq:dmax}
    \mathit{DM} = \max_{i = 1,\dots, n} \max_{j = 1, \dots, k} | {\bm B}(\hat {\bm \theta})_{ij} |,
\end{equation}
becomes large.  In determining where in ${\bm B}(\hat {\bm \theta})$
this maximum occurred, we are able to determine  
threshold(s) of parameter change (over the individuals $i = 1, \dots, n$)
and the parameter(s) affected by it (over $j = 1, \dots, k$). This test is
especially useful for visualization, as the cumulative score process for
each individual parameter can be displayed along with the appropriate
critical value.  An example of this visualization appears in the 
example section (first row, second column of Figure~\ref{fig:cusumex}).

However, taking maximums ``wastes'' power if many of the $k$~parameters change
at the same threshold, or if the score process takes large values for
many of the $n$~individuals (and not just a single threshold). In such
cases, sums insteads of maxima are more suitable for collapsing across
parameters and/or individuals, because they combine the deviations instead of
picking out only the single largest deviation. Thus, if the parameter instability
${\bm \theta}(V)$ affects many parameters and leads to many subgroups, sums
of (absolute or squared) values should be used for collapsing both across
parameters and individuals. On the other hand, if there is just a single
threshold that affects multiple parameters, then the natural aggregation
is by sums over parameters and then by the maximum over individuals.
More precisely, the former idea leads to a Cram{\'e}r-von Mises type
statistic and the latter to the maximum LM statistic from the previous section:
\begin{eqnarray}
    \label{eq:cvm}
    \mathit{CvM}     & = & n^{-1} \sum_{i = 1,\dots, n} \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2, \\
    \label{eq:maxlm}
    \max \mathit{LM} & = & \max_{i = \underline{i}, \dots, \overline{\imath}} ~
      \left\{ \frac{i}{n} \left( 1 - \frac{i}{n} \right) \right\}^{-1}
      \sum_{j = 1, \dots, k} {\bm B}(\hat {\bm \theta})_{ij}^2,
\end{eqnarray}
where the $\max \mathit{LM}$ statistic is additionally scaled by the
asymptotic variance $t (1 - t)$ of the process ${\bm B}(t, \hat {\bm \theta})$.
It is equivalent to the $\max_\nu \mathit{LM}(\nu)$ statistic from the previous
section, provided that the boundaries for the subgroups sizes $\underline{i}$/$\underline{\nu}$
and $\overline{\imath}$/$\overline{\nu}$ are chosen analogously.
Further aggregation functions have been suggested in the structural
change literature (see e.g., \citeNP{Zei05,ZeiSha10}) but the three
tests above are most likely to be useful in psychometric settings.

Finally, all tests can be easily modified to address the situation of
so-called ``partial structural changes'' \cite{And93}. This refers to the case of some
parameters being known to be stable, i.e., restricted to be constant across
potential subgroups. Tests for potential changes/instabilities only in the
$k^*$ remaining parameters (from overall $k$ parameters) are easily constructed
by omitting those $k - k^*$ columns from ${\bm B}(\hat {\bm \theta})_{ij}$ that are
restricted/stable, retaining only those $k^*$ columns that are potentially instable.
This may be of special interest to those wishing to test specific types of measurement
invariance, where subsets of model parameters are assumed to be stable.


\subsection{Critical Values \& $p$-values}

As pointed out above, specification of the asymptotic distribution under $H_0$ for the test
statistics from the previous section is straightforward: it is simply the aggregation
of the asympotic process ${\bm B}^0(t)$ \cite{HjoKon02,ZeiHor07}. Thus, $\mathit{DM}$
from (\ref{eq:dmax}) converges to $\sup_t || {\bm B}^0(t) ||_{\infty}$, where
$||\cdot||_\infty$ denotes the maximum norm. Similarly, $\mathit{CvM}$
from (\ref{eq:cvm}) converges to $\int_0^1 || {\bm B}^0(t) ||_2^2 d t$, where $||\cdot||^2$
denotes the Euclidean norm. Finally, $\max \mathit{LM}$ from (\ref{eq:maxlm}) -- and analogously
the maximum Wald and LR~tests -- converges to $\sup_t (t (1-t))^{-1} || {\bm B}^0(t) ||_2^2$
(which can also be interpreted as the maximum of a tied-down Bessel process, as pointed out
previously).

While it is easy to formulate these asymptotic distributions theoretically,
it is not always easy to find closed-form solutions for computing critical
values and $p$-values from them. In some cases -- in particular for the double maximum test --
such a closed-form solution is available from analytic results for Gaussian
processes (see e.g., \citeNP{ShoWel86}). For all other cases, tables of critical
values can be obtained from direct simulation \cite{Zei06} or in combination with
more refined techniques such as response surface regression \cite{Han97}.

The analytic solution for the asymptotic $p$-value of a $\mathit{DM}$ statistic
$d$ is
\begin{equation}
    \label{eq:absmax_p}
        P(\mathit{DM} > d ~|~ H_0) ~\overset{asy}{=}~ 1 - \left\{1 ~+~ 2 \sum_{h = 1}^{\infty} (-1)^h \exp(-2 h^2 d^2) \right\}^k.
\end{equation}
This combines the crossing probability of a univariate Brownian bridge
(see e.g., \citeNP{ShoWel86,PloKra92}) with a straightforward Bonferroni
correction to obtain the $k$-dimensional case. The terms in the summation
quickly go to zero as $h$ goes to infinity, so that only some large finite
number of terms (say, 100) need to be evaluated in practice.

For the Cram\'{e}r-von Mises test statistic $\mathit{CvM}$, \citeA{Nyb89}
and \citeA{Han92} provide small tables of critical values which
have been extended in the software provided by \citeA{Zei06}.
Critical values for the distribution of the maximum LR/Wald/LM tests
are provided by \citeA{Han97}. Note that the distribution depends on
the minimal and maximal thresholds employed in the test.

\subsection{Local Alternatives}
Using results from \citeA{HjoKon02} and \citeA{ZeiHor07}, we can also
capture the behaviour of the process $\bm{B}(t, \hat{\bm{\theta}})$
under specific alternatives 
of parameter instability. In particular, we can assume that the pattern
of deviation $\bm{\theta}(v_i)$ can be described as a constant
parameter plus some non-constant deviation $\bm{g}(i/n)$:
\begin{equation}
    \label{eq:local}
  \bm{\theta}(v_i) = \bm{\theta}_0 + n^{-1/2} \bm{g}(i/n).
\end{equation}
In this case, the scores $\bm{s}(\bm{\theta}_0; x_i)$ from
Equation~\eqref{eq:score} do not have zero expectation but rather
\begin{equation}
    \label{eq:localE}
  E[\bm{s}(\bm{\theta}_0; x_i)] = \bm{0} + n^{-1/2}
  \bm{C}(\bm{\theta}_0) \bm{g}(i/n).
\end{equation}
In this case, the covariance matrix $\bm{C}(\bm{\theta})$ from the expected
outer product of gradients is
\begin{equation}
    \label{eq:localS}
  \bm{C}(\bm{\theta}_0) = E[\bm{s}(\bm{\theta}_0; x_i) \bm{s}(\bm{\theta}; x_i)']    
\end{equation}
which, at $\bm{\theta}_0$, coincides with the expected information matrix.

Under the local alternative described above, \citeA{HjoKon02} show that the process
$\bm{B}(t, \hat{\bm{\theta}})$ behaves asymptotically like
\begin{equation}
    \label{eq:localB}
    \bm{B}^0(t) + \hat{\bm{I}}^{-1/2} \bm{C}(\hat{\bm{\theta}}) \bm{G}^0(t),
\end{equation}
i.e., a zero-mean Brownian bridge plus a term with non-zero mean driven by
$\bm{G}^0(t) = \bm{G}(t) - t \bm{G}(1)$, where $\bm{G}(t) = \int_0^t
\bm{g}(y) dy$.  Hence, unless the local
alternative has $\bm{g}(t) \equiv \bm{0}$, the empirical process $\bm{B}(t,
\hat{\bm{\theta}})$ will 
have a non-zero mean.  Hence, the corresponding tests will have non-trivial
power (asymptotically).  We use these results in the Simulation
section to describe the expected behavior of the Brownian bridge.


\subsection{Locating the Invariance}

If the employed parameter instability test detects a measurement invariance violation,
the researcher is typically interested in identification of the parameter(s) affected
by it and/or the associated threshold(s). As argued above, the double maximum test
is particularly appealing for this because the $k$-dimensional empirical cumulative
score process can be graphed along with boundaries for the associated critical values.
Boundary crossing then implies a violation of measurement invariance, and the location of
the most extreme deviation(s) in the process convey threshold(s) in the underlying
ordering $V$.

For the maximum LR/Wald/LM tests, it is natural to graph the sequence of LR/Wald/LM
statistics along $V$, with a boundary corresponding to the critical value.
Again, a boundary crossing signals a significant violation, and the peak(s) in the
sequence of statistics conveys threshold(s). Note that, due to summing over all
parameters, no specific parameter can be identified that is responsible for the
violation. Similarly,  neither component(s) nor threshold(s)
can be formally identified for the Cram\'{e}r-von Mises test. However, graphing of (transformations of) the cumulative
score process may still be valuable for gaining some insights (see,
e.g., Figure~\ref{fig:cusumex}).

If a measurement invariance violation is detected by any of the tests,
one may want to incorporate it into the model to account for it. The
procedure for doing this  typically depends on the type of violation ${\bm \theta}(V)$, and the visualizations
discussed above often prove helpful in determining a suitable parameterization.
In particular, one approach that is often employed in practice
involves adoptions of a model
with one (or more) threshold(s) in all parameters (i.e., (\ref{eq:h1*}) for the
single threshold case). In the multiple threshold case, their location can
be determined by maximizing the corresponding segmented log-likelihood over all
possible combinations of thresholds (\citeNP{ZeiSha10} adapt a dynamic programming
algorithm to this task). For the single threshold case, this reduces to
maximizing the segmented log-likelihood
\begin{equation} \label{eq:seglik}
  \ell(\hat {\bm \theta}^{({A)}}; x_1, \dots, x_m) ~+~ \ell(\hat {\bm \theta}^{({B)}}; x_{m+1}, \dots, x_n)
\end{equation}
over all values of $m$ corresponding to possible thresholds $\nu$ (such that $v_m \le \nu$ and
$v_{m+1} > \nu$). As pointed out previously, this is equivalent to maximizing the LR~statistic
from (\ref{eq:lr}) (with some minimal subgroup size typically imposed).

Formally speaking, the maximization of (\ref{eq:seglik}) -- or equivalently (\ref{eq:lr}) --
yields an estimate $\hat \nu$ of the threshold in $H_1^*$. If $H_1^*$ is in fact the true model,
the peaks in the Wald/LM sequences and the cumulative score process, respectively, will occur at the
same threshold asymptotically. However, in empirical samples, their location may differ somewhat
(although often not by much).

These attributes give the proposed tests important advantages over
existing tests, as existing measurement invariance methods cannot:
(1) isolate specific parameters violating measurement invariance, or
(2) test measurement invariance for unknown $\nu$. 
In particular, \citeA{Mil05} cites
``locating the invariance violation'' as a major outstanding problem
in the field.

In the next section, we employ the proposed tests to analyze existing
data from \citeA{WicDol05}.
Following the example, we consider a
full simulation study involving artificial data.

\section{Example: Stereotype Threat}

\citeA{WicDol05} utilized confirmatory
factor models to study measurement invariance in a series of
general intelligence scales.  They were interested in the
notion of {\em{stereotype threat}}, whereby stereotypes concerning a
subgroup's ability adversely impact the subgroup's performance on tests of that
ability.  The authors specifically focused on stereotypes concerning
ethnic minorities' performance on tests of general intelligence.  In this section, we use the proposed tests to supplement the authors' original analyses.

\subsection{Background}

To study stereotype threat in a measurement invariance framework, Study 1 of
\citeA{WicDol05} involved 295 high school students
completing three intelligence tests in two between-subjects conditions. 
Conditions were defined by whether or not students received primes about ethnic
stereotypes prior to testing. To study the data, Wicherts et al.\ employed a
four-group, one-factor model with the three intelligence tests as manifest
variables. The groups were defined by ethnicity (majority/minority) and by the
experimental manipulation (received/did not receive stereotype prime). Results
indicated that the intelligence tests lacked measurement invariance, with the
minority group receiving stereotype primes being particularly different from the
other three groups on the most difficult intelligence test.  In the
example below, we employ one of the models used by Wicherts et al.
Our $V$ variable is participants' grade point averages, which were unused in the original analyses.

\subsection{Method}
Wicherts et al.\ tested a series of confirmatory factor models for
various types of measurement invariance.  We focus on the model used
in their Step~5b (see pp.~703--704 of their paper), which involved
across-group parameter restrictions on the factor loadings, unique
variances, intercepts, and factor variances.  These parameters were
typically restricted to be equal across groups, though a subset of the
parameters were allowed to be group-specific upon examination of
modification indices.    The model
provided a reasonable fit to the data, as judged by examination of
$\chi^2$, RMSEA (root-mean-square error of approximation), and CFI
(comparative fit index) statistics.  While the model included four
groups as described above, we focus only on the submodel for the minority
group that received stereotype primes.

To carry out
the tests, we first fit the four-group model to the data,
calculating casewise derivatives and 
the observed information matrix.  We then
calculated the cumulative score process wrt student GPA via
\eqref{eq:cumscore}, allowing us to
obtain various test statistics and $p$-values from this 
process.  Test statistics include the double-max statistic from \eqref{eq:dmax},
the Cram\'{e}r-von Mises statistic from \eqref{eq:cvm}, and the $\max \mathit{LM}$
statistic from \eqref{eq:maxlm}.

As mentioned in the theory section, the 
tests give us the flexibility to study hypotheses of partial change.
That is, we have the ability to 
test various subsets of 
parameters.  For the Wicherts et al.\ data, we first test
\begin{equation}
    \label{eq:exh0}
H_0:\ (\nu_{i}\ \lambda_{i}\
\theta_{i}\ \alpha_{i}) = 
(\nu_{0}\ \lambda_{0}\
\theta_{0}\ \alpha_{0}),\ i=1,\ldots,n_{\text{MSP}},
\end{equation}
where $\nu_{i}$ is the intercept for student $i$ on intelligence
test 1, $\lambda_{i}$ the factor loading, $\theta_{i}$ the unique
variance, and $\alpha_i$ the factor mean.
The individuals are ordered according to GPA, and the 
hypothesis is taken only wrt the $n_{\text{MSP}}$ individuals in the
``minority, stereotype prime'' group.  Thus, \eqref{eq:exh0} states 
that these four group-specific model parameters are invariant with
respect to GPA.

We can construct a similar hypothesis involving only the intercept
parameter
\begin{equation}
    \label{eq:exh0.2}
H_0:\ \nu_{i}\ = \nu_{0},\ i=1,\ldots,n_{\text{MSP}},
\end{equation}
which, e.g., may be used to isolate the impact of stereotype threat.
We consider tests of both \eqref{eq:exh0} and \eqref{eq:exh0.2}
below.


\subsection{Results}
<<mz_mod>>=
load("wicherts05_study1.rda")

d <- subset(d, !is.na(gpa))

## fit model 5b
wdh5b <- lavaan(
   'ability   =~ label(c(rep("load_n", 3), "load_n:min_t")) * numerical + label(rep("load_v", 4)) * verbal + 1 * abstract
    ability   ~  label(c(NA, "lmean:min_c", "lmean:maj_t", "lmean:min_t")) * 1 + c(0, NA, NA, NA) * 1
    ability   ~~ label(c("lvar:maj", "lvar:min", "lvar:maj", "lvar:min")) * ability
    numerical ~  label(c(rep("mean_n", 3), "mean_n:min_t")) * 1
    abstract  ~  label(c("mean_a:maj_c", "mean_a:min_c", rep("mean_a", 2))) * 1
    verbal    ~  label(rep("mean_v", 4)) * 1
    numerical ~~ label(c(rep("var_n", 3), "var_n:min_t")) * numerical
    abstract  ~~ label(rep("var_a", 4)) * abstract
    verbal    ~~ label(rep("var_v", 4)) * verbal',
  data = d, meanstructure = TRUE, group = "group") ##, likelihood = "wishart")

## Refit model with new identification constraints
wdh5b.2 <- lavaan(
   'ability   =~ 1 * verbal + label(c(rep("load_n", 3), "load_n:min_t")) * numerical  + label(rep("load_a", 4)) * abstract
    ability   ~  label(c(NA, "lmean:min_c", "lmean:maj_t", "lmean:min_t")) * 1 + c(0, NA, NA, NA) * 1
    ability   ~~ label(c("lvar:maj", "lvar:min", "lvar:maj", "lvar:min")) * ability
    numerical ~  label(c(rep("mean_n", 3), "mean_n:min_t")) * 1
    abstract  ~  label(c("mean_a:maj_c", "mean_a:min_c", rep("mean_a", 2))) * 1
    verbal    ~  label(rep("mean_v", 4)) * 1
    numerical ~~ label(c(rep("var_n", 3), "var_n:min_t")) * numerical
    abstract  ~~ label(rep("var_a", 4)) * abstract
    verbal    ~~ label(rep("var_v", 4)) * verbal',
  data = d, meanstructure = TRUE, group = "group") #, likelihood = "wishart")
@ 

Test statistics for the hypotheses \eqref{eq:exh0}
and~\eqref{eq:exh0.2} are displayed in Figure~\ref{fig:cusumex}.
Each panel displays a test 
statistic's fluctuation across values of student GPA, with the first
column containing tests of~\eqref{eq:exh0} (testing $k^*=4$ parameters)
and the second column containing tests of~\eqref{eq:exh0.2} (testing
$k^*=1$ parameter).
The solid
horizontal 
lines represent critical values for $\alpha= 0.05$, and
the Cram\'{e}r-von Mises panels 
also contain a dashed line depicting the value of the test
statistic (test statistics for the others are simply 
the maxima of the processes).
In other words, for panels in the first and third rows, \eqref{eq:exh0} is
rejected if the process crosses the horizontal line.  For panels in
the second row, \eqref{eq:h0} is rejected if the dashed horizontal line is
higher than the solid horizontal line.

%% Details on test results
The results displayed in Figure~\ref{fig:cusumex} generally show that the
``minority, stereotype prime'' group lacks invariance with respect to
GPA.  All three tests are significant at the .05 level, both when the four
group-specific parameters are tested simultaneously (first column) and
when the intercept parameter is tested individually (second column).

We can also use the test results to estimate the threshold $\nu$,
which in this context can be used to define GPA-based subgroups whose
measurement parameters differ.  As described previously, estimates of
$\nu$ can be obtained by 
examining the peaks in Figure~\ref{fig:cusumex}.  For the $k^*=4$
panels (first column), two peaks occur near GPAs of 5.9 and of 6.3 (6
corresponds to the American `C' range).  These peaks roughly divide
individuals into those receiving D's and F's, those receiving solid
C's, and those receiving high C's, B's, and A's.  Parameter-specific
results can also be obtained, as shown for the intercept parameter in
the second column of Figure~\ref{fig:cusumex}.  The peak locations are
generally similar to those of all four parameters, though this finding
will not hold in general.


\begin{figure}
\caption{Three test statistics of~\eqref{eq:exh0} (set of
  group-specific parameters)
  and~\eqref{eq:exh0.2} (intercept only) across values of student GPA, 
  using data from Study 1 of Wicherts et al.\ (2005).
  Solid, horizontal lines represent critical values
  at $\alpha = 0.05$, and the dotted, horizontal lines (second row)
  represent values of the Cram\'{e}r-von Mises test statistic.}
\label{fig:cusumex}
\setkeys{Gin}{width=\textwidth}
<<gefp-4-1, fig=TRUE, height=8, width=6>>=
## add a small amount of random noise to duplicated GPAs, so that everything
## works with gefp().  (Without this, one can still obtain DM and CvM test 
##                      results but not supLM results.)
set.seed(1090)
ties <- duplicated(d$gpa)
d$gpa[ties] <- runif(sum(ties), min = d$gpa[ties] - .001, max = d$gpa[ties] + .001)

## FIXME It seems like info_full should go in lavaan_S3.R.
info_full <- function(x, ...) solve(vcov(x) * nobs(x))
scores_min_t <- function(x, ...) {
  ef <- estfun(x, ...)
  ef[d$group == "exp:minority", ]
}
gpa_min_t <- subset(d, group == "exp:minority")$gpa

## empirical fluctuation processes (4 vs 1 par)
gefp_4_info <- gefp(wdh5b, fit = NULL, scores = scores_min_t, order.by = gpa_min_t, vcov = info_full, sandwich = FALSE, parm = 15:18)
gefp_1_info <- gefp(wdh5b, fit = NULL, scores = scores_min_t, order.by = gpa_min_t, vcov = info_full, sandwich = FALSE, parm = 18)

# processes for second identification constraints
gefp_4_info_1 <- gefp(wdh5b.2, fit = NULL, scores = scores_min_t, order.by = gpa_min_t, vcov = info_full, sandwich = FALSE, parm = 15:18)
gefp_1_info_1 <- gefp(wdh5b.2, fit = NULL, scores = scores_min_t, order.by = gpa_min_t, vcov = info_full, sandwich = FALSE, parm = 18)

## visualization
par(mfcol = c(3, 2))
plot(gefp_4_info,  functional = maxBB, main = "DM, k* = 4", xlab = "GPA")
plot(gefp_4_info,  functional = meanL2BB, main = "CvM, k* = 4", xlab = "GPA")
plot(gefp_4_info,  functional = supLM(0.1), main = "max LM, k* = 4", xlab = "GPA")
plot(gefp_1_info, functional = maxBB, main = "DM, k* = 1", xlab = "GPA")
plot(gefp_1_info, functional = meanL2BB, main = "CvM, k* = 1", xlab = "GPA")
plot(gefp_1_info, functional = supLM(0.1), main = "max LM, k* = 1", xlab = "GPA")
@
\end{figure}

\subsection{Discussion}
Application of the proposed measurement invariance tests to the
\citeA{WicDol05} data allowed us to study the extent to which model
parameters are invariant wrt GPA in a straightforward manner.
The tests focused on a set of group-specific
parameters within a four-group confirmatory factor model, and they
could be carried out using the results from a single estimated model.
The latter fact is important, as other approaches to the problem
described here may require multiple models to
be estimated (e.g., for LRTs) or adversely impact model fit and
degrees of freedom (e.g., if GPA is inserted directly into the model).
Further, through examination of both 
test statistics and cumulative score processes, the tests were
interpretable from both a theoretical and applied standpoint.  In the
next section, we study the proposed tests' power via simulation.


\begin{figure}
\caption{Path diagram representing the base factor analysis model used for
  the example and simulations.  To induce measurement invariance
  violations, a seventh observed variable (student age) determines the
values of the verbal factor loadings ($\lambda_{11}$, $\lambda_{21}$,
$\lambda_{31}$).}
\label{fig:famod}
\includegraphics[height=5in]{famod.pdf}
\end{figure}

\section{Simulation}

In this section, we conduct a simulation designed to
examine the tests' power and Type I error rates in situations where
measurement invariance violations are known to exist.  Specifically,
we generated data from the factor analysis model displayed in
Figure~\ref{fig:famod}, with measurement invariance violations in the
``verbal'' factor loadings with respect to a continuous auxliary variable.
For simplicity, we
assume other model parameters are invariant.  We also employ a
single-group model, reflecting situations where there exist only continuous
$V$ (so that no groups can be predefined).

We examine the power and error rates of the three
tests used in the Example section: the double-max test, the
Cram\'{e}r-von Mises test, and the $\max \mathit{LM}$ test.  We also compare 
tests involving only the $k^* = 3$ factor loadings lacking invariance
 with tests of all
$k^* = k = 19$ model parameters.  It is likely that power
is higher when testing only the affected model parameters, but
the affected parameters are usually unknown in practice.
Finally, we also examine the tests' power across
various magnitudes of measurement invariance violations.

\subsection{Method}
Data were generated using the model in Figure~\ref{fig:famod}, with
$V$ being designed to reflect student ages.
For the measurement invariance violation, ``young'' students (13--15)
had smaller factor loadings 
than ``old'' students (16--18).
Sample size and magnitude
of measurement 
invariance violation were manipulated to examine power:
we examined power to detect 
invariance violations across four sample sizes ($n=50, 100,
200, 500$) and 17~magnitudes of violations.  These violations
involved the younger students' values of $\{\lambda_{11},
\lambda_{21}, \lambda_{31}\}$ deviating from the older students'
values by $d$ 
times the parameters' asymptotic standard errors (scaled by $\sqrt{n}$),
with $d = 0, 0.25, 0.5, \dots, 4$.  The 0-standard error condition was
used to study Type I error rate.

For each combination of sample size ($n$) $\times$
violation magnitude ($d$) $\times$ number of parameters being tested
($k^{\ast}$),
5,000 datasets were generated and tested.  In each dataset, half the
individuals had ``low $V$'' (e.g., 13--15 
years of age) and half had ``high $V$'' (e.g., 16--18 years of age).

Using results discussed previously in the ``Local Alternatives''
section, we can derive the expected behavior of the univariate 
Brownian bridges for the parameters $\{\lambda_{11},
\lambda_{21}, \lambda_{31}\}$.  For these parameters, 
we use a simple step function $g(t) = \text{I}(t > 0.5)$ multiplied
by the violation magnitude.  Thus, $G(t) = 
\text{I}(t > 0.5) \times (t - 0.5)$ and $G^0(t) = \{\text{I}(t > 0.5) - 0.5 \} \times t - \text{I}(t > 0.5) \times 0.5$,
both again multiplied by the violation magnitude. Thus, the mean under the
alternative is driven by a function that is triangle-shaped, with a peak at the
changepoint $t = 0.5$ for the parameters affected by the change (and
equal to zero for all remaining parameters). 


<<mz_sim>>=
if(file.exists("mz_sim.rda")) {
  load("mz_sim.rda")
} else {
  ## seed for replication
  RNGkind(kind = "default", normal.kind = "default")
  set.seed(1090)
  ## run simulation
  mz_sim <- simulation()
  save(mz_sim, file = "mz_sim.rda")
}

## select only subset
mz_sim_sub <- subset(mz_sim, pars %in% c(3, 19))
mz_sim_sub$pars <- factor(mz_sim_sub$pars)
## labeling
levels(mz_sim_sub$pars) <- paste("k* =", levels(mz_sim_sub$pars))
levels(mz_sim_sub$nobs) <- paste("n =", levels(mz_sim_sub$nobs))
@


\subsection{Results}
Full simulation results are presented in Figure~\ref{fig:simres}, and
the underlying numeric values for a subset of the results is additionally displayed in
Table~\ref{tab:simres}.  In describing the results, we largely refer
to the figure.

Figure~\ref{fig:simres} displays power curves as a function of violation
magnitude, with panels for each combination of sample size ($n$) $\times$
number of parameters being tested ($k^{\ast}$).  
Separate curves are drawn for the double-max test (solid lines), 
the Cram{\'e}r-von Mises test (dashed lines), and the $\max \mathit{LM}$ (dotted lines).
One can generally observe that simultaneous tests of all 19~parameters
result in decreased power, with the tests performing more similarly at
the larger sample sizes.  The tests distinguish themselves from one
another when only the three factor loadings are tested, with the
Cram\'{e}r-von Mises test having the most power, followed by $\max \mathit{LM}$,
followed by the double-max test.  
This advantage decreases at larger sample sizes.  
At $n=50$, generally regarded as a
small sample size for factor analysis, the power functions break down
and are not monotonic with respect to violation magnitude.

Table~\ref{tab:simres} presents a subset of the results displayed in 
Figure~\ref{fig:simres}, but it is easier to see exact power
magnitudes in the table.
The table shows that the
power advantage of the Cram\'{e}r-von
Mises test can be as large as 0.1, most notably when three parameters
are being tested.
  It also shows that the Cram\'{e}r-von Mises test generally
has true Type-I error rates, with the double-max test being somewhat
conservative and the $\max \mathit{LM}$ test being slightly liberal.

In summary, we found that the proposed tests have adequate power to detect
measurement invariance violations in applied contexts.  The 
Cram\'{e}r-von Mises statistic exhibited the best performance for the
data generated here, though more simulations are warranted to examine
the generality of this finding in other models or other parameter constellations.
In the discussion, we describe extensions of the tests in factor
analysis and beyond.

\begin{figure}
\caption{Simulated power curves for the double-max test (solid), 
  Cram\'{e}r-von Mises test (dashed), and $\max \mathit{LM}$ test (dotted)
  across four sample sizes $n$, two subsets of tested parameters $k^*$, and
  measurement invariance violations of 0--4 standard errors (scaled by $\sqrt{n}$). 
  See Table~\ref{tab:simres} for the underlying numeric values (using a
  subset of nine violation magnitudes).}
\label{fig:simres}
\setkeys{Gin}{width=\textwidth}
<<mzsim-xyplot, fig=TRUE, height=7.5, width=7>>=
## visualization
trellis.par.set(theme = canonical.theme(color = FALSE))
mykey <- simpleKey(c("CvM", "max LM", "DM"), points = FALSE, lines = TRUE)
mykey$lines$lty <- c(2, 3, 1)
mykey$lines$lwd <- c(1.2, 2, 1.2)
print(xyplot(power ~ diff | pars + nobs, group = ~ test, data = mz_sim_sub,
  type = "l", lwd = c(1, 1, 2), ylim = c(0, 1), key = mykey,
  xlab = "Violation Magnitude", ylab = "Power"))
@
\end{figure}


\begin{table*}
\caption{Simulated power for three test statistics
  across four sample sizes $n$, nine magnitudes of measurement
  invariance violations, and two subsets of tested
  parameters $k^*$. 
  See Figure~\ref{fig:simres} for a visualization (using all 17~violation magnitudes).}
\label{tab:simres}
\begin{center}
\begin{tabular}{lrlrrrrrrrrr}
  \hline
   & & & \multicolumn{9}{l}{Violation Magnitude (SE)} \\
<<mz_sim-table, results=tex>>=
## labeling
levels(mz_sim_sub$pars) <- gsub("k* = ", "", levels(mz_sim_sub$pars), fixed = TRUE)
levels(mz_sim_sub$nobs) <- gsub( "n = ", "", levels(mz_sim_sub$nobs), fixed = TRUE)
levels(mz_sim_sub$test) <- c("$\\mathit{DM}$", "$\\mathit{CvM}$", "$\\max \\mathit{LM}$")

## table
mz_tab <- round(ftable(100 * xtabs(power ~ nobs + pars + test + diff,
  data = mz_sim_sub, subset = diff %in% c(seq(0, 4, by = 0.5))),
  col.vars = "diff"), digits = 1)
mz_tab <- format(mz_tab, quote = FALSE)[-2, -4]
mz_tab[1,] <- c("$n$", "$k^*$", "Statistic", format(seq(0, 4, by = 0.5)))
mz_tab <- paste(apply(mz_tab, 1, paste, collapse = " & "), "\\\\")
mz_tab[c(1, length(mz_tab))] <- paste(mz_tab[c(1, length(mz_tab))], "\\hline")
mz_tab <- c(mz_tab,"\\multicolumn{2}{l}{{\\scriptsize{Abbreviations:}}} &
\\multicolumn{10}{l}{{\\scriptsize{CvM = Cram\\'{e}r-von Mises 
  test; $\\max \\mathit{LM}$ = Maximum Lagrange multiplier test;}}} \\\\")
mz_tab <- c(mz_tab," & & \\multicolumn{10}{l}{{\\scriptsize{DM = Double-max test.}}}")
writeLines(mz_tab)
@

\end{tabular}
\end{center}
\end{table*}


\section{Discussion}
In this paper, we have presented a new family of statistical tests for
the study of measurement invariance in psychometrics.  The tests,
based on stochastic processes, have reasonable power, can isolate
subgroups of individuals violating measurement invariance based on a
continuous auxiliary variable, and can
isolate specific model parameters affected by the violation.  In this
section, we consider the tests' use in practice and their 
extension to more complex scenarios.

<<constraint_study>>=
tests <- c("maxBB", "meanL2BB", "supLM(0.1)")

p.diffs <- matrix(NA, 2*length(tests), 2)

for (i in 1:length(tests)){
  p.diffs[i,1] <- unlist(sctest(gefp_4_info, functional=
                                eval(parse(text=tests[i])))[2])
  p.diffs[i,2] <- unlist(sctest(gefp_4_info_1, functional=
                                     eval(parse(text=tests[i])))[2])
  }
for (i in (length(tests)+1):(2*length(tests))){
  p.diffs[i,1] <- unlist(sctest(gefp_1_info, functional=
                                     eval(parse(text=tests[i-length(tests)])))[2])
  p.diffs[i,2] <- unlist(sctest(gefp_1_info_1, functional=
                                   eval(parse(text=tests[i-length(tests)])))[2])
}
@ 

\subsection{Use in Practice}
The proposed tests give researchers a new set of tools for studying 
measurement invariance, allowing them the 
flexibility to: (1)~simultaneously test all model parameters across
all individuals, yielding
results relevant to many types of measurement
invariance (see, e.g., \citeNP{Mer93}), (2)~test a subset of
model parameters, either across all individuals or within a
multiple-group model, and (3)~use the tests as a type of modification
index following significant LR~tests.
Traditional steps to studying measurement invariance have involved
sequential LR~tests for various types of invariance using
multiple-group models.  As shown in the Example section, it can be
beneficial to employ the traditional steps in tandem with the proposed
tests.  Further, when groups are not defined in advance (e.g.,
continuous $V$), the traditional steps fail unless further assumptions
about the nature of the groups are made.

Another difference between the proposed tests and traditional tests
involves the fact that, for the proposed tests, one's choice of
identification constraints can influence tests of the remaining
parameters.  This essentially reflects the fact that, while the model
fits equally well regardless of identification constraint, the
free model parameters adjust themselves to the specific identification
constraint chosen.  To examine this issue in more detail, we refit the model
used in the Example section, using an alternative identification
constraint (i.e., fixing a different factor loading at 1).  Across the 6
tests presented in the example section (see, e.g.,
Figure~\ref{fig:cusumex}), the largest difference in p-values for the
two identification constraints 
was~$\Sexpr{round(max(abs(p.diffs[,2] - p.diffs[,1])),3)}$.  This is not a large difference, though further
study is warranted. 

In addition to providing general information about whether or not
measurement 
invariance holds, the proposed tests allow researchers to interpret
the nature of the invariance violation.  This is made possible, e.g.,
through the tests' abilities to estimate $\nu$, the threshold dividing
individuals into subgroups that violate
measurement invariance (see Equation~\eqref{eq:h1*}).  It is also
possible to define formal rules for estimating multiple $\nu$
parameters (see \citeNP{ZeiSha10}).



\subsection{Comparison to Other Methods}
The step
functions from~\eqref{eq:h1*} were employed in the current paper to
highlight connections with nested model
comparison, but the proposed tests typically have non-trivial power for
all (non-constant) deviation patterns $\theta(v_i)$ (considered in
Equation~\eqref{eq:h1}). Thus, the tests will also have power for linear
deviations from parameter constancy, although other techniques may 
perform better in this particular case.  Examples include the 
class of moderated factor models \cite{BauHus09,MolDol10,Pur02}, 
whereby continuous moderators are allowed to linearly impact model
parameters (Purcell also considers quadratic effects of the
moderators).   
Returning to deviations in parameter constancy, if the change in
parameters is continuous but not exactly linear - e.g., a sigmoidal
shift from one set of parameters to another one - then the simple
single shift model in~\eqref{eq:h1*} may be a useful first
approximation and have better power than linear
techniques. 

% paragraph on factor mixture models
The proposed tests are also similar to factor mixture models (e.g.,
\citeNP{DolMaa98,LubMut05}) in that they can handle unknown subgroups
violating measurement invariance.  Covariates can also be used to
predict the unknown subgroups under both approaches.
For example, for the 
data used in our simulations, one could employ a factor mixture
model with two latent classes.  This would typically involve the
specification that student age has a linear effect on logit(P(Class
2)), which highlights the main difference between the two techniques:
the factor mixture model requires a specific assumption about the type
of deviation from parameter constancy, while the proposed tests do
not.

More generally, all the approaches described above can be distinguished
from the proposed tests in that they require estimation of a new model
of increased complexity (due to the moderator/covariate).
The proposed tests, on the other hand, are of the
``posthoc'' variety, relying only on results calculated during the
original model estimation.  While no method clearly dominates 
across all situations, use of the proposed tests can at least reduce 
some of the technical issues associated with estimating and
interpreting models of greater complexity.  This alone is not a
good reason to use the tests, but it is a consideration that is often
meaningful in practice.


\subsection{Categorical Auxiliary Variable}
One issue that was largely unaddressed in this paper involved the use
of categorical $V$ to study measurement invariance.  In this case,
groups are 
already specified in advance, and so traditional methods for fixed
subgroups (i.e., LR, Wald, and LM tests) may suffice.
Furthermore, we can also obtain an LM-type statistic from the
framework developed here. Assume the observations are divided into
$C$ categories $I_1, I_2, \ldots, I_C$. Then, the increment of
the cumulative score process $\Delta_{I_c} {\bm B}(\hat {\bm \theta})$
within each category is just the sum of the corresponding scores.
In somewhat sloppy notation:
\begin{equation}
    \label{eq:catsum}
    \Delta_{I_c} {\bm B}(\hat {\bm \theta}) ~=~ \hat {\bm I}^{-1/2} n^{-1/2}
    \sum_{i \in I_c} {\bm s}(\hat {\bm \theta}; x_i)
%% \\
%%    X^2 & = & \sum_{c = 1}^C n_c^{-1} n^{-1} || \Delta_{I_c} {\bm B}(\hat {\bm \theta}) ||^2
\end{equation}
This results in a $C \times k$ matrix, with one entry for
each category-by-model parameter combination.  We can test
a specific model parameter for invariance by focusing on the associated
column of the $C \times k$ matrix and employing a weighted squared sum of
the entries in the column to obtain a $\chi^2$-distributed statistic with
$(C-1)$ degrees of freedom \cite{HjoKon02}.
Alternatively, to simultaneously test multiple parameters, we can sum
the $\chi^2$ statistics and degrees of freedom for the individual
parameters.  In addition to categorical $V$, this framework may also
be useful for both continuous $V$ with many ties and ordinal $V$.  
The number of potential thresholds may be very low in these
situations, which impacts the extent to which asymptotic results hold
for the main test statistics described in this paper.

\subsection{Extensions}
The proposed family of tests can be extended in various ways.  First,
it is possible to construct an algorithm that recursively defines
groups of individuals violating measurement invariance with respect to
multiple auxiliary variables.  Such an algorithm is related to 
classification and regression trees \cite{BreFri84,MerSha10,StrMal09},
with related algorithms being developed for general parametric models
\cite{ZeiHot08} and Rasch models in particular \cite{KopZei10}.  

Relatedly, \citeA{San09} describes a general
method for partitioning/segmenting structural equation models within a 
partial least squares framework.  This method involves direct maximization of
the likelihood ratio (i.e., fitting the model for various subgroups
defined by 
$V$ and choosing the subgroups with the largest likelihood ratio).
Thus, unlike the tests described in this paper, this approach does not
provide a formal significance test with a controlled level of Type~I errors.


The proposed tests also 
readily extend to other popular psychometric models.  
For example, the tests can be used to generally 
study the stability of structural equation model parameters across
observations.  Under this framework, it is possible to assess whether
paths between 
latent variables are stronger for some individuals than for
others.  Further, in applying the proposed tests to factor mean
parameters (as was done in the example), implications of measurement
invariance violations for structural equation modeling may be better
understood.

The proposed tests also naturally extend to the study of differential
item functioning (DIF) 
in item response models (e.g., \citeNP{KopZei10}, who focused on Rasch
models).   
Traditional DIF methods are similar to those for factor analysis in
that subgroups must be specified in advance.
%% The tests proposed here can detect subgroups automatically, however, offering a unified way of
%% studying both  measurement invariance in factor analysis and differential item
%% functioning in item response.
While factor-analytic measurement invariance methods and DIF methods
have developed 
largely independently of one another, the methods can certainly be
treated from a unified perspective (e.g.,
\citeNP{Mcd99,Mil11,StaChe06}).   
The tests proposed here were designed with this perspective in mind.


\subsection{Summary}
We have outlined a family of 
stochastic process-based parameter instability tests from theoretical
statistics and applied them to the issue of measurement invariance in psychometrics.
The paper included theoretical development, an applied example, and 
study of the tests' performance.  The tests were found to have good
properties via simulation, making them useful for many psychometric
applications.  More generally, the tests help 
solve standing problems in
measurement invariance research and provide many avenues for
future research.  This can happen both through extensions of the tests
within a factor-analytic context and through application of the tests to new
models.

\section*{Computational Details}

All results were obtained using the {R}~system for statistical computing \cite{R11},
version~\Sexpr{paste(R.Version()[6:7], collapse = ".")}, employing the add-on packages
{lavaan}~\Sexpr{packageDescription("lavaan")["Version"]} \cite{lavaan11} and
{OpenMx}~\Sexpr{packageDescription("OpenMx")["Version"]} \cite{BokNea11} for fitting of the factor analysis models and
{strucchange}~\Sexpr{packageDescription("strucchange")["Version"]} \cite{ZeiLei02,Zei06}
for evaluating the parameter instability tests. {R}~and the packages {lavaan} and {strucchange} are
freely available under the General Public License~2 from the
Comprehensive {R} Archive Network at \url{http://CRAN.R-project.org/}
while {OpenMx} is available under the
Apache License~2.0 from \url{http://OpenMx.psyc.virginia.edu/}.
{R}~code for replication of our results is
available at \url{http://semtools.R-Forge.R-project.org/}.

\bibliography{refs}

\end{document}
