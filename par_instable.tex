\documentclass[man]{apa}
\usepackage{graphicx,epsfig,amsmath,alltt,setspace,bm}
\title{Studying measurement invariance in factor analysis models
  via stochastic processes}
\twoauthors{Edgar C. Merkle}{Achim Zeileis}
\twoaffiliations{Wichita State University}{Universit\"{a}t Innsbruck}

\abstract{Common methods for the study of measurement invariance in a
  factor-analytic context include
  likelihood ratio tests, Lagrange multiplier tests, and
  Wald tests. 
  These methods require advance definition of the number of groups, group
  membership, and offending model parameters.
In this paper, we construct tests of parameter
invariance based on stochastic processes of casewise
derivatives of the likelihood function.  These tests can be viewed as
generalizations of the Lagrange multiplier test, and they are especially
useful for: (1) isolating specific parameters affected by measurement
invariance violations, and (2) identifying subgroups of individuals
that violated measurement invariance based on a continuous auxiliary
variable.  The tests are presented and illustrated in detail, along
with simulations examining the tests' abilities in controlled conditions.}

\acknowledgements{Correspondence to Edgar C.\
  Merkle, Department of 
  Psychology, Wichita State University, Wichita, KS 67260-0034.
  Email: {\texttt{edgar.merkle@wichita.edu}}.}
\shorttitle{Parameter instability tests}
\rightheader{Parameter instability tests}

\begin{document}
\maketitle

The assumption that parameters are
invariant across observations is a
fundamental tenet of many statistical models.  A specific type of 
parameter invariance, measurement invariance, has implications for the
general design and use of psychometric scales.
A set of scales are defined to be measurement invariant with respect to
an auxiliary variable $V$ if:
\begin{equation}
    \label{eq:midef}
      f({\bf X} | T, V) = f({\bf X} | T),
\end{equation}
where ${\bf X}$ is a matrix of scale scores, $T$ is the latent
variable that the scales purport to measure, and $f$ is some assumed
distributional form.  This concept is 
particularly important because violations can render the scales
useless.  
That is, if a set of scales violates the condition described by
Equation~\eqref{eq:midef}, then individuals with the same
score on $T$ can systematically receive 
different scale scores.
This may lead researchers to conclude subgroup
differences on a wide variety of interesting constructs 
when, in reality, the scales are the sole cause of the 
differences.  Further, it can be inappropriate to incorporate scales
violating measurement invariance into structural equation
models, where relationships between constructs are hypothesized.  Horn
and McArdle \citeyear{HorMca92} concisely summarize the impact of
these issues, stating ``Lack of evidence of measurement 
invariance equivocates conclusions and casts doubt on theory in the
behavioral sciences'' (p.\ 141).  Borsboom \citeyear{Bor06a} also
notes that researchers often fail to assess whether measurement
invariance holds.

Focusing on applications, measurement
invariance is commonly assessed with respect to categorical variables
such as ethnicity. 
These assessments are often carried out using nested Multiple Groups
Models (e.g., \citeNP{Jor71,Bol89}) along with Likelihood Ratio tests,
though 
Lagrange Multiplier and Wald tests may also be constructed for this
purpose.
Scales may also violate measurement invariance with
respect to a continuous variable such as income.  In this situation,
there are no groups, but the condition in Equation~\eqref{eq:midef}
may still be violated.  The situation involving continuous auxiliary
variables is directly addressed by the tests proposed in this paper.
The tests proposed in this paper also have the ability to isolate
specific model parameters that violate measurement invariance.
Focusing on this point, Millsap's \citeyear{Mil05} review of 
measurement invariance methods cites ``locating the violation of the
invariance'' as one of the major outstanding problems.  The tests
resulting from the proposed project directly address this issue,
leading to an important advance in measurement invariance research.

In the following pages, we first provide a brief review of Likelihood
Ratio Tests, Lagrange Multiplier Tests, and Wald Tests.  We then
proposed tests that generalize the Lagrange Multiplier
tests, providing background and relevant theoretical results.  Next,
we study the 
proposed tests' abilities through example and simulation.  Finally,
we discuss some interesting extensions of the tests.
Throughout the manuscript, we use the term {\em{test}} to refer to a
statistical test and the term {\em{scale}} to refer to a psychometric 
test or scale.

\section{Existing Tests of Measurement Invariance}

Measurement invariance is often studied in a factor-analytic context.
For a $p \times 1$ vector of scales  
${\bm x}$ and $m$ factors, the model is
specified as:
% Define data model via equation
\begin{equation}
    \label{eq:famod}
    {\bm x}_i = {\bm \mu} + {\bm \lambda}{\bm z}_i + {\bm e}_i,\ \ \ i=1,\ldots,n,
\end{equation}
where ${\bm \mu}$ is a $p \times 1$ vector of scale means, ${\bm
  \lambda}$ is a $p \times m$ matrix of factor loadings, ${\bm z}_i$ is
an $m \times 1$ vector of factor scores for individual $i$, and ${\bm
  e}_i$ is a $p \times 1$ vector of error terms for individual $i$.
The model states that each scale is a
linear combination of the latent factor(s) and error.  
Multivariate normality of the ${\bm z}_i$ and of the ${\bm e}_i$ are
traditionally assumed (e.g., \citeNP{LawMax71}), leading to a model
that is often estimated via Maximum Likelihood methods.  We restrict
ourselves to Maximum Likelihood estimation in this manuscript, leaving
us with at least three statistical approaches to assessing measurement
invariance: the Likelihood Ratio Test, the
Lagrange Multiplier Test, and the Wald Test.  While these three tests
are asymptotically equivalent \cite{Sat89}, each is detailed
individually below.

\subsection{Likelihood Ratio Test}

Measurement invariance is achieved
if sets of factor analysis model parameters are equal across
subgroups of individuals 
(\citeNP{Mer93}; there are many types of measurement invariance based
on different sets of model parameters being held constant, but any of these
can be examined via the proposed tests).  If measurement invariance is
not achieved, 
then the parameters assume different values for different
subgroups.  This leads to statistical tests of measurement
invariance via the comparison of two models: a restricted model where
parameters are equal across subgroups, and a ``full'' model
where parameters are allowed to assume different values for each
subgroup.  Statistically, this comparison is often 
accomplished by a likelihood ratio test (also called a
difference test).  Let the full model parameters be denoted 
${\bm \theta} = ({\bm \theta}_1^{\prime}\ {\bm
  \theta}_2^{\prime})^{\prime}$, where we can obtain the restricted model
by placing a set of equality constraints on ${\bm \theta}_1$ described
by the vector-valued function ${\bm
  h}({\bm \theta}_1) = {\bm 0}$.  A $\chi^2$ statistic testing
measurement invariance may then be calculated via:
\begin{equation}
    \label{eq:chisq}
 \chi^2 = -2(n-1)(\log L({\bm X},
\widehat{{\bm \theta}}_c) - \log L({\bm X},\widehat{{\bm \theta}})),
\end{equation}
where ${\bm{X}}$ is an $n \times p$ data matrix, $\widehat{\bm \theta}_c$
contains Maximum Likelihood parameter estimates satisfying the
constraints ${\bm h}({\bm \theta}_1) = {\bm 0}$, and $\widehat{\bm
  \theta}$ contains Maximum Likelihood parameter estimates from the
full model.  The log-likelihood function in the above equation arises
from the multivariate normal distribution and is defined as:
\begin{equation}
    \label{eq:loglik}
    \log L( \bm{X}, \bm{\theta}) = -\frac{n}{2} \left \{ p
          \log(2\pi) + \log | {\bm{\Sigma}}({\bm{\theta}}) | +
          \text{tr}[{\bm{\Sigma}}^{-1}({\bm{\theta}})({\bm{S}} +
          ({\overline{{\bm{X}}} -
            {\bm{\mu}}({\bm{\theta}})})({\overline{{\bm{X}}} -
            {\bm{\mu}}({\bm{\theta}})})^{\prime})]\right \},
\end{equation}
where $\overline{{\bm{X}}}$ is the observed mean vector, ${\bm S}$ is
the observed covariance matrix, ${\bm{\mu}}({\bm{\theta}})$ is the
model-implied mean vector, and ${\bm{\Sigma}}({\bm{\theta}})$ is the
model-implied covariance matrix.  The test resulting from
Equation~\eqref{eq:chisq} has 
degrees of freedom equal to the difference in number of free
parameters for the two models, and it rejects the hypothesis of measurement
invariance for large values of $\chi^2$.

While the Likelihood Ratio Test is most popular for testing
measurement invariance, Lagrange Multiplier tests and Wald tests
may also be constructed for the same purpose.The Lagrange Multiplier and Wald 
tests, described below, are also advantageous in that they require
estimation of only one 
model (either the full or restricted model), whereas the Likelihood
Ratio Test requires estimation of both models.

\subsection{Lagrange Multiplier Test}
The Lagrange Multiplier test (e.g., \citeNP{Sil59,ChouBent90})
focuses on a restricted model and tests whether the equality
constraints described by ${\bm h}({\bm \theta}_1) = {\bm 0}$ should be
freed.
Estimating the restricted model, we define a vector of Lagrange
multipliers $\widehat{\bm \lambda}$ that satisfy:
\begin{equation}
    \label{eq:lagrange}
    \frac{\partial \log L}{\partial {\bm \theta}} \bigg |_{\widehat{\theta}_c} +
    \frac{\partial {\bm h}}{\partial {\bm \theta}}
    \bigg |_{\widehat{\theta}_c}^{\prime} \widehat{{\bm \lambda}} = {\bm 0}.
\end{equation}
The test itself is then based on the asymptotic distribution of 
$\widehat{{\bm \lambda}}$: if $\widehat{{\bm \lambda}}$ is sufficiently close
to ${\bm 0}$, then the constraints are deemed to hold in the
population.  The resulting test statistic, which is a function of
$\widehat{\bm \lambda}$, follows a $\chi^2$ distribution for large
samples.

\subsection{Wald Test}
In contrast to the Lagrange Multiplier test, the
Wald test (e.g., \citeNP{Wald43})
focuses on the full model and tests the plausibility of the
constraints ${\bm h}({\bm \theta}_1) = {\bm 0}$.
The test is based on the estimates ${\bm h}(\widehat{{\bm \theta}}_1)$
from the full model; if
these are sufficiently close to zero, then the constraints are deemed
to hold in the population.  The resulting test statistic, which is a
function of ${\bm h}(\widehat{{\bm \theta}}_1)$, is also
$\chi^2$-distributed in large 
samples.
Chou and Bentler \citeyear{ChouBent90} compared the 
Wald and Lagrange tests with finite sample sizes via
simulation, and they generally found similar
performance.  They noted, 
however, that the Lagrange test has a tendency toward Type I errors in
some contexts.  They therefore urged caution in the Lagrange test's
use, as it may lead one to discard more constraints than is necessary,
leading to overly-complex models.

\subsection{Relationships to Proposed Tests}
All the tests described above require advance specification of
subgroups that potentially violate measurement invariance.  This is a
major limitation in psychometrics, where researchers
ultimately want to ensure that tests are invariant with respect to all
possible subgroups of students.  For example, there are many possible
ways to define subgroups based on a continuous auxiliary variable like
income.  Assuming two subgroups, we
could define an arbitrary cutoff separating the
poorer individuals from the richer individuals.  Alternatively, we could
consider larger numbers of subgroups with similarly-arbitrary cutoffs
defining the groups.  The ultimate subgroup definitions that we
choose could potentially impact our
conclusions about whether or not a scale is measurement invariant, 
in the same way that dichotomization of continuous variables impacts
general statistical analyses \cite{MacZha02}.
Heuristically, we would like to conduct a separate Lagrange (or
Likelihood Ratio or Wald) test for each possible definition of
subgroups, then declare the scales to be measurement invariant if they
``pass'' all of these tests.  Given the large number of possible
subgroups, however, this would generally result in problems with Type
I errors.\footnote{An alternative to this procedure involves inserting the
continuous income variable directly into the factor analysis model,
which we do not pursue due 
to the potential impact on model fit and on other parameter estimates.}

  % Instead of this, can employ parameter instability tests from
  % theoretical statistics to simultaneously examine all possible
  % groupings.
Instead of testing measurement invariance separately for each possible 
subgroup definition, we can use a single test from the family of tests
proposed here.
The proposed tests can be viewed as generalizations of the
Lagrange test \cite{And93}, 
as they focus on a restricted model and 
simultaneously test for measurement invariance across all
possible subgroup definitions.  This removes the problems associated
with error rates and generally promotes a more flexible framework
for studying measurement invariance.  As previously stated, the proposed
tests also have the ability to isolate specific model parameters violating
measurement invariance.

\section{Stochastic Processes for Measurement Invariance}
The proposed tests of measurement invariance implicitly rely on an
estimated factor analysis model (one that restricts parameters to be
invariant across subgroups).
The traditional factor analysis likelihood function 
(Equation~\eqref{eq:loglik}) 
utilizes the observed covariance matrix
${\bm{S}}$ and observed mean vector $\overline{\bm{X}}$
instead of individuals' data, but the proposed tests
require the likelihood to be evaluated for each individual.  Thus, 
we utilize the equivalent casewise likelihood:
\begin{equation}
    \label{eq:caselik}
    \log \text{L}^{\ast}({\bm{X}}, {\bm{\theta}}) = \sum_{i=1}^{N} \log \mid 
\bm{\Sigma}(\bm{\theta}) \mid + \sum_{i=1}^{N} (\bm{x}_i -
\bm{\mu}(\bm{\theta}))^{\prime} \bm{\Sigma}(\bm{\theta})^{-1} (\bm{x}_i -
\bm{\mu}(\bm{\theta})).
\end{equation}
This equation is often employed for factor analysis and structural
equation models with missing data (e.g., \citeNP{Wot00}), 
in which case we would take subsets of
$\bm{\Sigma}(\bm{\theta})$ and $\bm{\mu}(\bm{\theta})$ corresponding
to the observed data on each individual $i$.

Maximization of Equation~\eqref{eq:caselik} typically involves iterative
algorithms that seek values $\widehat{{\bm{\theta}}}$ such that
$\frac{\partial}{\partial \theta_j} \log \text{L}^{\ast}({\bm{X}},
{\bm{\theta}}) \big |_{\theta_j = \widehat{\theta}_j} = 0\ \ \forall\ j$.
% insert derivatives of casewise evaluated at theta-hat = 0
Such derivatives are taken across individuals, but, using the casewise
likelihood described above, we can also 
evaluate the derivatives with respect to each individual.
If a unique value of $\widehat{{\bm{\theta}}}$ maximized
each individual likelihood, then we would have:
% Equation: \psi(y_i, \theta) = d/d theta casewise_i = 0 \forall i.
\begin{equation}
    \label{eq:casederiv}
    \psi({\bm{x}}_i, \theta_j) = \frac{\partial}{\partial\theta_j}
\left[ \log \mid 
\bm{\Sigma}(\bm{\theta}) \mid + (\bm{x}_i -
\bm{\mu}(\bm{\theta}))^{\text{T}} \bm{\Sigma}(\bm{\theta})^{-1} (\bm{x}_i -
\bm{\mu}(\bm{\theta}))\right] \bigg |_{\theta_j = \widehat{\theta}_j} = 0\ \ \ \forall\ i, j.
\end{equation}
In practice, no value of $\widehat{{\bm{\theta}}}$ will maximize all
individuals' likelihoods, but, if parameter invariance is satisfied, 
we can expect the $\psi(\cdot, \cdot)$ to fluctuate around zero.  This
is the idea underlying the tests described here.

\subsection{Theory}
Theoretical work in statistics (e.g., \citeNP{HjoKon02}) has shown
that functions of the 
$\psi(\cdot, \cdot)$ follow specific stochastic processes, allowing
us to use them to generally test measurement
invariance.  
That is, letting ${\bm \theta}_i$ reflect parameter values
specifically 
associated with individual $i$, measurement invariance can be 
described by the null hypothesis:
\begin{equation}
    \label{eq:h0}
    H_0: {\bm \theta}_i = {\bm \theta}_0,\ i=1,\ldots,n,
\end{equation}
where the $i$'s are typically ordered with respect to the auxiliary
variable of interest (i.e., the variable defining subgroups for tests
of measurement invariance).  For example, if parental income was the
auxiliary variable, we would order students according to parental
income and then examine whether parameters were constant across
students.  The ordering of individuals is crucial to
the test development below, but it is relaxed later in the proposal.

Despite addressing measurement
invariance, the above $H_0$ focuses no longer on subgroups of
individuals but rather on individuals themselves.  The $H_0$ is
generally applicable to situations where parameters may vary across
observations.  For example, it has most often been examined in
longitudinal models where observations are 
ordered according to time.
%In this context, {\em{change-point
%    analyses}} have received much attention from the psychometric
%community \cite{Coh08}. % CITE BOOK
Observations may also be ordered with respect to 
continuous variables other than time, a fact that allows for the
measurement invariance tests described here.  Thus, the proposed tests
stem from seminal work on
detecting turning points in longitudinal models (e.g.,
\citeNP{BroDur75,Nyb89}).

The alternative hypothesis corresponding to the above $H_0$ is that not
all the ${\bm{\theta}}_i$ are constant (i.e., measurement invariance is
violated), though specific local alternatives may also be specified to
make the tests more powerful.  We now review some of the main results
for testing $H_0$ via stochastic processes of first derivatives; more
detailed accounts include Hjort and Koning \citeyear{HjoKon02} and
Zeileis and Hornik \citeyear{ZeiHor07}.

% New subsection starts here?

For application to measurement invariance, the most important
theoretical result involves the fact that, under $H_0$, functions of
the $\psi(\cdot, \cdot)$ result in specific stochastic
processes.  One such function
is the {\em{cumulative score process}}, given as:
\begin{equation}
    \label{eq:cumscore}
    W_n(t,\theta_j) = \frac{1}{\sqrt{n}} \sum_{i=1}^{\lfloor nt
      \rfloor} \psi ({\bm{x}}_i, \theta_j),
\end{equation}
where $t$ is a continuous variable in $(1/n,1)$ and $\lfloor nt
\rfloor$ is the floor operator, defined as the integer part of
$nt$.
As the equation shows, the cumulative score process adds subsets of
casewise first derivatives across individuals who have been ordered
based on an auxiliary variable.  Starting at $t=1/n$, only the
first individual's derivative enters into the summation.  Once
$t=2/n$, the first two individuals' derivatives enter into the
summation.  This procedure continues until we reach $t=n$, at which
point all individuals' first derivatives have entered into the
summation.  There are $n$ cumulative sums obtained by sequentially
inserting individuals' derivatives into the equation, and these are
calculated 
for each of the $p$ model parameters.  This results
in $n\times p$
empirical cumulative scores.

Elements of the summation in Equation~\eqref{eq:cumscore}
can be positive or 
negative, so that the cumulative scores do not necessarily increase
with $t$.  In fact, if measurement invariance (i.e., $H_0$) holds,
then the cumulative scores should 
follow a stochastic process that fluctuates around zero.  
Zeileis and Hornik \citeyear{ZeiHor07} showed specifically that, under
$H_0$:
%which generalizes earlier results from %CITE bigger journals:
% Z+H Theorem 2/Corollary 2
\begin{equation}
    \label{eq:browbridge}
{\bm{B}}(\cdot, \widehat{{\bm{\theta}}}) = {\bm{I}}(\widehat{{\bm{\theta}}})^{-1/2}{\bm{W}}_n(\cdot,\widehat{{\bm{\theta}}})
\overset{d}{\rightarrow} {\bm W}^{0}(\cdot), % put d over rightarrow
\end{equation}
where ${\bm{I}}(\widehat{{\bm{\theta}}})$ is the observed information
matrix (e.g., of the factor analysis model), ${\bm{W}}_n(\cdot,\widehat{{\bm{\theta}}})$ reflects the $p$-dimensional
cumulative sums (one for each parameter), ${\bm W}^{0}(\cdot)$ is a
$p$-dimensional Brownian bridge, and 
$\overset{d}{\rightarrow}$ reflects convergence in distribution. %?
In words, there are $p$ cumulative score processes, one for each
model parameter.  This collection of processes follows a
multidimensional Brownian bridge as derivatives accumulate in the 
summation from individual 1 to individual $n$.
Multiplication by ${\bm{I}}(\widehat{{\bm{\theta}}})^{-1/2}$ 
``decorrelates'' the $p$
cumulative score processes, such that each univariate process (i.e., each
process for a single model parameter) is independent of all other
processes.

The cumulative scores resulting from Equation~\eqref{eq:browbridge}
can be arranged in an $n \times p$ matrix called an {\em{empirical
    cumulative score process}}, which we will denote as
${\bm{B}}^{\text{emp}}(\widehat{\bm{\theta}})$.
Each column of this matrix follows a univariate Brownian bridge and is
based on a single factor analysis parameter. 
To carry out a test of $H_0$, we need functions that collapse across
rows (individuals) and/or columns (parameters) of the matrix.  These
functions then lead to scalar test statistics and p-values.
The specific choice of function depends on the goals of the analyst:
the row-collapsing functions are useful for isolating subsets of
parameters that violate measurement invariance, and the
column-collapsing functions are useful for isolating subgroups of
individuals who violate measurement invariance across all parameters.
Some functions result in test
statistics whose critical values can be derived analytically, while
others require critical values to be derived via the
simulation of a Brownian bridge.

For example, if we wish to test a specific parameter for
measurement invariance, ``row-collapsing''
functions include the absolute maximum or mean of the corresponding 
column in ${\bm{B}}^{\text{emp}}(\widehat{\bm{\theta}})$
\cite{ZeiHor07}. % (see ZH07 p 7)
Conversely, if we wish to generally test 
measurement invariance across sets of model parameters,
``column-collapsing'' functions 
include the maximum norm or the squared Euclidean norm of the
corresponding row in ${\bm{B}}^{\text{emp}}(\widehat{\bm{\theta}})$
\cite{HjoKon02}.

A general, two-step strategy for testing measurement
invariance involves first collapsing over columns for each individual,
yielding a single statistic for each individual. 
These $n$ statistics (ordered according to an auxiliary variable)
can then be graphed to visually define groups that violate measurement
invariance.  Functions of these $n$ statistics can also yield scalar
test statistics.

As a concrete example of the above strategy, we could
first collapse over columns for each individual $i$ via the Euclidean
norm:
\begin{equation}
    \label{eq:meanl2}
    \lambda_i = \lVert {\bm B}^{\text{emp}}_{i\cdot}(\widehat{\bm \theta}) \rVert,
\end{equation}
where the $i\cdot$ subscript signifies row $i$ of the empirical
fluctuation process matrix.  A univariate test statistic may then be
obtained by taking the mean of the $\lambda_i$.  This is a
Cram\'{e}r-von Mises statistic described by, e.g., Nyblom
\citeyear{Nyb89} and Hansen \citeyear{Han92} in the contexts of
longitudinal models and linear regression.  In general contexts,
this test is recommended
when there are more than two groups exhibiting parameter instability 
and when multiple parameters change across groups \cite{ZeiSha10}.  
We demonstrate these recommendations' implications for
measurement invariance later in the paper.

% We still obtain a unidimensional process; the norm is applied
% to each row vector.
As an alternative to the two-step approach described in the previous
paragraph (collapse over columns, then take the absolute maximum), the
{\em{double-max}} statistic allows for simultaneous isolation of 
individuals violating invariance along with offending model
parameters (that are unspecified in advance).  These functions take
the maximum absolute cumulative sum across all entries:
\begin{equation}
    \label{eq:doubmax}
    DM = \max_{i=1,\ldots,n} \max_{j=1,\ldots,p} |
    B^{\text{emp}}_{ij}(\widehat{\bm{\theta}}) |,
\end{equation}
where $B^{\text{emp}}_{ij}(\widehat{\bm{\theta}})$ represents the
entry in row $i$ and column $j$ of
${\bm{B}}^{\text{emp}}(\widehat{\bm{\theta}})$.  This is different from
the two-step approach because, in the two-step approach, we collapse
over parameters (columns) first.  We then obtain a test statistic
from an $n \times 1$ vector.  In contrast, the
$DM$ statistic takes an absolute maximum with respect to the $n \times
p$ empirical cumulative score process (i.e., with respect to
cumulative sums associated with individual parameters).  This is
especially useful for visualization, as the fluctuation process for
each individual parameter can be displayed along with the appropriate
critical value.  An example of this visualization appears in the
Example section.

There exist other functions of first derivatives and of the
empirical fluctuation process that
result in other test statistics; these are described by, e.g.,
Zeileis, Shah, and Patnaik \citeyear{ZeiSha10}.  
In the analyses described later, we focus on the abilities
of the Cram\'{e}r-von Mises test and of the double-max test.  However,
the many 
row- and column-collapsing functions offer a large family of tests
that can be applied to the study of measurement invariance.

\subsection{Critical Values \& $p$-values.}
To obtain $p$-values associated with $H_0$, we can rely on analytic
work concerning functions of Gaussian processes.
As an example of this, we focus on use of the 
double-max function (Equation~\eqref{eq:doubmax}) as a test statistic.
There exist 
analytic results for Brownian bridges that allow us to calculate
% fix double-max notation on following line:
$P(DM > \beta | H_0)$, where $\beta$ is a specific value
that the test statistic may achieve.  

We first focus on a univariate
Brownian bridge, which could test a single parameter (say, $\theta_j$) for
measurement invariance using the test statistic $DM_j$.
Under $H_0$, it can be shown that (e.g., \citeNP{ShoWel86}):
 % see Beghin & Orsingher Eq (4.12).  They cite Shorack &
            % Wellner 1986 book
\begin{eqnarray}
    P(DM_j < \beta | H_0) &
    = & \sum_{h=-\infty}^{\infty} (-1)^h \exp(-2h^2\beta^2) \\
   & = & 1 + 2 \sum_{h=1}^{\infty} (-1)^h \exp(-2h^2\beta^2).
\end{eqnarray}
The associated $p$-value is therefore given by:
\begin{equation}
    \label{eq:absmax_p}
        p = P(DM_j > \beta | H_0)
    = 1 - (1 + 2 \sum_{h=1}^{\infty} (-1)^h \exp(-2h^2\beta^2)).
\end{equation}
The terms in the summation quickly go to zero as $h$ goes to infinity,
so, in practice, we only need to compute the first 100 terms (say).

For multidimensional Brownian bridges whose dimensions are independent
(i.e., those that 
have been ``decorrelated'' by the information matrix), $p$-values can
be obtained similarly.  Assuming a Brownian bridge with $p$
independent dimensions (i.e., simultaneously testing $p$ model
parameters for measurement invariance), we have:
\begin{eqnarray}
    \label{eq:multidim}
    p & = & P(DM_1 >
    \beta\ \cup\ DM_2 > \beta\ \cup\ \ldots \cup\ DM_p > \beta | H_0)
      \nonumber \\
   & = & 1 - P(DM_1 <
    \beta\ \cap\ DM_2 < \beta\ \cap\ \ldots \cap\ DM_p < \beta | H_0)
     \nonumber \\
   & = & 1 - \left ( 1 + 2 \sum_{h=1}^{\infty} (-1)^h
       \exp(-2h^2\beta^2) \right )^p.
\end{eqnarray}
These expressions are used to compute $p$-values for the double-max
test statistic, with associated critical values being
obtained, e.g., through a simple grid search using
Equation~\eqref{eq:multidim}.
For other test statistics, we can either obtain similar expressions
for $p$-values or obtain $p$-values via simulation of Brownian
bridges.

\subsection{Locating the Invariance.}
If a test described above implies a measurement invariance violation,
then the researcher may want to: (1) define subgroups of individuals that
the scales measure differently; or (2) isolated model
parameters affected by the invariance.  
In the context of a Cram\'{e}r-von Mises test, we can accomplish the
first task by graphing the $\lambda_i$ (Equation~\eqref{eq:meanl2})
and noting the location of the peaks and valleys.  We can accomplish
the second task by taking the norm in Equation~\eqref{eq:meanl2}
across specific columns of $B^{\text{emp}}(\widehat{\bm \theta})$.

In the context of a double-max test, we can accomplish the first task
by defining subgroups
based on the individual who achieves the absolute
maximum.  That is, assuming the existence of two subgroups
violating measurement invariance, the absolute maximum cumulative
score should be achieved close to 
the ``cut point'' between subgroups.  For more than two subgroups, we
could heuristically define groups based on the number of peaks and
valleys in the graph.
We can accomplish the second task by conducting posthoc
tests on specific model parameters.  These ideas are illustrated in
the example below, which focuses on the double-max test.

\begin{figure}
\caption{Path diagram representing the factor analysis model used for
  the Example and Simulations.}
\label{fig:famod}
\includegraphics[height=5in]{famod.pdf}
%\input{figs/path}
\end{figure}

\section{Example with Artificial Data}

As an example of the ideas discussed above, consider a
hypothetical battery of six scales administered to students aged 14 to 17
years.  Three of the scales are intended to measure verbal ability, and
three of the scales are intended to measure mathematical ability.  We
may observe a maturation effect in the resulting data, whereby the scales
measure older students better than younger students (i.e., the scales
are too difficult for younger students).  The researcher's goal is to
study whether the scales are measurement invariant with
respect to the full range of ages.

\subsection{Method}

To formally represent these ideas, we specify that the data arise from
a factor analysis model with two factors.  As displayed in
Figure~\ref{fig:famod},
three scales arise from the verbal factor and three 
scales arise from the mathematical second factor.
A seventh observed variable (not pictured in Figure~\ref{fig:famod}),
student age, determines the values of 
verbal factor loadings in the model: 
if students are 16 or 17 years of age, then the factor
loadings corresponding to the first 
factor ($\lambda_{11}, \lambda_{21}, \lambda_{31}$) reflect those in
Figure~\ref{fig:famod}.  If students are between 14 or 15 years of age,
however, then the factor loadings corresponding to the first factor
are three standard errors lower than those in Figure~\ref{fig:famod}
(the standard errors were obtained by fitting
  the model to a sample of size 200, where the sample consisted of all
  ``older'' subjects).
This violation states that the verbal ability scales
lack measurement invariance with respect to age.  For simplicity, we
assume that the mathematical scales are invariant.



A sample of size 200 was generated from the model described above, and
a test was conducted to examine measurement invariance of the three
verbal scales.  To carry out
the test, a confirmatory factor analysis model (with the paths
displayed in Figure~\ref{fig:famod}) was fit to the
data.  Casewise derivatives and 
the observed information matrix were then obtained, and they were used
to calculate the cumulative score process via
Equations~\eqref{eq:cumscore} and~\eqref{eq:browbridge}.  Finally, we
obtained a 
double-max statistic via Equation~\eqref{eq:doubmax} and associated
$p$-value via Equation~\eqref{eq:multidim}.  Note that, because we
were examining only the three verbal factor loading parameters, the
specific null hypothesis being tested is:
\begin{equation}
    \label{eq:exh0}
H_0:\ (\lambda_{i,11}\ \lambda_{i,21}\ \lambda_{i,31}) =
(\lambda_{11}\ \lambda_{21}\ \lambda_{31}),\ i=1,\ldots,n,
\end{equation}
where $(\lambda_{i,11}\ \lambda_{i,21}\ \lambda_{i,31})$ represent the
verbal factor loading parameters for student $i$.

\subsection{Results}
In the results section, we first describe overall results and
describe isolation of groups and model parameters violating
measurement invariance.

\subsubsection{Overall Results}
Results related to the cumulative score process are displayed in
Figure~\ref{fig:cusumex}.  In this figure, the processes
are displayed individually 
for each factor loading, with student number (ordered by age and
numbered from 1 to 200, but divided by 200 to correspond 
to a Brownian bridge) on the x-axis and
absolute values of the cumulative scores on the y-axis.  The dashed horizontal
lines represent the critical value for rejecting $H_0$ at $\alpha=.05$
based on the double-max statistic; if any of the three processes
crosses the horizontal line, then we reject $H_0$.  It is seen that
the processes for both the second and third factor loadings
($\lambda_{21}$ and $\lambda_{31}$) cross the dashed line, indeed
implying rejection of $H_0$.  The maximum across all three processes,
corresponding to the double-max test statistic, is 1.72.  This maximum
occurs in the third graph and is represented as a solid circle, 
achieving a $p$-value of .016.  



\subsubsection{Group and Parameter Isolation}
The results of the test imply that the 
verbal scales lack measurement invariance, and the age at which the
maximum is achieved allows us to define subgroups violating
measurement invariance.  The student corresponding to the maximum
absolute cumulative sum (the solid circle in the third graph) is 15.8
years of age, implying one subgroup of 
students below 15.8 years and one above 15.8 years.  This agrees well
with the true subgroup cut point of 16.0 years.

The results of the test also yield information about specific
parameters violating measurement invariance.  We simultaneously tested
three factor loading parameters for measurement invariance.  Given
rejection of the hypothesis of measurement invariance, we can 
do posthoc 
tests to study specific parameters violating measurement invariance.
This involves individual examination of each cumulative score process
(i.e., of each of the three graphs in Figure~\ref{fig:cusumex}),
along with a procedure that controls for Type I error.  Taking a
Bonferroni approach, we can examine whether each process's maximum
surpasses the critical value associated with an $\alpha$ of
$.05/3=.017$.  This amounts to the same critical value as that used in
the overall test (as shown by Equation~\eqref{eq:multidim}),
meaning that we simply examine the individual processes that cross
the horizontal dashed lines in Figure~\ref{fig:cusumex}.  The Figure
shows that the second and third parameters (i.e., $\lambda_{21}$ and
$\lambda_{31}$) cross the dashed line, so we would conclude a measurement
invariance violation with respect to age in the second and third
verbal tests.  The fact that the cumulative score process for
$\lambda_{11}$ did not achieve the critical value represents a Type II
error, which implicitly brings into question the posthoc tests' power.  We
generally address the issue of power later in the simulations below.

\begin{figure}
\caption{Cumulative score processes for the verbal factor loadings,
  based on the example involving measurement invariance with respect
  to student age.  The dashed lines represent critical values for the
  test of measurement invariance at $\alpha=.05$.}
\label{fig:cusumex}
\includegraphics[height=5in]{example.pdf}
\end{figure}

\section{Simulation}
% Simulations demonstrating power of test(s) at various
% sample sizes, types of invariance violations, ?
In this section, we conduct a simulation designed to
examine the tests' power and Type I error rates in the context
described previously (testing three factor loadings for measurement
invariance).  We 
examine the power and error rates of three tests: the double-max test, the
Cram\'{e}r-von Mises test, and the traditional $\chi^2$ likelihood
ratio (difference) test involving nested 
multiple-group models.  The $\chi^2$ test has an advantage over the
other two tests here, in that it requires advance definition of
groups violating measurement invariance (we supply it with the known
subgroups here).  This test is useful for comparative purposes,
however, as it helps indicate the extent to which the other tests
``lose'' power due to lack of subgroup information.

\subsection{Method}
Simulated data were generated in a similar way to that of 
the Example section.
These data included verbal scales that violated measurement invariance
with respect to students' ages, with students 14--15 years of age
having smaller factor loadings than students 16--17 years of age.  
Simulation data were generated from the same general factor analysis
model (see Figure~\ref{fig:famod}), but sample size and magnitude
of measurement 
invariance violation was manipulated to examine power:
we examined power to detect 
invariance violations across three sample sizes ($n=100,
200, 500$) and three magnitudes of violations (factor loadings
for the younger students being 0, 1, 2, or 3 standard
errors\footnote{The standard errors used here were
  obtained by fitting
  the model to a sample of size 100, where the sample consisted of all
  ``older'' subjects.} below 
those for the older students).  The 0-standard error condition was
used to study Type I error rate.

For each sample size $\times$
magnitude combination, 500 datasets were generated and tested for
measurement invariance.  For the 0-standard error condition, we
generated 5,000 datasets to get a more precise measure of Type I
error.  In each dataset, half the students were 14--15
years of age and half were 16--17 years of age.  As stated previously,
group
designations (below 16.0 years, above 16.0 years) were assumed to be
known for the likelihood ratio test.

\subsection{Results}
% MODIFY RESULTS TO DISCUSS ALL THREE TESTS
% ALSO NEED 0-SE CONDITION
For each test statistic, power and Type I error rates for the twelve
sample size $\times$ magnitude combinations are displayed in
Table~\ref{tab:sim1}.  The 0-SE column lists Type I error rates; this
is the situation where the tests reject the hypothesis of measurement
invariance at $\alpha=.05$ when none exist.  This column generally
shows that the Cram\'{e}r-von Mises test has accurate Type I error
rates at smaller sample sizes, but it becomes slightly conservative at
$n=500$.  The double-max test, on the other hand, is conservative at
all sample sizes examined.  Finally, the likelihood ratio test is
slightly liberal at smaller sample sizes, with Type I error rates of
.07 and .06 at $n=100$ and $200$, respectively.  Type I error for the
likelihood ratio test at $n=500$ is accurate, however.

Focusing on power, the table includes many interesting results.
First, the likelihood ratio test has superior power over the stochastic
process-based tests at all sample sizes and invariance violations.
This is likely due to the fact that the likelihood ratio test had
extra information (the subgroup definitions), whereas the other tests
were essentially testing measurement invariance over all possible
subgroups.  While power was lower for the tests developed in this
paper, it was not terribly low.  At $n=200$ and above, all tests were
on the same side of the traditional power cutoff of 0.8.  The tests
were able to detect large measurement invariance violations (of three
and sometimes two standard errors) at the larger sample sizes, and
they were generally unable to detect the one-standard-error violation
at any of the sample sizes studied.

Comparing only the two proposed test statistics, we see that the
Cram\'{e}r-von Mises test has better power in all conditions.  This is
similar to the general recommendation described by Zeileis et al.\
\citeyear{ZeiSha10}, stating that the Cram\'{e}r-von Mises test
is generally superior when multiple parameters change across
subgroups.  Because the three verbal factor loadings all changed
across the two subgroups in the simulation, the Cram\'{e}r-von Mises
test excels.

In summary, we found that the proposed tests have less power than a
likelihood ratio test with known subgroups.  However, the power levels
remain adequate after considering the fact that the proposed tests are
testing measurement invariance across all possible subgroups.  For the
two-factor model examined here, all tests had trouble detecting small
measurement invariance violations at small sample size.  Larger
violations were more easily detected at larger sample sizes, with the
Cram\'{e}r-von Mises test having better power due to multiple
parameters being involved in the invariance violation.

% 0-SE column is fixed for n=100 (using 5000 reps instead of 500)
\begin{table*}
\caption{Simulated power and Type I error rates for three test statistics
  across three sample sizes and four magnitudes of measurement
  invariance violations. Abbreviations: CvM = Cram\'{e}r-von Mises
  test; DM = Double-max test; $\chi^2$ = Chi-square likelihood ratio
  test.}
\label{tab:sim1}
\begin{tabular}{llcccc} \thickline
 & & \multicolumn{4}{c}{Violation Magnitude (SEs)} \\
$n$ & Test Stat & 0 & 1 & 2 & 3 \\\hline
100 & CvM       & 0.05 & 0.10 & 0.33 & 0.63 \\ 
    & DM        & 0.03 & 0.06 & 0.19 & 0.41 \\ 
    & $\chi^2$  & 0.07 & 0.16 & 0.49 & 0.83 \\ \hline
200 & CvM       & 0.05 & 0.19 & 0.64 & 0.96 \\ 
    & DM        & 0.04 & 0.12 & 0.44 & 0.88 \\ 
    & $\chi^2$  & 0.06 & 0.27 & 0.76 & 0.99 \\ \hline
500 & CvM       & 0.03 & 0.44 & 0.98 & 1.00 \\ 
    & DM        & 0.03 & 0.35 & 0.94 & 1.00 \\ 
    & $\chi^2$  & 0.05 & 0.58 & 1.00 & 1.00 \\\thickline
\end{tabular}
\end{table*}







% Need to re-do simulation to monitor specific parameters in the
% posthoc test.

% Cramer-von Mises now in Sim 1.  May skip Sim 2 for the time being.
%\section{Simulation 2: Improving Power}
%Simulation 2 examines whether we can improve power using a Cramer-von
%Mises statistic (summing instead of taking maximum).

% Table 2 of Nyblom89 contains critical values that may prove useful.
% Hansen 1992 p. 524 has table of critical values that matches 
%  Nyblom89 within reason.
% See Zeileis05 p. 450-451



% Use model that is similar to the example.

\section{Discussion}
In this paper, we have presented a new class of statistical tests for
the study of measurement invariance in psychometrics.  The tests,
based on stochastic processes, have reasonable power, can isolate
groups of individuals violating measurement invariance, and can
isolate specific model parameters affected by the violation.  In this
section, we consider the tests' use in practice and their 
extension to more complex scenarios.

\subsection{Use in Practice}
% Simultaneous test of Meredith's various types of invariance
The proposed tests give researchers a new set of tools for studying 
measurement invariance.  First, they give researchers the
opportunity to simultaneously test for many types of measurement
invariance (see, e.g., Meredith \citeNP{Mer93}).  The traditional
steps have involved hypothesizing a specific type of invariance and
then testing for it via a Likelihood Ratio Test, but the tests
proposed here do not require one to hypothesize a specific type of
invariance a priori.  Instead, one could define a type of measurement
invariance after seeing the proposed tests' results.

% Researchers interpreting subgroups violating MI
In addition to simultaneously testing different types of measurement
invariance, the proposed tests allow researchers to easily interpret
the nature of the invariance violation.  This is made possible through
the tests' abilities to identify subgroups of individuals violating
measurement invariance.  While subgroup identification was
accomplished in this paper via visualization, it is also possible to
define 
formal rules for identifying subgroups.  This idea leads us to the
next section, which describes further issues associated with the
tests' application to the study of measurement invariance.

\subsection{Further Issues}
Further issues associated with the proposed tests include: (1) formal
definition of subgroups violating measurement invariance based on the
results of the statistical test; and (2) dealing
with ties on the auxiliary variable.  We address each in turn below. 

% More than two groups violating MI
\subsubsection{Subgroup Definition}
Given rejection of the hypothesis of measurement invariance, the most
straightforward way to formally identify offending groups is through
the location of the maximum of the cumulative score process.  Assuming two
subgroups, the maximum should be achieved close to the split point
between the the groups.  Referring to the Example (see
Figure~\ref{fig:cusumex}), we would split students at the
age corresponding to the solid dot in the third panel.

To study this method for group identification in more detail, we used
results of our simulation to examine the age at which the maximum of
the cumulative score process occurs.
If the test accurately recovers the violating subgroups,
then the maximum should be close to 16 years
of age.\footnote{The data generated for these
  simulations 
  contained ages measured in days, as opposed to years.  Thus,
  the tests could split students at continuous values like 15.6 or
  16.3 years of age.}
  For each simulation condition, Table~\ref{tab:age1}
  displays confidence intervals for the location of the maximum
  absolute cumulative score.  These confidence intervals were
  calculated across generated 
  datasets, with each dataset contributing one maximum absolute cumulative
  score
  (regardless of whether the hypothesis of
  measurement invariance was rejected).
It is observed that these confidence intervals slightly underestimate
the true age dividing the subgroups, with the degree of bias
decreasing as sample size increases.  The interval widths
are impacted by both the magnitude of the invariance and the sample
size.  In future work, we plan to study alternative ways of
identifying subgroups.

\begin{table*}
\caption{Confidence intervals for the location of the maximum absolute
  cumulative score across the conditions from the simulation.}
\label{tab:age1}
  \begin{tabular}{lccc} \thickline
  & \multicolumn{3}{c}{Violation Magnitude} \\
  $n$ & 1SE & 2SE & 3SE \\\hline
  100 & (15.61; 15.73) & (15.55; 15.65) & (15.50; 15.59) \\
  200 & (15.67; 15.77) & (15.64; 15.72) & (15.67; 15.73) \\
  500 & (15.71; 15.81) & (15.77; 15.83) & (15.80; 15.83) \\\thickline
  \end{tabular}
\end{table*}

% Differing proportions of people in each group
%\subsubsection{Subgroup Proportions}
%The power of the proposed tests is impacted by the proportion of
%individuals within each subgroup.  

% Ties on auxiliary variable (mention use in categorical contexts)
\subsubsection{Ties on the Auxiliary Variable}
There remain unaddressed theoretical issues specific to the 
tests' application to measurement invariance.  These
issues generally stem from the types of auxiliary variables on which
researchers may study measurement invariance.  In
the example described earlier, researchers wanted to know whether a
scale was measurement invariant with respect to student age.
Students could then be ordered based on age, and a test could be 
constructed via Equation~\eqref{eq:cumscore}.  However, an issue arises if there
are ties on age; that is, if two students' ages are exactly
the same.  The proposed tests assume complete ordering of the
students, but these two students cannot be ordered.  In this case, we
may randomly order the two students, but there is an
arbitrariness associated with this strategy.  Alternatively, to obtain
tests that liberally reject the hypothesis of measurement invariance,
we may choose the ordering that results in the largest test
statistic.  If there are many tied students, then there are many
possible orderings that must be examined.  However, examination of all
possible orderings remains computationally feasible because the
casewise first derivatives need to be calculated only once; the
derivatives simply need to be reordered for each ordering of tied
students.

A related issue involves the use of categorical demographic
variables to study measurement invariance; this may be conceptualized
as a situation when many students are tied.  In this case, groups are
already specified in advance, and so traditional methods (i.e.,
Likelihood Ratio tests) may suffice.
However, we could use the framework developed here to obtain an
alternative $\chi^2$ statistic testing measurement invariance.
Assume the observations are divided into $K$ categories $I_1, I_2,
\ldots, I_K$.
First, we can sum first derivatives within each category of the
demographic variable via:
\begin{equation}
    \label{eq:catsum}
    \Delta W_n(I_k) = \frac{1}{n_k\sqrt{n}} \sum_{i \in I_k}
    {\bm{I}}(\widehat{\bm{\theta}})^{-1/2} {\bm{\psi}}({\bm{y}}_i, \widehat{{\bm
      \theta}}),
\end{equation}
where $n_k$ is the sample size in category $k$ and $n$ is the overall
sample size.  This results in a $K \times p$ matrix, with one entry for
each category-by-model parameter combination.  We can test
a specific model parameter for invariance by focusing on the associated
column of the $K \times p$ matrix, summing over the squared entries in
the column to obtain a $\chi^2$ statistic with
$(K-1)$ degrees of freedom \cite{HjoKon02}.
Alternatively, to simultaneously test multiple parameters, we can sum
the $\chi^2$ statistics and degrees of freedom for the individual
parameters.

\subsection{Extensions}
The proposed family of tests can be extended to the simultaneous study
of measurement invariance with 
respect to multiple auxiliary variables and to other psychometric
models.  We consider each extension below.

% Recursive method
\subsubsection{Recursive Multiple-Groups Models}
The proposed tests have the ability to automatically define groups of
individuals violating measurement invariance with respect to a single
auxiliary (often demographic) variable.  If a researcher has multiple
auxiliary variables that he/she wishes to assess for measurement
invariance, then the proposed tests can be inserted into a recursive
algorithm 
that isolates groups of individuals violating measurement
invariance.  Such an algorithm is related to 
classification and regression trees \cite{BreFri84,MerSha10,StrMal09} and
C4.5 \cite{Qui93}.  The algorithm would proceed via the following
steps: 
\begin{enumerate}
  \item Fit a confirmatory factor analysis model to the data, with all
  parameters constrained to be equal across observations.
  \item Conduct a measurement invariance test with respect to each
    auxiliary variable (auxiliary variables are determined in
    advance by the researcher).
  \item If violations of measurement invariance are detected,
  split the data into two (or more) groups based on the auxiliary variable
    corresponding to the largest test statistic.
  \item Fit a multiple-groups factor analysis model based on step 3.
  \item Repeat steps 2--5.
\end{enumerate}
The algorithm would continue until it reaches a
predefined stopping rule.  For example, we may stop 
the algorithm when the tests fail to indicate measurement invariance
violations.  Alternatively, the algorithm may be stopped when the
sample size within any subgroup reaches a minimum level.

The algorithm described in the previous paragraph is related to one
developed by Zeileis et al.\ \citeyear{ZeiHot08} for representing
parameter invariance violations in generalized linear models.  Zeileis
et al.\ present the results in a tree structure, which is
suboptimal for factor analysis models.  Instead, the subgroups
discovered by the algorithm are used here to adaptively define a
multiple-groups factor analysis model.  The
simultaneous study of measurement invariance with respect to multiple
auxiliary variables is an important future direction.

\subsubsection{Other Latent Variable Models}
Aside from recursive measurement invariance detection, the proposed tests
readily extend to other popular psychometric models.  
Instead of studying measurement invariance in factor
analysis, the tests can be used to generally 
study the stability of structural equation model parameters across
observations.  For 
example, it would be possible to assess whether relationships between
latent variables are stronger for some students than for
others.  Secondly, 
the tests may be extended to study differential item functioning (DIF)
in item response models (e.g., \citeNP{KopZei10}, who focused on an
application to Rasch models).  
DIF methods are similar to those for factor analysis in
that subgroups must be specified in advance.  The tests proposed here
can detect subgroups automatically, however, offering a unified way of
studying both 
measurement invariance in factor analysis and differential item
functioning in item response.  While these
two methods have developed largely independently of one another,
some treatments \cite{Mcd99} and recent research \cite{StaChe06} have
sought to unify the methods.  Extensions of the proposed tests can
support this endeavor.

\subsection{Summary}
We have outlined a family of 
stochastic process-based parameter instability tests from theoretical
statistics to the issue of measurement invariance in psychometrics.
The paper included both theoretical development and 
study of the tests' performance.  The tests were found via simulation
to have good properties, making them useful for many psychometric
applications.  More generally, the tests help to
solve standing problems in
measurement invariance research and provide many avenues for
future research, both through extensions of the tests within a
factor-analytic context and through application of the tests to new
models.

\bibliography{list}

\end{document}